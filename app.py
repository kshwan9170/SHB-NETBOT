import os
import uuid
import shutil
import re
import json as global_json  # ì „ì—­ JSON ëª¨ë“ˆì— ë³„ì¹­ ë¶€ì—¬
import urllib.parse
import time
from pathlib import Path
from datetime import datetime
from werkzeug.utils import secure_filename
from flask import Flask, render_template, request, jsonify, send_from_directory, redirect, url_for, abort
import openai
from openai import OpenAI

# ê²Œì‹œíŒ ëª¨ë¸ ì„í¬íŠ¸
from models import init_db, get_db, close_db, InquiryBoard, FeedbackBoard, ReportBoard, ChatFeedbackModel

# Custom modules
import database
import document_processor
import chatbot
from config import FAQ_KEYWORDS, FINE_TUNED_MODEL, RAG_SYSTEM
from flow_converter import check_and_sync_flow, get_offline_flow

# CSV íŒŒì¼ ì²˜ë¦¬ ì´ˆê¸°í™”
chatbot.initialize_csv_narratives()

app = Flask(__name__)

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
init_db()

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ
@app.teardown_appcontext
def close_connection(exception):
    close_db(exception)

# íŒŒì¼ ì—…ë¡œë“œ ì„¤ì •
UPLOAD_FOLDER = 'uploaded_files'
TEMP_CHUNK_FOLDER = 'temp_chunks'  # ì²­í¬ íŒŒì¼ ì„ì‹œ ì €ì¥ í´ë”
ALLOWED_EXTENSIONS = {'pdf', 'docx', 'pptx', 'xlsx', 'xls', 'txt', 'csv'}
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['TEMP_CHUNK_FOLDER'] = TEMP_CHUNK_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB max upload size (for chunks)

# ì—…ë¡œë“œ í´ë” ìƒì„±
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(TEMP_CHUNK_FOLDER, exist_ok=True)

# OpenAI API í‚¤ ì„¤ì •
openai_api_key = os.environ.get("OPENAI_API_KEY")
client = OpenAI(api_key=openai_api_key)

def allowed_file(filename):
    """íŒŒì¼ í™•ì¥ì ì²´í¬"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def get_clean_filename(filename):
    """ë³´ì•ˆì„ ìœ„í•´ ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„± (í•œê¸€ íŒŒì¼ëª… ì§€ì›)"""
    if not filename:
        return ""
    # ìœ„í—˜í•œ ë¬¸ìë§Œ ì œê±°í•˜ê³  í•œê¸€ì€ ìœ ì§€
    s = str(filename).strip()
    s = re.sub(r'[\\/*?:"<>|]', '', s)  # ìœˆë„ìš°ì—ì„œ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
    s = s.replace('..', '')  # ìƒìœ„ ë””ë ‰í† ë¦¬ ì°¸ì¡° ë°©ì§€
    return s.strip()

@app.route('/')
def index():
    return render_template('index.html')
    


@app.route('/static/<path:path>')
def serve_static(path):
    return app.send_static_file(path)

@app.route('/api/connection_status', methods=['GET'])
def connection_status():
    """
    í˜„ì¬ OpenAI API ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    
    Returns:
        JSON: ì—°ê²° ìƒíƒœ ì •ë³´ {'status': 'online'/'offline', 'reason': 'ì´ìœ '}
    """
    # OpenAI API í‚¤ í™•ì¸
    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key:
        return jsonify({'status': 'offline', 'reason': 'api_key_missing'}), 200
    
    # OpenAI API ì—°ê²° í™•ì¸ (ê°„ë‹¨í•œ ìš”ì²­ìœ¼ë¡œ í…ŒìŠ¤íŠ¸)
    try:
        openai_client = OpenAI(api_key=openai_key)
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": "test"}],
            max_tokens=5
        )
        return jsonify({'status': 'online'}), 200
    except Exception as e:
        print(f"OpenAI API ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return jsonify({'status': 'offline', 'reason': 'api_connection_error', 'error': str(e)}), 200

@app.route('/api/sync_offline_data', methods=['POST'])
def sync_offline_data():
    """ChromaDB ë°ì´í„°ë¥¼ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡í•˜ì—¬ IndexedDB ë™ê¸°í™”"""
    try:
        from csv_to_narrative import CsvNarrativeConverter
        
        # CSV íŒŒì¼ì—ì„œ ëª¨ë“  ìì—°ì–´ ë°ì´í„° ìƒì„±
        converter = CsvNarrativeConverter()
        all_narratives = []
        
        # ì—…ë¡œë“œëœ CSV íŒŒì¼ë“¤ ì²˜ë¦¬
        uploaded_files = os.listdir('uploaded_files')
        csv_files = [f for f in uploaded_files if f.endswith('.csv') and not f.startswith('test')]
        
        print(f"ì˜¤í”„ë¼ì¸ ë™ê¸°í™”: {len(csv_files)}ê°œ CSV íŒŒì¼ ì²˜ë¦¬ ì‹œì‘")
        
        for csv_file in csv_files:
            try:
                csv_path = os.path.join('uploaded_files', csv_file)
                narratives = converter.csv_to_narratives(csv_path)
                all_narratives.extend(narratives)
                print(f"CSV íŒŒì¼ {csv_file}: {len(narratives)}ê°œ ë ˆì½”ë“œ ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                print(f"CSV íŒŒì¼ {csv_file} ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                continue
        
        print(f"ì´ {len(all_narratives)}ê°œ ë ˆì½”ë“œë¥¼ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡")
        
        return jsonify({
            'status': 'success',
            'data': all_narratives,
            'total_records': len(all_narratives),
            'csv_files_processed': len(csv_files)
        })
        
    except Exception as e:
        print(f"ì˜¤í”„ë¼ì¸ ë°ì´í„° ë™ê¸°í™” ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'ì˜¤í”„ë¼ì¸ ë°ì´í„° ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.get_json()
    user_message = data.get('message', '')
    use_offline_mode = data.get('offline_mode', False)
    
    if not user_message:
        return jsonify({'error': 'ë©”ì‹œì§€ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.'}), 400
    
    # ì§ˆë¬¸ í†µê³„ ê¸°ë¡ (ì¹´í…Œê³ ë¦¬ëŠ” ì¼ë‹¨ nullë¡œ ë‘ê³  ì¶”í›„ ê°œì„ )
    from models import QueryStatisticsModel
    query_stats = QueryStatisticsModel()
    query_stats.record_query(user_message)
    
    # OpenAI API í‚¤ í™•ì¸
    openai_key = os.getenv("OPENAI_API_KEY")
    
    # ì˜¤í”„ë¼ì¸ ëª¨ë“œ ê°•ì œ ì„¤ì • ì—¬ë¶€ ë˜ëŠ” API í‚¤ ë¶€ì¬ í™•ì¸
    if use_offline_mode or not openai_key:
        try:
            # ë¡œì»¬ ë°ì´í„° ê¸°ë°˜ ì‘ë‹µ ìƒì„±
            # CSV ë°ì´í„°ê°€ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ì¬ë¡œë“œ ì‹œë„
            if not chatbot.csv_narratives:
                print("CSV ë°ì´í„°ê°€ ì—†ì–´ ì´ˆê¸°í™” ì‹œë„")
                chatbot.initialize_csv_narratives()
                
            reply = chatbot.get_local_response(user_message)
            offline_message = "[ğŸ”´ ì„œë²„ ì—°ê²°ì´ ëŠê²¼ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì•ˆë‚´ ì •ë³´ë¡œ ì‘ë‹µ ì¤‘ì…ë‹ˆë‹¤.]\n\n"
            
            return jsonify({
                'reply': offline_message + reply,
                'question': user_message,
                'mode': 'offline'
            })
        except Exception as offline_error:
            print(f"ì˜¤í”„ë¼ì¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(offline_error)}")
            return jsonify({
                'reply': '[ğŸ”´ ì„œë²„ ì—°ê²°ì´ ëŠê²¼ìŠµë‹ˆë‹¤.]\n\nëª¨ë“  ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.',
                'question': user_message,
                'mode': 'offline',
                'error': str(offline_error)
            }), 500
    
    # ì¼ë°˜(ì˜¨ë¼ì¸) ëª¨ë“œ
    try:
        # ì±—ë´‡ ëª¨ë“ˆì„ í™œìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
        # ì´ í•¨ìˆ˜ëŠ” í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ê¸° ì²˜ë¦¬, Fine-tuned ëª¨ë¸ ì‚¬ìš©, RAG ì‹œìŠ¤í…œ í™œìš©ì„ ëª¨ë‘ í¬í•¨í•©ë‹ˆë‹¤
        reply = chatbot.get_chatbot_response(
            query=user_message,
            model=RAG_SYSTEM["model"],
            use_rag=True
        )
        
        # ë¡œê·¸ ê¸°ë¡ (ë””ë²„ê¹…ìš©)
        print(f"ì±—ë´‡ ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(user_message)}ì ì§ˆë¬¸ / {len(reply) if reply else 0}ì ì‘ë‹µ")
        
        return jsonify({'reply': reply, 'question': user_message, 'mode': 'online'})
    
    except Exception as e:
        print(f"API ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ, ì˜¤í”„ë¼ì¸ ëª¨ë“œë¡œ ì „í™˜: {str(e)}")
        
        try:
            # API ì˜¤ë¥˜ ì‹œ ì˜¤í”„ë¼ì¸ ëª¨ë“œë¡œ í´ë°±
            # CSV ë°ì´í„°ê°€ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ì¬ë¡œë“œ ì‹œë„
            if not chatbot.csv_narratives:
                print("API ì˜¤ë¥˜ ëª¨ë“œ: CSV ë°ì´í„°ê°€ ì—†ì–´ ì´ˆê¸°í™” ì‹œë„")
                chatbot.initialize_csv_narratives()
                
            offline_reply = chatbot.get_local_response(user_message)
            fallback_message = f"[ğŸ”´ ì„œë²„ ì—°ê²°ì´ ëŠê²¼ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì•ˆë‚´ ì •ë³´ë¡œ ì‘ë‹µ ì¤‘ì…ë‹ˆë‹¤.]\n\n"
            
            return jsonify({
                'reply': fallback_message + offline_reply,
                'question': user_message,
                'mode': 'offline'
            })
        except Exception as offline_error:
            print(f"ì˜¤í”„ë¼ì¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(offline_error)}")
            # ì‚¬ìš©ì ì–¸ì–´ì— ë§ê²Œ ì˜¤ë¥˜ ë©”ì‹œì§€
            if re.search(r'[ê°€-í£]', user_message):
                reply = "[ğŸ”´ ì„œë²„ ì—°ê²°ì´ ëŠê²¼ìŠµë‹ˆë‹¤.]\n\nì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì„œë²„ ì—°ê²°ì´ ì›í™œí•˜ì§€ ì•Šì•„ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            else:
                reply = "[ğŸ”´ Server connection lost.]\n\nSorry, the server connection is currently unavailable. Please check your network connection."
                
            return jsonify({'reply': reply, 'question': user_message, 'mode': 'offline'}), 500

@app.route('/api/chat/feedback', methods=['POST'])
def chat_feedback():
    """ì±„íŒ… í”¼ë“œë°± API"""
    try:
        data = request.get_json()
        
        # í•„ìˆ˜ íŒŒë¼ë¯¸í„° í™•ì¸
        if not data or 'question' not in data or 'answer' not in data or 'feedback_type' not in data:
            return jsonify({'error': 'í•„ìˆ˜ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.'}), 400
        
        question = data['question']
        answer = data['answer']
        feedback_type = data['feedback_type']
        feedback_comment = data.get('feedback_comment', '')  # ì„ íƒì  íŒŒë¼ë¯¸í„°
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        feedback_model = ChatFeedbackModel()
        feedback_id = feedback_model.create_feedback(
            question=question, 
            answer=answer,
            feedback_type=feedback_type,
            feedback_comment=feedback_comment
        )
        
        return jsonify({
            'success': True,
            'message': 'í”¼ë“œë°±ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'feedback_id': feedback_id
        })
        
    except Exception as e:
        print(f"Error in chat feedback API: {str(e)}")
        return jsonify({'error': f'í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500
        
@app.route('/api/upload', methods=['POST'])
def upload_file():
    # íŒŒì¼ì´ ìš”ì²­ì— ìˆëŠ”ì§€ í™•ì¸
    if 'file' not in request.files:
        return jsonify({'error': 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400
    
    files = request.files.getlist('file')
    
    if not files or files[0].filename == '':
        return jsonify({'error': 'ì„ íƒëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400
    
    # ì—…ë¡œë“œëœ ê° íŒŒì¼ì— ëŒ€í•´ ì²˜ë¦¬
    results = []
    for file in files:
        if file and allowed_file(file.filename):
            # ë³´ì•ˆì„ ìœ„í•œ íŒŒì¼ëª… ì„¤ì • (í•œê¸€ íŒŒì¼ëª… ì§€ì›)
            if file and file.filename:
                filename = get_clean_filename(str(file.filename))
            else:
                continue
            
            # ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
            unique_filename = f"{uuid.uuid4()}_{filename}"
            file_path = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
            
            try:
                # íŒŒì¼ ì €ì¥
                file.save(file_path)
                
                # ë¬¸ì„œ ì²˜ë¦¬ ë° ì²­í¬ ìƒì„± (ìµœëŒ€ 500 í† í° í¬ê¸° ì²­í¬)
                chunks = document_processor.process_document(file_path)
                print(f"ë¬¸ì„œ ë¶„í•  ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬")
                
                # ê° ì²­í¬ì— í•„ìš”í•œ ë©”íƒ€ë°ì´í„° ì¶”ê°€ (ì†ŒìŠ¤ ë¬¸ì„œ ì •ë³´)
                for chunk in chunks:
                    if 'metadata' in chunk:
                        chunk['metadata']['source'] = filename
                        chunk['metadata']['doc_id'] = chunk['doc_id']
                
                # ì²­í¬ë¥¼ ë²¡í„° DBì— ì €ì¥ (ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ ì»¬ë ‰ì…˜ "uploaded_docs" ì‚¬ìš©)
                try:
                    database.add_document_embeddings(chunks)
                    print(f"ë²¡í„° DBì— {len(chunks)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ: {filename}")
                except Exception as db_error:
                    print(f"ERROR: RAG pipeline failed during vector DB storage: {str(db_error)}")
                    raise db_error
                
                # â­ SHB-NetBot_Flow.csv íŒŒì¼ ìë™ ê°ì§€ ë° JSON ë³€í™˜
                flow_sync_message = ""
                if "SHB-NetBot_Flow" in filename and filename.endswith('.csv'):
                    try:
                        print(f"ğŸ”„ Flow íŒŒì¼ ê°ì§€: {filename} - ì¦‰ì‹œ JSON ë³€í™˜ ì‹œì‘")
                        
                        # Flow ë³€í™˜ê¸° ì„í¬íŠ¸ ë° ì¦‰ì‹œ ì‹¤í–‰
                        from flow_converter import FlowConverter
                        import time
                        import json
                        
                        converter = FlowConverter()
                        flow_path = os.path.join(app.config['UPLOAD_FOLDER'], safe_filename)
                        
                        # ğŸš¨ ì¤‘ìš”: ì—…ë¡œë“œëœ íŒŒì¼ ì¦‰ì‹œ ë³€í™˜
                        conversion_result = converter.csv_to_flow_json(flow_path)
                        
                        if conversion_result and conversion_result.get('success', False):
                            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ ìºì‹œ ë¬´íš¨í™” ê°•ì œ
                            timestamp = int(time.time() * 1000)
                            
                            try:
                                json_path = converter.output_path
                                if os.path.exists(json_path):
                                    with open(json_path, 'r', encoding='utf-8') as f:
                                        flow_data = json.load(f)
                                    
                                    # ğŸ”„ ê°•ì œ ë™ê¸°í™”ë¥¼ ìœ„í•œ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                                    flow_data['_sync_metadata'] = {
                                        'last_updated': timestamp,
                                        'source_file': filename,
                                        'force_refresh': True,
                                        'version': f"upload_{timestamp}",
                                        'cache_bust': f"flow_{timestamp}"
                                    }
                                    
                                    with open(json_path, 'w', encoding='utf-8') as f:
                                        json.dump(flow_data, f, ensure_ascii=False, indent=2)
                                    
                                    print(f"ğŸ”„ Flow JSON ê°•ì œ ê°±ì‹  ì™„ë£Œ: {timestamp}")
                                    flow_sync_message = f"\nâœ… Flow ì‹¤ì‹œê°„ ë™ê¸°í™” ì™„ë£Œ: {conversion_result.get('nodes_count', 0)}ê°œ ë…¸ë“œ (ë²„ì „: {timestamp})"
                                    
                            except Exception as meta_error:
                                print(f"âš ï¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨: {meta_error}")
                                flow_sync_message = f"\nâœ… Flow ê¸°ë³¸ ë™ê¸°í™” ì™„ë£Œ: {conversion_result.get('nodes_count', 0)}ê°œ ë…¸ë“œ"
                            
                            print(f"âœ… Flow ì—…ë¡œë“œ í›„ ì¦‰ì‹œ ë³€í™˜ ì™„ë£Œ: {conversion_result}")
                        else:
                            flow_sync_message = f"\nâŒ Flow ë³€í™˜ ì‹¤íŒ¨: {conversion_result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                            print(f"âŒ Flow ì¦‰ì‹œ ë³€í™˜ ì‹¤íŒ¨: {conversion_result}")
                            
                    except Exception as flow_error:
                        flow_sync_message = f"\nâŒ Flow ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {str(flow_error)}"
                        print(f"âŒ Flow ìë™ ë³€í™˜ ì˜¤ë¥˜: {str(flow_error)}")
                
                # ì„±ê³µ ê²°ê³¼ ì¶”ê°€
                results.append({
                    'filename': filename,
                    'status': 'success',
                    'message': 'ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.' + flow_sync_message,
                    'doc_id': chunks[0]['doc_id'] if chunks else None,
                    'chunk_count': len(chunks)
                })
            except Exception as e:
                print(f"Error processing file {filename}: {str(e)}")
                results.append({
                    'filename': filename,
                    'status': 'error',
                    'message': f'ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
                })
        else:
            results.append({
                'filename': file.filename,
                'status': 'error',
                'message': 'ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.'
            })
    
    return jsonify({'results': results})

@app.route('/api/documents', methods=['GET'])
def get_documents():
    """ì—…ë¡œë“œëœ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ"""
    try:
        document_status = database.get_database_status()
        
        # í´ë”ì—ì„œ íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        files = []
        for filename in os.listdir(app.config['UPLOAD_FOLDER']):
            if not filename.startswith('.') and not filename.endswith('_metadata.json'):  # ìˆ¨ê¹€ íŒŒì¼ê³¼ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì œì™¸
                file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                if os.path.isfile(file_path):
                    # ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ (UUID ì œê±°)
                    original_filename = "_".join(filename.split("_")[1:])
                    
                    # íŒŒì¼ í†µê³„ ì •ë³´
                    file_stats = os.stat(file_path)
                    files.append({
                        'filename': original_filename,
                        'size': file_stats.st_size,
                        'uploaded_at': file_stats.st_mtime,
                        'file_type': original_filename.split('.')[-1].lower(),
                        'system_filename': filename  # ì‹œìŠ¤í…œ ë‚´ë¶€ íŒŒì¼ëª… ì¶”ê°€ (ì‚­ì œ ê¸°ëŠ¥ì„ ìœ„í•´)
                    })
        
        return jsonify({
            'document_count': document_status.get('document_count', 0),
            'chunk_count': document_status.get('chunk_count', 0),
            'files': files
        })
    except Exception as e:
        print(f"Error getting documents: {str(e)}")
        return jsonify({'error': str(e)}), 500
        
# CSV íŒŒì¼ í¸ì§‘ API ì—”ë“œí¬ì¸íŠ¸ 
@app.route('/api/documents/edit/<path:system_filename>', methods=['POST'])
def edit_document(system_filename):
    """ë¬¸ì„œ ë‚´ìš© í¸ì§‘ API - CSV íŒŒì¼ ì›¹ í¸ì§‘ ì§€ì›"""
    try:
        # íŒŒì¼ëª…ì— íŠ¹ìˆ˜ë¬¸ìê°€ ìˆì„ ê²½ìš° ì²˜ë¦¬ (URL ë””ì½”ë”©)
        decoded_filename = urllib.parse.unquote(system_filename)
        print(f"Attempting to edit document: {decoded_filename}")
        
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], decoded_filename)
        
        # íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
        if not os.path.exists(file_path):
            return jsonify({
                'status': 'error',
                'message': f'ìš”ì²­í•œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {decoded_filename}'
            }), 404
        
        # ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ ë° íŒŒì¼ í˜•ì‹ í™•ì¸
        basename = os.path.basename(file_path)
        parts = basename.split("_", 1)
        original_filename = parts[1] if len(parts) > 1 else basename
        file_extension = os.path.splitext(original_filename)[1][1:].lower()
        
        # CSV íŒŒì¼ë§Œ í¸ì§‘ ì§€ì›
        if file_extension != 'csv':
            return jsonify({
                'status': 'error',
                'message': f'í˜„ì¬ CSV íŒŒì¼ë§Œ í¸ì§‘ì„ ì§€ì›í•©ë‹ˆë‹¤. íŒŒì¼ í˜•ì‹: {file_extension}'
            }), 400
        
        # ìš”ì²­ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        request_data = request.get_json()
        if not request_data or 'headers' not in request_data or 'data' not in request_data:
            return jsonify({
                'status': 'error',
                'message': 'ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° í˜•ì‹ì…ë‹ˆë‹¤. headersì™€ data í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }), 400
        
        headers = request_data['headers']
        data = request_data['data']
        encoding = request_data.get('encoding', 'utf-8')
        
        # CSV íŒŒì¼ ì—…ë°ì´íŠ¸
        from csv_editor import update_csv_file, get_csv_preview_html
        success = update_csv_file(file_path, headers, data, encoding)
        
        if not success:
            return jsonify({
                'status': 'error',
                'message': 'CSV íŒŒì¼ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
            }), 500
        
        # ì—…ë°ì´íŠ¸ëœ CSV íŒŒì¼ ì½ê¸°
        import pandas as pd
        try:
            df = pd.read_csv(file_path, encoding=encoding)
        except UnicodeDecodeError:
            # ë‹¤ë¥¸ ì¸ì½”ë”© ì‹œë„
            try:
                encoding = 'cp949' if encoding == 'utf-8' else 'utf-8'
                df = pd.read_csv(file_path, encoding=encoding)
            except Exception as e:
                return jsonify({
                    'status': 'error',
                    'message': f'CSV íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
                }), 500
        
        # ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        metadata_filename = f"{os.path.splitext(decoded_filename)[0]}_metadata.json"
        metadata_path = os.path.join(app.config['UPLOAD_FOLDER'], metadata_filename)
        
        # HTML í…Œì´ë¸” ìƒì„± (í¸ì§‘ëœ ë‚´ìš© í‘œì‹œ)
        table_html = df.to_html(classes='table table-striped table-bordered table-hover editable-csv-table', index=False, na_rep='')
        
        # ì„±ê³µ ì‘ë‹µ
        return jsonify({
            'status': 'success',
            'message': 'CSV íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'content': table_html,
            'file_type': 'csv'
        })
        
    except Exception as e:
        print(f"Error editing document: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'ë¬¸ì„œ í¸ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500

@app.route('/api/documents/view/<path:system_filename>', methods=['GET'])
def view_document(system_filename):
    """ë¬¸ì„œ ë‚´ìš© ì¡°íšŒ API - ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ ì§€ì›"""
    try:
        # íŒŒì¼ëª…ì— íŠ¹ìˆ˜ë¬¸ìê°€ ìˆì„ ê²½ìš° ì²˜ë¦¬ (URL ë””ì½”ë”©)
        decoded_filename = urllib.parse.unquote(system_filename)
        print(f"Attempting to view document: {decoded_filename}")
        
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], decoded_filename)
        print(f"File path: {file_path}")
        
        # íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš° íŒŒì¼ëª… ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰
        if not os.path.exists(file_path):
            # ì‹œìŠ¤í…œì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  íŒŒì¼ í™•ì¸
            all_files = os.listdir(app.config['UPLOAD_FOLDER'])
            matching_files = [f for f in all_files if decoded_filename in f]
            
            if matching_files:
                file_path = os.path.join(app.config['UPLOAD_FOLDER'], matching_files[0])
                print(f"Found similar file: {matching_files[0]}")
            else:
                return jsonify({
                    'status': 'error',
                    'message': f'ìš”ì²­í•œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {decoded_filename}'
                }), 404
        
        print(f"File exists: {os.path.exists(file_path)}")
        
        # ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ ë° íŒŒì¼ í˜•ì‹ í™•ì¸
        basename = os.path.basename(file_path)
        parts = basename.split("_", 1)
        original_filename = parts[1] if len(parts) > 1 else basename
        file_extension = os.path.splitext(original_filename)[1][1:].lower()
        
        print(f"Original filename: {original_filename}, Extension: {file_extension}")
        
        # íŒŒì¼ í˜•ì‹ë³„ ì²˜ë¦¬
        content = ""
        
        # TXT íŒŒì¼ ì²˜ë¦¬
        if file_extension == 'txt':
            # íŒŒì¼ ë‚´ìš© ì½ê¸° (UTF-8 ë¨¼ì € ì‹œë„, ì‹¤íŒ¨ ì‹œ CP949 ì‹œë„)
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                try:
                    with open(file_path, 'r', encoding='cp949') as f:
                        content = f.read()
                except Exception as e:
                    return jsonify({
                        'status': 'error',
                        'message': f'íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
                    }), 500
        
        # CSV íŒŒì¼ ì²˜ë¦¬
        elif file_extension == 'csv':
            import pandas as pd
            from csv_editor import generate_csv_metadata, save_csv_metadata, get_csv_preview_html
            
            try:
                # CSV íŒŒì¼ ì½ê¸° ì‹œë„ (ë‹¤ì–‘í•œ ì¸ì½”ë”© ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„)
                encodings = ['utf-8', 'cp949', 'latin1']
                df = None
                used_encoding = None
                
                for encoding in encodings:
                    try:
                        # ë¨¼ì € ì²« ì¤„ë§Œ ì½ì–´ì„œ í—¤ë” í™•ì¸
                        header_check = pd.read_csv(file_path, dtype=str, nrows=1, encoding=encoding)
                        header_count = len(header_check.columns)
                        
                        # í—¤ë”ê°€ 1ê°œë§Œ ìˆëŠ” ê²½ìš° (ì¸ì½”ë”©ì´ ì˜ëª» ì¸ì‹ë˜ì—ˆì„ ê°€ëŠ¥ì„±)
                        if header_count <= 1:
                            print(f"{encoding} ì¸ì½”ë”©ìœ¼ë¡œ í—¤ë”ë¥¼ ì½ì—ˆìœ¼ë‚˜ ì—´ì´ {header_count}ê°œë°–ì— ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ë²• ì‹œë„...")
                            # í—¤ë” ì—†ì´ ì½ê¸°
                            df_raw = pd.read_csv(file_path, header=None, encoding=encoding)
                            if len(df_raw) > 0 and len(df_raw.columns) > 1:
                                # ì²« ë²ˆì§¸ í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©
                                df = pd.DataFrame(df_raw.values[1:], columns=df_raw.iloc[0])
                                print(f"í—¤ë” ì—†ì´ ì½ì—ˆì„ ë•Œ ì—´ ê°œìˆ˜: {len(df.columns)}")
                            else:
                                # ì²« ë²ˆì§¸ í–‰ í¬í•¨í•´ì„œ ë°ì´í„°ë¡œ ì‚¬ìš© (ì—´ êµ¬ë¶„ ë¬¸ì œì¸ ê²½ìš°)
                                try:
                                    sep_options = [',', ';', '\t', '|']
                                    for sep in sep_options:
                                        try:
                                            df_test = pd.read_csv(file_path, sep=sep, encoding=encoding)
                                            if len(df_test.columns) > 1:
                                                df = df_test
                                                print(f"êµ¬ë¶„ì '{sep}'ë¡œ ì„±ê³µì ìœ¼ë¡œ {len(df.columns)}ê°œ ì—´ ì½ìŒ")
                                                break
                                        except:
                                            continue
                                except:
                                    # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°
                                    pass
                        else:
                            # ì •ìƒì ìœ¼ë¡œ í—¤ë”ê°€ ì—¬ëŸ¬ ê°œ ì¸ì‹ë¨
                            df = pd.read_csv(file_path, dtype=str, na_filter=False, encoding=encoding)
                        
                        used_encoding = encoding
                        print(f"CSV íŒŒì¼ '{original_filename}' {encoding} ì¸ì½”ë”©ìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ì½ìŒ, ì—´ ê°œìˆ˜: {len(df.columns if df is not None else header_check.columns)}")
                        break
                    except Exception as e:
                        print(f"{encoding} ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸° ì‹¤íŒ¨: {str(e)}")
                        continue
                
                # ëª¨ë“  ì¸ì½”ë”© ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨í•œ ê²½ìš°
                if df is None:
                    return jsonify({
                        'status': 'error',
                        'message': f'CSV íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§€ì›ë˜ì§€ ì•ŠëŠ” ì¸ì½”ë”©ì…ë‹ˆë‹¤.'
                    }), 500
                    
                # ë°ì´í„° í™•ì¸
                print(f"ìµœì¢… ì—´ ëª©ë¡: {df.columns.tolist()}")
                print(f"ë°ì´í„° í–‰ ìˆ˜: {len(df)}")
                
                # ë©”íƒ€ë°ì´í„° ìƒì„± ë° ì €ì¥
                metadata_filename = f"{os.path.splitext(decoded_filename)[0]}_metadata.json"
                metadata_path = os.path.join(app.config['UPLOAD_FOLDER'], metadata_filename)
                metadata = generate_csv_metadata(file_path)
                save_csv_metadata(metadata, metadata_path)
                
                # í¸ì§‘ ê°€ëŠ¥í•œ HTML ë¯¸ë¦¬ë³´ê¸° ìƒì„±
                html_content = get_csv_preview_html(
                    df=df, 
                    filename=original_filename, 
                    system_filename=decoded_filename, 
                    metadata_filename=os.path.basename(metadata_path)
                )
                
                return jsonify({
                    'status': 'success',
                    'html_content': True,
                    'file_type': 'csv',
                    'content': html_content,
                    'metadata_generated': True,
                    'encoding': used_encoding
                })
                
            except Exception as e:
                print(f"CSV íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return jsonify({
                    'status': 'error',
                    'message': f'CSV íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
                }), 500
        
        # JSON íŒŒì¼ ì²˜ë¦¬
        elif file_extension == 'json':
            try:
                # JSON íŒŒì¼ ì½ê¸°
                try:
                    # UTF-8ë¡œ ì‹œë„
                    with open(file_path, 'r', encoding='utf-8') as f:
                        json_content = f.read()
                except UnicodeDecodeError:
                    # CP949ë¡œ ì‹œë„ (í•œê¸€ íŒŒì¼ëª… ëŒ€ì‘)
                    with open(file_path, 'r', encoding='cp949') as f:
                        json_content = f.read()
                
                # JSON í¬ë§·íŒ… ì²˜ë¦¬
                import json as json_module  # ì´ë¦„ ì¶©ëŒì„ í”¼í•˜ê¸° ìœ„í•´ ë³„ì¹­ ì‚¬ìš©
                try:
                    parsed_json = json_module.loads(json_content)
                    formatted_json = json_module.dumps(parsed_json, indent=2, ensure_ascii=False)
                    
                    # HTMLë¡œ í‘œì‹œí•˜ê¸° ìœ„í•œ ì²˜ë¦¬
                    content = f"""
                    <div class="json-container">
                        <div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px; margin-bottom: 10px;">
                            <h3 style="margin: 0; color: #333;">JSON íŒŒì¼ ë‚´ìš©</h3>
                            <p style="margin: 5px 0 0;">íŒŒì¼ëª…: {original_filename}</p>
                        </div>
                        <pre style="background-color: #f8f9fa; padding: 15px; border-radius: 5px; overflow: auto; white-space: pre-wrap; font-family: monospace; line-height: 1.5;">{formatted_json}</pre>
                    </div>
                    """
                    
                    # HTML ì½˜í…ì¸ ë¡œ ë°˜í™˜
                    return jsonify({
                        'status': 'success',
                        'html_content': True,
                        'content': content,
                        'file_type': 'json'
                    })
                    
                except global_json.JSONDecodeError as je:
                    # ìœ íš¨í•˜ì§€ ì•Šì€ JSONì¸ ê²½ìš° ì˜¤ë¥˜ ë©”ì‹œì§€ì™€ í•¨ê»˜ ì›ë³¸ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
                    content = f"""
                    <div class="json-container">
                        <div style="background-color: #fff0f0; padding: 10px; border-radius: 5px; margin-bottom: 10px; border: 1px solid #ffcccc;">
                            <h3 style="margin: 0; color: #cc0000;">ìœ íš¨í•˜ì§€ ì•Šì€ JSON íŒŒì¼</h3>
                            <p style="margin: 5px 0 0;">ì˜¤ë¥˜: {str(je)}</p>
                        </div>
                        <pre style="background-color: #f8f9fa; padding: 15px; border-radius: 5px; overflow: auto; white-space: pre-wrap; font-family: monospace; line-height: 1.5;">{json_content}</pre>
                    </div>
                    """
                    
                    return jsonify({
                        'status': 'success',
                        'html_content': True,
                        'content': content,
                        'file_type': 'json'
                    })
                    
            except Exception as e:
                print(f"JSON íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return jsonify({
                    'status': 'error',
                    'message': f'JSON íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
                }), 500

        # PDF íŒŒì¼ ì²˜ë¦¬
        elif file_extension == 'pdf':
            import base64
            with open(file_path, 'rb') as f:
                pdf_content = f.read()
                # PDFë¥¼ base64ë¡œ ì¸ì½”ë”©
                pdf_base64 = base64.b64encode(pdf_content).decode('utf-8')
                
                # PDF ë·°ì–´ë¥¼ ìœ„í•œ HTML ì½˜í…ì¸  ìƒì„±
                content = f"""
                <div class="pdf-container" style="width: 100%; height: 800px; display: flex; flex-direction: column;">
                    <div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px; margin-bottom: 10px;">
                        <h3 style="margin: 0; color: #333;">PDF íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°</h3>
                        <p style="margin: 5px 0 0;">íŒŒì¼ëª…: {original_filename}</p>
                    </div>
                    <iframe 
                        src="data:application/pdf;base64,{pdf_base64}" 
                        width="100%" 
                        height="100%" 
                        style="border: 1px solid #ddd; border-radius: 5px;"
                        title="PDF ë¯¸ë¦¬ë³´ê¸°">
                        <p>PDFë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. <a href="data:application/pdf;base64,{pdf_base64}" download="{original_filename}">ì—¬ê¸°ë¥¼ í´ë¦­í•˜ì—¬ ë‹¤ìš´ë¡œë“œ</a>í•˜ì„¸ìš”.</p>
                    </iframe>
                </div>
                """
                
            return jsonify({
                'status': 'success',
                'html_content': True,
                'content': content,
                'file_type': 'pdf'
            })
        
        # CSV íŒŒì¼ ì²˜ë¦¬ (ì´ ë¶€ë¶„ì€ ìœ„ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨)
        elif file_extension == 'csv':
            # ì´ë¯¸ ìœ„ì—ì„œ CSV íŒŒì¼ ì²˜ë¦¬ ë¡œì§ì„ êµ¬í˜„í–ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ê±´ë„ˆëœ€
            pass

        # Excel íŒŒì¼ ì²˜ë¦¬
        elif file_extension in ['xlsx', 'xls']:
            import pandas as pd
            import io
            import base64
            try:
                # ì—‘ì…€ íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ ì½ê¸°
                excel_file = pd.ExcelFile(file_path)
                sheet_names = excel_file.sheet_names
                
                # ëª¨ë“  ì‹œíŠ¸ë¥¼ HTMLë¡œ ë³€í™˜
                all_sheets_html = []
                
                for sheet_name in sheet_names:
                    # ì‹œíŠ¸ ì½ê¸° ì„¤ì • - ëª¨ë“  ì—´ì„ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬í•˜ì—¬ ë°ì´í„° ìœ ì‹¤ ë°©ì§€
                    df = pd.read_excel(file_path, sheet_name=sheet_name, dtype=str, na_filter=False)
                    
                    # ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                    if df.empty:
                        sheet_html = f'<div class="sheet-container"><h3 class="sheet-name">ì‹œíŠ¸: {sheet_name}</h3>'
                        sheet_html += '<p class="empty-sheet">ì´ ì‹œíŠ¸ì—ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.</p>'
                        sheet_html += '</div>'
                        all_sheets_html.append(sheet_html)
                        continue
                    
                    # í…Œì´ë¸” HTML ìƒì„± ì‹œ ì„¤ì •
                    sheet_html = f'<div class="sheet-container"><h3 class="sheet-name">ì‹œíŠ¸: {sheet_name}</h3>'
                    sheet_html += df.to_html(
                        index=False, 
                        classes='table table-striped table-bordered',
                        na_rep='', 
                        escape=False,  # HTML íƒœê·¸ í—ˆìš©
                        border=1
                    )
                    sheet_html += '</div>'
                    all_sheets_html.append(sheet_html)
                
                # ì›ë³¸ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µì„ ìœ„í•´ ì—‘ì…€ íŒŒì¼ base64 ì¸ì½”ë”©
                with open(file_path, 'rb') as excel:
                    excel_data = excel.read()
                    excel_base64 = base64.b64encode(excel_data).decode('utf-8')
                
                # ëª¨ë“  ì‹œíŠ¸ HTML í•©ì¹˜ê¸° (ë‹¤ìš´ë¡œë“œ ë§í¬ í¬í•¨)
                content = '<div class="excel-container">'
                content += f'''
                <div class="excel-download">
                    <a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{excel_base64}" 
                       download="{original_filename}" class="excel-download-btn">
                        ì›ë³¸ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                    </a>
                </div>
                '''
                content += ''.join(all_sheets_html)
                content += '</div>'
            except Exception as e:
                print(f"Excel íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return jsonify({
                    'status': 'error',
                    'message': f'ì—‘ì…€ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
                }), 500
        
        # Word íŒŒì¼ ì²˜ë¦¬
        elif file_extension == 'docx':
            try:
                from docx import Document
                doc = Document(file_path)
                # ë¬¸ì„œì˜ ëª¨ë“  ë‹¨ë½ì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
                paragraphs = [p.text for p in doc.paragraphs]
                content = "\n\n".join(paragraphs)
            except Exception as e:
                return jsonify({
                    'status': 'error',
                    'message': f'Word ë¬¸ì„œë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
                }), 500
        
        # ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹
        else:
            return jsonify({
                'status': 'error',
                'message': f'ì´ íŒŒì¼ í˜•ì‹({file_extension})ì€ ë‚´ìš© ì¡°íšŒë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.'
            }), 400
        
        return jsonify({
            'status': 'success',
            'filename': original_filename,
            'content': content,
            'file_type': file_extension
        })
    
    except Exception as e:
        print(f"Error viewing document: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'ë¬¸ì„œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500

# ì´ì „ í¸ì§‘ ê¸°ëŠ¥ ë¹„í™œì„±í™” ì½”ë“œ (CSV í¸ì§‘ ê¸°ëŠ¥ìœ¼ë¡œ ëŒ€ì²´ë¨)
# @app.route('/api/documents/edit/<path:system_filename>', methods=['POST'])
# def edit_document_disabled(system_filename):
#     """ë¬¸ì„œ ë‚´ìš© í¸ì§‘ API - ìš”ì²­ì— ë”°ë¼ ë¹„í™œì„±í™”ë¨"""
#     return jsonify({
#         'status': 'error',
#         'message': 'í¸ì§‘ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ëª¨ë“  ë¬¸ì„œëŠ” ì½ê¸° ì „ìš©ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤.'
#     }), 403
        
@app.route('/api/upload-chunk', methods=['POST'])
def upload_chunk():
    """
    ì²­í¬ ë‹¨ìœ„ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ API
    ì „ì†¡ ë°ì´í„° í˜•ì‹: 
    - filename: ì›ë³¸ íŒŒì¼ëª…
    - chunkIndex: í˜„ì¬ ì²­í¬ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)
    - totalChunks: ì „ì²´ ì²­í¬ ìˆ˜
    - chunkData: ì²­í¬ ë°ì´í„° (íŒŒì¼)
    - sessionId: ì„¸ì…˜ ID (ì²« ë²ˆì§¸ ì²­í¬ ì´í›„ë¶€í„° ì‚¬ìš©)
    """
    # íŒŒë¼ë¯¸í„° ê²€ì¦
    if 'chunkData' not in request.files:
        return jsonify({
            'success': False, 
            'error': 'ì²­í¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'
        }), 400
        
    if not request.form.get('filename'):
        return jsonify({
            'success': False, 
            'error': 'íŒŒì¼ëª…ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
        }), 400
    
    # ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ
    filename = request.form.get('filename')
    chunk_index = int(request.form.get('chunkIndex', 0))
    total_chunks = int(request.form.get('totalChunks', 1))
    chunk_file = request.files['chunkData']
    
    # íŒŒì¼ëª… ë³´ì•ˆ ì²˜ë¦¬
    if not filename:
        return jsonify({
            'success': False, 
            'error': 'ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ëª…ì…ë‹ˆë‹¤.'
        }), 400
    # í•œê¸€ì„ ë³´ì¡´í•˜ëŠ” íŒŒì¼ëª… ìƒì„±
    safe_filename = get_clean_filename(str(filename))
        
    # íŒŒì¼ í™•ì¥ì í™•ì¸
    if not allowed_file(safe_filename):
        return jsonify({
            'success': False, 
            'error': 'ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.'
        }), 400
    
    # ì„¸ì…˜ ID ì²˜ë¦¬
    session_id = request.form.get('sessionId')
    if chunk_index == 0 and not session_id:
        session_id = str(uuid.uuid4())
    
    # ì‘ë‹µ ë°ì´í„° ì¤€ë¹„
    response_data = {
        'success': True,
        'sessionId': session_id,
        'chunkIndex': chunk_index,
        'totalChunks': total_chunks,
        'received': True
    }
    
    try:
        # ì²­í¬ ì €ì¥ ê²½ë¡œ
        chunk_filename = f"{session_id}_{safe_filename}.part{chunk_index}"
        chunk_path = os.path.join(app.config['TEMP_CHUNK_FOLDER'], chunk_filename)
        
        # ì²­í¬ íŒŒì¼ ì €ì¥
        chunk_file.save(chunk_path)
        print(f"Saved chunk {chunk_index+1}/{total_chunks} for file {safe_filename}")
        
        # ë§ˆì§€ë§‰ ì²­í¬ì¸ ê²½ìš° ëª¨ë“  ì²­í¬ë¥¼ í•©ì³ì„œ ìµœì¢… íŒŒì¼ ìƒì„±
        if chunk_index == total_chunks - 1:
            # ìµœì¢… íŒŒì¼ëª… ë° ê²½ë¡œ
            final_unique_filename = f"{session_id}_{safe_filename}"
            final_path = os.path.join(app.config['UPLOAD_FOLDER'], final_unique_filename)
            print(f"Combining chunks for {safe_filename} to {final_unique_filename}")
            
            # ì²­í¬ í•©ì¹˜ê¸°
            with open(final_path, 'wb') as final_file:
                for i in range(total_chunks):
                    part_filename = f"{session_id}_{safe_filename}.part{i}"
                    part_path = os.path.join(app.config['TEMP_CHUNK_FOLDER'], part_filename)
                    
                    if os.path.exists(part_path):
                        with open(part_path, 'rb') as part_file:
                            final_file.write(part_file.read())
                        
                        # ì²­í¬ íŒŒì¼ ì‚­ì œ
                        os.remove(part_path)
                        print(f"Removed temporary chunk file: {part_filename}")
            
            # ë¬¸ì„œ ì²˜ë¦¬ ë° ë²¡í„° DBì— ì¶”ê°€
            try:
                print(f"Processing document: {final_path}")
                
                # CSV ë˜ëŠ” Excel íŒŒì¼ì¸ ê²½ìš° ìë™ ì „ì²˜ë¦¬ ìˆ˜í–‰
                file_extension = Path(final_path).suffix.lower()
                processed_file_path = final_path
                
                if file_extension in ['.csv', '.xlsx', '.xls']:
                    # ìë™ ì „ì²˜ë¦¬ ëª¨ë“ˆ ì„í¬íŠ¸
                    from auto_processor import auto_process_file
                    
                    # ì „ì²˜ë¦¬ ìˆ˜í–‰
                    success, processed_path = auto_process_file(final_path)
                    if success and processed_path:
                        print(f"ìë™ ì „ì²˜ë¦¬ ì™„ë£Œ: {final_path} -> {processed_path}")
                        processed_file_path = processed_path
                        response_data['auto_processed'] = True
                    else:
                        print(f"ìë™ ì „ì²˜ë¦¬ ì‹¤íŒ¨, ì›ë³¸ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: {final_path}")
                        response_data['auto_processed'] = False
                
                # ë¬¸ì„œ ì²˜ë¦¬ (ì›ë³¸ ë˜ëŠ” ì „ì²˜ë¦¬ëœ íŒŒì¼)
                chunks = document_processor.process_document(processed_file_path)
                
                # ë²¡í„° DBì— ì²­í¬ ì¶”ê°€
                if chunks:
                    print(f"ë²¡í„° DBì— {len(chunks)}ê°œ ì²­í¬ ì €ì¥ ì¤‘...")
                    database.add_document_embeddings(chunks)
                    print(f"ë²¡í„° DBì— {len(chunks)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ: {safe_filename}")
                
                # íŒŒì¼ ì™„ì„± ì •ë³´ ì¶”ê°€
                response_data['fileComplete'] = True
                response_data['finalFilename'] = safe_filename
                response_data['size'] = os.path.getsize(processed_file_path)
                response_data['doc_id'] = chunks[0]['doc_id'] if chunks else None
                response_data['chunk_count'] = len(chunks) if chunks else 0
                print(f"File upload and processing complete for {safe_filename}")
                
            except Exception as e:
                print(f"Error processing file {safe_filename}: {str(e)}")
                response_data['processingError'] = str(e)
        
        return jsonify(response_data)
    
    except Exception as e:
        print(f"Error in chunk upload: {str(e)}")
        # ì„ì‹œ ì²­í¬ íŒŒì¼ ì •ë¦¬ ì‹œë„
        try:
            for i in range(total_chunks):
                part_filename = f"{session_id}_{safe_filename}.part{i}"
                part_path = os.path.join(app.config['TEMP_CHUNK_FOLDER'], part_filename)
                if os.path.exists(part_path):
                    os.remove(part_path)
        except:
            pass
            
        return jsonify({
            'success': False,
            'error': f'ì²­í¬ ì—…ë¡œë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}'
        }), 500

@app.route('/api/delete', methods=['POST'])
def delete_file():
    """ì—…ë¡œë“œëœ íŒŒì¼ ì‚­ì œ"""
    try:
        # ìš”ì²­ ë°ì´í„° ë¡œê¹…
        data = request.get_json()
        print(f"Delete request received with data: {data}")
        
        # ì‹œìŠ¤í…œ íŒŒì¼ëª… ê°€ì ¸ì˜¤ê¸°
        system_filename = data.get('system_filename')
        
        if not system_filename:
            print("Error: No system_filename provided in request")
            return jsonify({'success': False, 'error': 'íŒŒì¼ëª…ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 400
            
        print(f"Processing delete request for file: {system_filename}")
            
        # íŒŒì¼ ê²½ë¡œ í™•ì¸
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], system_filename)
        print(f"File path to delete: {file_path}")
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(file_path) or not os.path.isfile(file_path):
            print(f"File not found: {file_path}")
            return jsonify({'success': False, 'error': 'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
        
        # ì—…ë¡œë“œ í´ë” ìƒíƒœ í™•ì¸
        print("Current files in upload folder:")
        for f in os.listdir(app.config['UPLOAD_FOLDER']):
            print(f" - {f}")
            
        # íŒŒì¼ ì‚­ì œ
        os.remove(file_path)
        print(f"File removed: {file_path}")
        
        # ë²¡í„° DBì—ì„œ í•´ë‹¹ ë¬¸ì„œ ê´€ë ¨ ë°ì´í„° ì‚­ì œ
        # íŒŒì¼ëª…ì—ì„œ UUID ì¶”ì¶œ
        try:
            file_uuid = system_filename.split('_')[0]
            print(f"Extracted UUID: {file_uuid}")
            database.delete_document(file_uuid)
            print(f"Document deleted from vector database with ID: {file_uuid}")
        except Exception as db_err:
            print(f"DB ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(db_err)}")
            # DB ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  íŒŒì¼ ì‚­ì œ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
            
        return jsonify({'success': True, 'message': f'íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.'})
        
    except Exception as e:
        error_msg = str(e)
        print(f"Error deleting file: {error_msg}")
        return jsonify({'success': False, 'error': error_msg}), 500

# ë¬¸ì˜í•˜ê¸° ê²Œì‹œíŒ ë¼ìš°íŠ¸
@app.route('/inquiry')
def inquiry_list():
    page = request.args.get('page', 1, type=int)
    board = InquiryBoard()
    pagination = board.get_posts(page=page, per_page=10)
    
    # í…œí”Œë¦¿ ë³€ìˆ˜ ì„¤ì •
    template_args = {
        'posts': pagination['posts'],
        'pagination': {
            'page': pagination['page'],
            'per_page': pagination['per_page'],
            'pages': pagination['pages'],
            'total': pagination['total'],
            'has_prev': pagination['page'] > 1,
            'has_next': pagination['page'] < pagination['pages'],
            'prev_num': pagination['page'] - 1,
            'next_num': pagination['page'] + 1,
            'iter_pages': lambda: range(1, pagination['pages'] + 1)
        },
        'board_page_title': 'ë¬¸ì˜í•˜ê¸°',
        'board_title': 'ë¬¸ì˜í•˜ê¸°',
        'board_description': 'ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ë¬¸ì˜ì‚¬í•­ì„ ë“±ë¡í•˜ê³  ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆëŠ” ê²Œì‹œíŒì…ë‹ˆë‹¤.',
        'list_route': 'inquiry_list',
        'write_route': 'inquiry_write',
        'view_route': 'inquiry_view',
        'edit_route': 'inquiry_edit',
        'board_type': 'inquiry'
    }
    
    return render_template('board_template.html', **template_args)

@app.route('/inquiry/write', methods=['GET', 'POST'])
def inquiry_write():
    if request.method == 'POST':
        title = request.form.get('title')
        content = request.form.get('content')
        author = request.form.get('author')
        
        if not title or not content or not author:
            return "ì œëª©, ë‚´ìš©, ì‘ì„±ìëŠ” í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤.", 400
            
        board = InquiryBoard()
        post_id = board.create_post(title, content, author)
        
        return redirect(url_for('inquiry_view', post_id=post_id))
    
    return render_template('write_post.html', board_title='ë¬¸ì˜í•˜ê¸°', list_route='inquiry_list', write_route='inquiry_write')

@app.route('/inquiry/view/<int:post_id>')
def inquiry_view(post_id):
    board = InquiryBoard()
    post = board.get_post(post_id)
    
    if not post:
        abort(404)
        
    return render_template('view_post.html', post=post, board_title='ë¬¸ì˜í•˜ê¸°', list_route='inquiry_list', edit_route='inquiry_edit', board_type='inquiry')

@app.route('/inquiry/edit/<int:post_id>', methods=['GET', 'POST'])
def inquiry_edit(post_id):
    board = InquiryBoard()
    post = board.get_post(post_id)
    
    if not post:
        abort(404)
    
    if request.method == 'POST':
        title = request.form.get('title')
        content = request.form.get('content')
        author = request.form.get('author')
        
        if not title or not content or not author:
            return "ì œëª©, ë‚´ìš©, ì‘ì„±ìëŠ” í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤.", 400
            
        board.update_post(post_id, title, content, author)
        return redirect(url_for('inquiry_view', post_id=post_id))
    
    return render_template('write_post.html', post=post, board_title='ë¬¸ì˜í•˜ê¸°', 
                          list_route='inquiry_list', write_route='inquiry_edit', 
                          is_edit=True)

# ë¬¸ì˜í•˜ê¸° ê²Œì‹œê¸€ ì‚­ì œ API
@app.route('/inquiry/delete/<int:post_id>', methods=['POST'])
def inquiry_delete(post_id):
    try:
        board = InquiryBoard()
        # í•´ë‹¹ ê²Œì‹œê¸€ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        post = board.get_post(post_id)
        if not post:
            return jsonify({'success': False, 'error': 'ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
        
        # ê²Œì‹œê¸€ ì‚­ì œ
        board.delete_post(post_id)
        return jsonify({'success': True, 'message': 'ê²Œì‹œê¸€ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

# í”¼ë“œë°± ê²Œì‹œíŒ ë¼ìš°íŠ¸
@app.route('/feedback')
def feedback_list():
    page = request.args.get('page', 1, type=int)
    board = FeedbackBoard()
    pagination = board.get_posts(page=page, per_page=10)
    
    # í…œí”Œë¦¿ ë³€ìˆ˜ ì„¤ì •
    template_args = {
        'posts': pagination['posts'],
        'pagination': {
            'page': pagination['page'],
            'per_page': pagination['per_page'],
            'pages': pagination['pages'],
            'total': pagination['total'],
            'has_prev': pagination['page'] > 1,
            'has_next': pagination['page'] < pagination['pages'],
            'prev_num': pagination['page'] - 1,
            'next_num': pagination['page'] + 1,
            'iter_pages': lambda: range(1, pagination['pages'] + 1)
        },
        'board_page_title': 'í”¼ë“œë°±',
        'board_title': 'í”¼ë“œë°±',
        'board_description': 'SHB-NetBot ì„œë¹„ìŠ¤ ê°œì„ ì„ ìœ„í•œ ì˜ê²¬ì´ë‚˜ ì œì•ˆì„ ë“±ë¡í•´ ì£¼ì„¸ìš”.',
        'list_route': 'feedback_list',
        'write_route': 'feedback_write',
        'view_route': 'feedback_view',
        'edit_route': 'feedback_edit',
        'board_type': 'feedback'
    }
    
    return render_template('board_template.html', **template_args)

@app.route('/feedback/write', methods=['GET', 'POST'])
def feedback_write():
    if request.method == 'POST':
        title = request.form.get('title')
        content = request.form.get('content')
        author = request.form.get('author')
        
        if not title or not content or not author:
            return "ì œëª©, ë‚´ìš©, ì‘ì„±ìëŠ” í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤.", 400
            
        board = FeedbackBoard()
        post_id = board.create_post(title, content, author)
        
        return redirect(url_for('feedback_view', post_id=post_id))
    
    return render_template('write_post.html', board_title='í”¼ë“œë°±', list_route='feedback_list', write_route='feedback_write')

@app.route('/feedback/view/<int:post_id>')
def feedback_view(post_id):
    board = FeedbackBoard()
    post = board.get_post(post_id)
    
    if not post:
        abort(404)
        
    return render_template('view_post.html', post=post, board_title='í”¼ë“œë°±', list_route='feedback_list', edit_route='feedback_edit', board_type='feedback')

@app.route('/feedback/edit/<int:post_id>', methods=['GET', 'POST'])
def feedback_edit(post_id):
    board = FeedbackBoard()
    post = board.get_post(post_id)
    
    if not post:
        abort(404)
    
    if request.method == 'POST':
        title = request.form.get('title')
        content = request.form.get('content')
        author = request.form.get('author')
        
        if not title or not content or not author:
            return "ì œëª©, ë‚´ìš©, ì‘ì„±ìëŠ” í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤.", 400
            
        board.update_post(post_id, title, content, author)
        return redirect(url_for('feedback_view', post_id=post_id))
    
    return render_template('write_post.html', post=post, board_title='í”¼ë“œë°±', 
                          list_route='feedback_list', write_route='feedback_edit', 
                          is_edit=True)

# í”¼ë“œë°± ê²Œì‹œê¸€ ì‚­ì œ API
@app.route('/feedback/delete/<int:post_id>', methods=['POST'])
def feedback_delete(post_id):
    try:
        board = FeedbackBoard()
        # í•´ë‹¹ ê²Œì‹œê¸€ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        post = board.get_post(post_id)
        if not post:
            return jsonify({'success': False, 'error': 'ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
        
        # ê²Œì‹œê¸€ ì‚­ì œ
        board.delete_post(post_id)
        return jsonify({'success': True, 'message': 'ê²Œì‹œê¸€ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

# ì¥ì•  ì‹ ê³  ê²Œì‹œíŒ ë¼ìš°íŠ¸
@app.route('/report')
def report_list():
    page = request.args.get('page', 1, type=int)
    board = ReportBoard()
    pagination = board.get_posts(page=page, per_page=10)
    
    # í…œí”Œë¦¿ ë³€ìˆ˜ ì„¤ì •
    template_args = {
        'posts': pagination['posts'],
        'pagination': {
            'page': pagination['page'],
            'per_page': pagination['per_page'],
            'pages': pagination['pages'],
            'total': pagination['total'],
            'has_prev': pagination['page'] > 1,
            'has_next': pagination['page'] < pagination['pages'],
            'prev_num': pagination['page'] - 1,
            'next_num': pagination['page'] + 1,
            'iter_pages': lambda: range(1, pagination['pages'] + 1)
        },
        'board_page_title': 'ì¥ì•  ì‹ ê³ ',
        'board_title': 'ì¥ì•  ì‹ ê³ ',
        'board_description': 'ë„¤íŠ¸ì›Œí¬ ì¥ì• ê°€ ë°œìƒí–ˆì„ ë•Œ ì‹ ì†í•˜ê²Œ ì‹ ê³ í•˜ì—¬ ë¹ ë¥¸ ì¡°ì¹˜ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        'list_route': 'report_list',
        'write_route': 'report_write',
        'view_route': 'report_view',
        'edit_route': 'report_edit',
        'board_type': 'report'
    }
    
    return render_template('board_template.html', **template_args)

@app.route('/report/write', methods=['GET', 'POST'])
def report_write():
    if request.method == 'POST':
        title = request.form.get('title')
        content = request.form.get('content')
        author = request.form.get('author')
        
        if not title or not content or not author:
            return "ì œëª©, ë‚´ìš©, ì‘ì„±ìëŠ” í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤.", 400
            
        board = ReportBoard()
        post_id = board.create_post(title, content, author)
        
        return redirect(url_for('report_view', post_id=post_id))
    
    return render_template('write_post.html', board_title='ì¥ì•  ì‹ ê³ ', list_route='report_list', write_route='report_write')

@app.route('/report/view/<int:post_id>')
def report_view(post_id):
    board = ReportBoard()
    post = board.get_post(post_id)
    
    if not post:
        abort(404)
        
    return render_template('view_post.html', post=post, board_title='ì¥ì•  ì‹ ê³ ', list_route='report_list', edit_route='report_edit', board_type='report')

@app.route('/report/edit/<int:post_id>', methods=['GET', 'POST'])
def report_edit(post_id):
    board = ReportBoard()
    post = board.get_post(post_id)
    
    if not post:
        abort(404)
    
    if request.method == 'POST':
        title = request.form.get('title')
        content = request.form.get('content')
        author = request.form.get('author')
        
        if not title or not content or not author:
            return "ì œëª©, ë‚´ìš©, ì‘ì„±ìëŠ” í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤.", 400
            
        board.update_post(post_id, title, content, author)
        return redirect(url_for('report_view', post_id=post_id))
    
    return render_template('write_post.html', post=post, board_title='ì¥ì•  ì‹ ê³ ', 
                          list_route='report_list', write_route='report_edit', 
                          is_edit=True)

# ì¥ì•  ì‹ ê³  ê²Œì‹œê¸€ ì‚­ì œ API
@app.route('/report/delete/<int:post_id>', methods=['POST'])
def report_delete(post_id):
    try:
        board = ReportBoard()
        # í•´ë‹¹ ê²Œì‹œê¸€ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        post = board.get_post(post_id)
        if not post:
            return jsonify({'success': False, 'error': 'ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
        
        # ê²Œì‹œê¸€ ì‚­ì œ
        board.delete_post(post_id)
        return jsonify({'success': True, 'message': 'ê²Œì‹œê¸€ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

# ë¬¸ì„œ ë™ê¸°í™” API
@app.route('/api/sync-documents', methods=['POST'])
def sync_documents():
    """
    ì—…ë¡œë“œëœ ë¬¸ì„œì™€ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë™ê¸°í™”
    - íŒŒì¼ ì‹œìŠ¤í…œì˜ ë¬¸ì„œê°€ ë²¡í„° DBì— ì—†ìœ¼ë©´ ì¶”ê°€
    - íŒŒì¼ ìˆ˜ì • ì‹œê°„ì´ ë³€ê²½ëœ ë¬¸ì„œëŠ” ë‹¤ì‹œ ì²˜ë¦¬
    """
    try:
        def generate_progress():
            """ì§„í–‰ ìƒí™©ì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ì œë„ˆë ˆì´í„° í•¨ìˆ˜"""
            
            yield global_json.dumps({
                'progress': 0,
                'message': 'ë¬¸ì„œ ë™ê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...'
            }) + '\n'
            
            # 1. í˜„ì¬ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
            files = []
            try:
                file_list = os.listdir(app.config['UPLOAD_FOLDER'])
                
                for filename in file_list:
                    if filename.startswith('.'):  # ìˆ¨ê¹€ íŒŒì¼ ì œì™¸
                        continue
                        
                    file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                    if os.path.isfile(file_path):
                        file_stats = os.stat(file_path)
                        
                        # ì‹œìŠ¤í…œ íŒŒì¼ëª…ì—ì„œ UUID ì¶”ì¶œ (ë¬¸ì„œ IDë¡œ ì‚¬ìš©)
                        doc_id = filename.split('_')[0] if '_' in filename else filename
                        
                        # ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ
                        original_filename = "_".join(filename.split("_")[1:])
                        
                        files.append({
                            'system_filename': filename,
                            'display_filename': original_filename,
                            'file_path': file_path,
                            'doc_id': doc_id,
                            'modified_time': file_stats.st_mtime
                        })
                
                yield global_json.dumps({
                    'progress': 10,
                    'message': f'{len(files)}ê°œ ë¬¸ì„œë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.'
                }) + '\n'
                
            except Exception as e:
                print(f"íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
                yield global_json.dumps({
                    'progress': 10,
                    'message': f'íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}'
                }) + '\n'
                return
            
            if not files:
                yield global_json.dumps({
                    'progress': 100,
                    'message': 'ë™ê¸°í™”í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.'
                }) + '\n'
                return
            
            # 2. ê° íŒŒì¼ ë™ê¸°í™” ì²˜ë¦¬
            total_files = len(files)
            processed_files = 0
            
            # ë™ê¸°í™” ì „ì— ë°ì´í„°ë² ì´ìŠ¤ í˜„ì¬ ìƒíƒœ ì €ì¥
            db_status_before = database.get_database_status()
            sync_needed = False
            
            # ë¹ ë¥¸ ê²€ì‚¬: ì´ë¯¸ ëª¨ë“  íŒŒì¼ì´ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
            # ë¬¸ì„œ ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            existing_doc_ids = database.get_all_document_ids()
            
            # 1. íŒŒì¼ ì‹œìŠ¤í…œê³¼ ë²¡í„° DB ë™ê¸°í™” ì²´í¬
            # í˜„ì¬ íŒŒì¼ ì‹œìŠ¤í…œì— ìˆëŠ” ë¬¸ì„œ ID ëª©ë¡
            filesystem_doc_ids = set(file_info['doc_id'] for file_info in files)
            
            # ë²¡í„° DBì—ëŠ” ìˆì§€ë§Œ íŒŒì¼ ì‹œìŠ¤í…œì—ëŠ” ì—†ëŠ” ë¬¸ì„œ ID ì°¾ê¸°
            orphaned_doc_ids = existing_doc_ids - filesystem_doc_ids
            
            # ë” ì´ìƒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¬¸ì„œì˜ ì„ë² ë”© ì œê±°
            if orphaned_doc_ids:
                orphaned_count = len(orphaned_doc_ids)
                yield global_json.dumps({
                    'progress': 5,
                    'message': f'ğŸ” íŒŒì¼ ì‹œìŠ¤í…œì— ë” ì´ìƒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” {orphaned_count}ê°œì˜ ë¬¸ì„œ ë°ì´í„° ì •ë¦¬ ì¤‘...'
                }) + '\n'
                
                # ê° ê³ ì•„ ë¬¸ì„œ ì œê±°
                removed_count = 0
                for doc_id in orphaned_doc_ids:
                    if database.delete_document(doc_id):
                        removed_count += 1
                
                yield global_json.dumps({
                    'progress': 10,
                    'message': f'âœ… ì‚­ì œëœ ë¬¸ì„œ {removed_count}ê°œì˜ ì •ë³´ê°€ ë²¡í„° DBì—ì„œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì •ë³´ëŠ” ë” ì´ìƒ ì±—ë´‡ ì‘ë‹µì— ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.'
                }) + '\n'
            
            # 2. ìƒˆë¡œìš´ ë¬¸ì„œ ì²˜ë¦¬
            files_to_process = []
            
            # ì²˜ë¦¬ê°€ í•„ìš”í•œ íŒŒì¼ë§Œ í•„í„°ë§
            for file_info in files:
                doc_id = file_info['doc_id']
                if doc_id not in existing_doc_ids:
                    files_to_process.append(file_info)
            
            # ìƒˆë¡­ê²Œ ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ê³  ì‚­ì œëœ íŒŒì¼ë„ ì—†ìœ¼ë©´ ë™ê¸°í™” í•„ìš” ì—†ìŒ
            if not files_to_process and not orphaned_doc_ids:
                yield global_json.dumps({
                    'progress': 100,
                    'message': f'ğŸ›ˆ ë™ê¸°í™”í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ëª¨ë“  íŒŒì¼ì€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.'
                }) + '\n'
                return
            
            # ìƒˆë¡­ê²Œ ì²˜ë¦¬ê°€ í•„ìš”í•œ íŒŒì¼ë¡œ ëª©ë¡ ê°±ì‹ 
            if files_to_process:
                files = files_to_process
                total_files = len(files)
            else:
                yield global_json.dumps({
                    'progress': 100,
                    'message': f'ğŸ›ˆ ìƒˆë¡­ê²Œ ì¶”ê°€í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì‚­ì œëœ ë¬¸ì„œ ì •ë³´ ì •ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'
                }) + '\n'
                return
            
            for file_info in files:
                try:
                    file_path = file_info['file_path']
                    doc_id = file_info['doc_id']
                    display_filename = file_info['display_filename']
                    
                    # í˜„ì¬ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘ ë©”ì‹œì§€
                    current_progress = 10 + int((processed_files / total_files) * 80)
                    yield global_json.dumps({
                        'progress': current_progress,
                        'message': f'({processed_files+1}/{total_files}) {display_filename} ë™ê¸°í™” ì¤‘...'
                    }) + '\n'
                    
                    # ë¬¸ì„œ ì²˜ë¦¬ ë° ë²¡í„° DB ì—…ë°ì´íŠ¸
                    if allowed_file(display_filename):
                        # ê¸°ì¡´ ë¬¸ì„œ IDë¡œ ë¨¼ì € ì‚­ì œ (ë¬¸ì„œ ì—…ë°ì´íŠ¸ íš¨ê³¼)
                        deleted = database.delete_document(doc_id)
                        
                        # íŠ¹ë³„íˆ Excel íŒŒì¼ ì²˜ë¦¬ (íŒŒì¼ëª… ë³€ê²½ì—ë„ ë§¤í•‘ ìœ ì§€)
                        # "ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ" ë˜ëŠ” "ì—…ë¬´ì•ˆë‚´" ë“±ì˜ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì—‘ì…€ íŒŒì¼ ì‹ë³„
                        # ì¼ìë³„ íŒŒì¼ ì—…ë°ì´íŠ¸ í˜•ì‹ë„ ìë™ ì¸ì‹ (ì˜ˆ: ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ_2025.05.19.xlsx)
                        excel_procedure_file = False
                        excel_date_pattern = re.search(r'_(\d{4}[.ë…„\-_]\d{1,2}[.ì›”\-_]\d{1,2})', display_filename)
                        file_date = excel_date_pattern.group(1) if excel_date_pattern else "ìµœì‹ "
                        
                        if display_filename.lower().endswith(('.xlsx', '.xls')):
                            # ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ íŒŒì¼ íŒ¨í„´ ì²´í¬ (ë‚ ì§œ í˜•ì‹ì´ í¬í•¨ëœ ë²„ì „ë„ ì¸ì‹)
                            guide_keywords = ['ì—…ë¬´ ì•ˆë‚´', 'ì—…ë¬´_ì•ˆë‚´', 'ì—…ë¬´ì•ˆë‚´', 'ê°€ì´ë“œ', 'ë§¤ë‰´ì–¼', 'ì ˆì°¨']
                            
                            if any(keyword in display_filename for keyword in guide_keywords):
                                excel_procedure_file = True
                                yield global_json.dumps({
                                    'progress': current_progress,
                                    'message': f'âœ¨ {display_filename} - ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ íŒŒì¼ë¡œ ì¸ì‹ë˜ì—ˆìŠµë‹ˆë‹¤. ì ˆì°¨ ì•ˆë‚´ ì‹œíŠ¸ë¥¼ ì„¸ë¶€ í•­ëª©ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤. (ë²„ì „: {file_date})'
                                }) + '\n'
                            
                        # ë¬¸ì„œ ì²˜ë¦¬
                        chunks = document_processor.process_document(file_path)
                        
                        # ì²­í¬ê°€ ì—†ìœ¼ë©´ ë‹¤ìŒ íŒŒì¼ë¡œ
                        if not chunks:
                            yield global_json.dumps({
                                'progress': current_progress + 5,
                                'message': f'{display_filename} ì²˜ë¦¬ ì¤‘ ì²­í¬ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                            }) + '\n'
                            processed_files += 1
                            continue
                        
                        # ë¬¸ì„œ ID ì„¤ì •
                        for chunk in chunks:
                            chunk['doc_id'] = doc_id
                        
                        # ë²¡í„° DBì— ì €ì¥
                        added = database.add_document_embeddings(chunks)
                        
                        # ë™ê¸°í™”ê°€ ì‹¤ì œë¡œ ì´ë£¨ì–´ì¡ŒëŠ”ì§€ í™•ì¸
                        if deleted or added:
                            sync_needed = True
                        
                        yield global_json.dumps({
                            'progress': current_progress + 5,
                            'message': f'{display_filename} ì²˜ë¦¬ ì™„ë£Œ (ì²­í¬ {len(chunks)}ê°œ)'
                        }) + '\n'
                    else:
                        yield global_json.dumps({
                            'progress': current_progress,
                            'message': f'{display_filename}ì€ ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.'
                        }) + '\n'
                    
                except Exception as e:
                    error_filename = file_info.get('display_filename', 'ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼')
                    error_progress = 10 + int((processed_files / total_files) * 80)
                    print(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({error_filename}): {str(e)}")
                    yield global_json.dumps({
                        'progress': error_progress,
                        'message': f'{error_filename} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
                    }) + '\n'
                
                processed_files += 1
            
            # 3. ì™„ë£Œ ë©”ì‹œì§€
            db_status = database.get_database_status()
            
            if not sync_needed:
                yield global_json.dumps({
                    'progress': 100,
                    'message': f'ğŸ›ˆ ë™ê¸°í™”í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ëª¨ë“  íŒŒì¼ì€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.'
                }) + '\n'
            else:
                yield global_json.dumps({
                    'progress': 100,
                    'message': f'ë™ê¸°í™” ì™„ë£Œ! í˜„ì¬ ë¬¸ì„œ {db_status.get("document_count", 0)}ê°œ, ì²­í¬ {db_status.get("chunk_count", 0)}ê°œ'
                }) + '\n'
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°˜í™˜
        return app.response_class(generate_progress(), mimetype='text/event-stream')
    
    except Exception as e:
        print(f"ë¬¸ì„œ ë™ê¸°í™” ì˜¤ë¥˜: {str(e)}")
        return jsonify({'error': str(e)}), 500

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” í›„ ì•± ì‹¤í–‰
if __name__ == '__main__':
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    init_db()
    
    # Replitì—ì„œëŠ” í¬íŠ¸ê°€ í™˜ê²½ë³€ìˆ˜ë¡œ ì œê³µë©ë‹ˆë‹¤
    port = int(os.environ.get("PORT", 5000))
    app.run(host='0.0.0.0', port=port, debug=False)