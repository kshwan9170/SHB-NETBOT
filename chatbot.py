import os
from typing import List, Dict, Any, Optional, Tuple
import json
import openai
import re
import pandas as pd
from pathlib import Path
from openai import OpenAI
from database import search_similar_docs

# Import configuration
from config import FAQ_KEYWORDS, FINE_TUNED_MODEL, RAG_SYSTEM

# Initialize OpenAI client
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# ì—…ë¡œë“œëœ íŒŒì¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ
UPLOAD_FOLDER = 'uploaded_files'

def detect_language(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.
    
    Args:
        text: ê°ì§€í•  í…ìŠ¤íŠ¸
    
    Returns:
        ì–¸ì–´ ì½”ë“œ ('ko' ë˜ëŠ” 'en')
    """
    # í•œê¸€ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if re.search(r'[ê°€-í£]', text):
        return 'ko'
    else:
        return 'en'

def retrieve_relevant_documents(query: str, top_k: int = 5) -> Tuple[List[Any], str]:
    """
    ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        top_k: ê²€ìƒ‰í•  ìƒìœ„ ë¬¸ì„œ ìˆ˜
        
    Returns:
        (ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸, ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´) íŠœí”Œ
    """
    try:
        # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„)
        keywords = extract_keywords_from_query(query)
        print(f"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
        
        # ì ˆì°¨ ê°€ì´ë“œ ì „ìš© ê²€ìƒ‰ì„ ìœ„í•œ í•„í„°ë§
        procedure_guide_filter = None
        
        # íŠ¹ì • ë²„ì „ì˜ ê°€ì´ë“œë¥¼ ìš”ì²­í•˜ëŠ”ì§€ í™•ì¸ (ì˜ˆ: "2025ë…„ 5ì›” 19ì¼ ì—…ë¬´ ê°€ì´ë“œì—ì„œ...")
        version_pattern = re.search(r'(\d{4}[.ë…„\-_]\s?\d{1,2}[.ì›”\-_]\s?\d{1,2})', query)
        guide_version = None
        
        if version_pattern:
            # ë²„ì „ ì •ë³´ ì¶”ì¶œ ë° ì •ê·œí™”
            raw_version = version_pattern.group(1)
            
            # ê³µë°± ì œê±°
            normalized_version = raw_version.replace(' ', '')
            
            # yyyyë…„mmì›”ddì¼ í˜•ì‹ -> yyyy.mm.dd í˜•ì‹ìœ¼ë¡œ ë³€í™˜ 
            normalized_version = re.sub(r'(\d{4})ë…„(\d{1,2})ì›”(\d{1,2})ì¼', r'\1.\2.\3', normalized_version)
            
            # yyyy-mm-dd í˜•ì‹ë„ ìœ ì§€ (ChromaDB ê²€ìƒ‰ì—ì„œëŠ” ì›ë³¸ í˜•ì‹ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
            guide_version = normalized_version
            
            print(f"íŠ¹ì • ë²„ì „ ê°€ì´ë“œ ìš”ì²­ ê°ì§€: {raw_version} -> {guide_version}")
        
        # ì ˆì°¨ ê°€ì´ë“œ í•„í„°ë§ ì ìš©
        if any(keyword in query for keyword in ['ì–´ë–»ê²Œ', 'ë°©ë²•', 'ì ˆì°¨', 'ì‹ ì²­', 'ì‹ ê·œ', 'ë³€ê²½']):
            procedure_guide_filter = {"content_type": "procedure_guide"}
            
            # íŠ¹ì • ë²„ì „ì´ ìš”ì²­ëœ ê²½ìš° í•´ë‹¹ ë²„ì „ìœ¼ë¡œ í•„í„°ë§ ì¶”ê°€
            if guide_version:
                procedure_guide_filter["guide_version"] = guide_version
            
            print(f"ì ˆì°¨ ê°€ì´ë“œ ìš°ì„  ê²€ìƒ‰ í™œì„±í™”ë¨ - í•„í„°: {procedure_guide_filter}")
        
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        docs = search_similar_docs(query, top_k=top_k, filter=procedure_guide_filter)
        
        # ê°€ì´ë“œ ë¬¸ì„œê°€ ì—†ê³  í•„í„°ê°€ ì ìš©ëœ ê²½ìš° ë‹¤ì‹œ í•„í„° ì—†ì´ ê²€ìƒ‰
        if (not docs or len(docs) == 0) and procedure_guide_filter:
            print("ì ˆì°¨ ê°€ì´ë“œì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í•´ ì „ì²´ ë¬¸ì„œì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤")
            docs = search_similar_docs(query, top_k=top_k)
        
        # ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ë¹ˆ ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜
        if not docs or len(docs) == 0:
            return [], ""
        
        # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
        context_str = "Context:\n"
        
        # ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ ë¬¸ì„œëŠ” íŠ¹ë³„í•œ í¬ë§·ìœ¼ë¡œ í‘œì‹œ
        for i, doc in enumerate(docs):
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì—…ë¬´ ê°€ì´ë“œ ì •ë³´ í™•ì¸
            metadata = getattr(doc, 'metadata', {})
            content_type = metadata.get('content_type', '')
            
            if content_type == 'procedure_guide':
                # ì—…ë¬´ ê°€ì´ë“œ í˜•ì‹ìœ¼ë¡œ í¬ë§· (ë²„ì „ ì •ë³´ í¬í•¨)
                guide_version = metadata.get('guide_version', 'latest')
                version_text = f" (ë²„ì „: {guide_version})" if guide_version != 'latest' else ""
                context_str += f"- ({i+1}) ì—…ë¬´ ì•ˆë‚´{version_text}: "
                
                # ì§ˆë¬¸ ì˜ˆì‹œì™€ ìƒì„¸ ì•ˆë‚´ ë¶€ë¶„ ê°•ì¡°
                if 'ì§ˆë¬¸ ì˜ˆì‹œ' in metadata:
                    context_str += f"[ì§ˆë¬¸: {metadata['ì§ˆë¬¸ ì˜ˆì‹œ']}] "
                
                if 'ìš”ì•½ ì‘ë‹µ' in metadata:
                    context_str += f"[ìš”ì•½: {metadata['ìš”ì•½ ì‘ë‹µ']}] "
                    
                if 'ìƒì„¸ ì•ˆë‚´' in metadata:
                    context_str += f"[ì•ˆë‚´: {metadata['ìƒì„¸ ì•ˆë‚´']}] "
                
                # ì¼ë°˜ ë‚´ìš©ë„ í¬í•¨
                context_str += f"\n  ì›ë³¸ë‚´ìš©: \"{doc.page_content}\"\n\n"
            else:
                # ì¼ë°˜ ë¬¸ì„œ í˜•ì‹ìœ¼ë¡œ í¬ë§·
                context_str += f"- ({i+1}) \"{doc.page_content}\"\n\n"
        
        return docs, context_str
    except Exception as e:
        print(f"ERROR: RAG pipeline failed during document retrieval: {str(e)}")
        return [], ""

# ì—‘ì…€ ì²˜ë¦¬ ê´€ë ¨ í•¨ìˆ˜ë“¤
def find_excel_files(search_keyword="ì—…ë¬´ ì ˆì°¨ ì•ˆë‚´ ê°€ì´ë“œ"):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ ì¤‘ ì—‘ì…€ íŒŒì¼ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        search_keyword: ê²€ìƒ‰í•  í‚¤ì›Œë“œ
        
    Returns:
        ì°¾ì€ ì—‘ì…€ íŒŒì¼ì˜ ê²½ë¡œ ëª©ë¡
    """
    excel_files = []
    
    # ì—…ë¡œë“œ í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(UPLOAD_FOLDER):
        print(f"ì—…ë¡œë“œ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {UPLOAD_FOLDER}")
        return excel_files
    
    # ì—…ë¡œë“œ í´ë” ë‚´ íŒŒì¼ ê²€ìƒ‰
    for filename in os.listdir(UPLOAD_FOLDER):
        if filename.endswith(('.xlsx', '.xls')):
            # í‚¤ì›Œë“œê°€ í¬í•¨ëœ íŒŒì¼ì¸ì§€ í™•ì¸
            if search_keyword.lower() in filename.lower():
                file_path = os.path.join(UPLOAD_FOLDER, filename)
                excel_files.append(file_path)
    
    # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ëª¨ë“  ì—‘ì…€ íŒŒì¼ ê²€ìƒ‰
    if not excel_files:
        for filename in os.listdir(UPLOAD_FOLDER):
            if filename.endswith(('.xlsx', '.xls')):
                file_path = os.path.join(UPLOAD_FOLDER, filename)
                excel_files.append(file_path)
    
    return excel_files

def get_sheet_names(excel_file):
    """
    ì—‘ì…€ íŒŒì¼ì˜ ì‹œíŠ¸ ì´ë¦„ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        excel_file: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì‹œíŠ¸ ì´ë¦„ ëª©ë¡
    """
    try:
        xls = pd.ExcelFile(excel_file)
        return xls.sheet_names
    except Exception as e:
        print(f"ì‹œíŠ¸ ì´ë¦„ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

def read_excel_sheet(excel_file, sheet_name):
    """
    ì—‘ì…€ íŒŒì¼ì˜ íŠ¹ì • ì‹œíŠ¸ë¥¼ DataFrameìœ¼ë¡œ ì½ì–´ì˜µë‹ˆë‹¤.
    
    Args:
        excel_file: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        sheet_name: ì‹œíŠ¸ ì´ë¦„
        
    Returns:
        pandas DataFrame
    """
    try:
        # ëª¨ë“  ì—´ì„ ë¬¸ìì—´ë¡œ ì²˜ë¦¬í•˜ì—¬ ë°ì´í„° ìœ ì‹¤ ë°©ì§€
        df = pd.read_excel(excel_file, sheet_name=sheet_name, dtype=str, na_filter=False)
        
        # NaN ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ëŒ€ì²´
        df = df.fillna('')
        
        return df
    except Exception as e:
        print(f"ì—‘ì…€ ì‹œíŠ¸ '{sheet_name}'ë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return pd.DataFrame()

def extract_keywords_from_query(query):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        
    Returns:
        ì¶”ì¶œëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    # ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ (ê³µë°± ê¸°ì¤€)
    basic_keywords = query.split()
    
    # OpenAIë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
    try:
        if OPENAI_API_KEY:
            messages = [
                {"role": "system", "content": "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. JSON í˜•ì‹ì˜ ë°°ì—´ë¡œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤."},
                {"role": "user", "content": f"ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ì¤‘ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”: {query}"}
            ]
            
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                temperature=0.3,
                max_tokens=150
            )
            
            content = response.choices[0].message.content
            
            # JSON ë¶€ë¶„ ì¶”ì¶œ ì‹œë„
            try:
                # JSON ë°°ì—´ì´ ì§ì ‘ ë°˜í™˜ëœ ê²½ìš°
                keywords = json.loads(content)
                if isinstance(keywords, list):
                    return keywords
            except:
                # í…ìŠ¤íŠ¸ì—ì„œ JSON ë°°ì—´ ì°¾ê¸° ì‹œë„
                match = re.search(r'\[(.*?)\]', content)
                if match:
                    try:
                        keywords = json.loads('[' + match.group(1) + ']')
                        if isinstance(keywords, list):
                            return keywords
                    except:
                        pass
                
                # ì¤„ë°”ê¿ˆì„ ê¸°ì¤€ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„
                if '\n' in content:
                    lines = content.split('\n')
                    keywords = []
                    for line in lines:
                        line = line.strip()
                        if line and not line.startswith(('â€¢', '-', '*', '1.', '2.')):
                            keywords.append(line)
                        elif line.startswith(('â€¢', '-', '*')):
                            keyword = line[1:].strip()
                            keywords.append(keyword)
                        elif re.match(r'^\d+\.', line):
                            keyword = re.sub(r'^\d+\.', '', line).strip()
                            keywords.append(keyword)
                    
                    if keywords:
                        return keywords
    except Exception as e:
        print(f"OpenAIë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # ê¸°ë³¸ í‚¤ì›Œë“œ ë°˜í™˜
    return basic_keywords

def find_relevant_rows(df, keywords):
    """
    í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ í–‰ì„ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        keywords: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ê´€ë ¨ í–‰ì˜ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
    """
    relevant_indices = []
    
    # ê° í–‰ì— ëŒ€í•´ í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
    for idx, row in df.iterrows():
        row_text = ' '.join(str(val).lower() for val in row.values)
        
        # í‚¤ì›Œë“œ ì¼ì¹˜ í™•ì¸
        match_score = 0
        for keyword in keywords:
            if keyword.lower() in row_text:
                match_score += 1
        
        if match_score > 0:
            # (ì¸ë±ìŠ¤, ë§¤ì¹­ ì ìˆ˜) í˜•íƒœë¡œ ì €ì¥
            relevant_indices.append((idx, match_score))
    
    # ë§¤ì¹­ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ì¸ë±ìŠ¤ë§Œ ì¶”ì¶œ
    if relevant_indices:
        relevant_indices.sort(key=lambda x: x[1], reverse=True)
        return [idx for idx, _ in relevant_indices]
    
    # ë§¤ì¹­ë˜ëŠ” ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì²˜ìŒ ëª‡ ê°œ í–‰ë§Œ ë°˜í™˜
    return list(range(min(5, len(df))))

def dataframe_to_text(df):
    """
    ë°ì´í„°í”„ë ˆì„ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        
    Returns:
        ë°ì´í„°í”„ë ˆì„ ë‚´ìš©ì„ í‘œí˜„í•œ ë¬¸ìì—´
    """
    # ë¹ˆ ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬
    if df.empty:
        return "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ë°ì´í„°í”„ë ˆì„ì˜ ì—´ ì´ë¦„ê³¼ ê°’ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    text_parts = []
    
    # í…Œì´ë¸” í—¤ë” ì¶”ê°€
    columns = ' | '.join(df.columns)
    text_parts.append(columns)
    text_parts.append('-' * len(columns))
    
    # ê° í–‰ ë°ì´í„° ì¶”ê°€
    for _, row in df.iterrows():
        row_text = ' | '.join(str(val) for val in row.values)
        text_parts.append(row_text)
    
    return '\n'.join(text_parts)

def format_reference_result(df, search_term):
    """
    ì¡°íšŒ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    
    Args:
        df: ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        search_term: ê²€ìƒ‰ì–´
        
    Returns:
        í¬ë§·íŒ…ëœ ê²°ê³¼ ë¬¸ìì—´
    """
    if df.empty:
        return f"'{search_term}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    md_table = []
    
    # í—¤ë” ì¶”ê°€
    headers = '| ' + ' | '.join(df.columns) + ' |'
    md_table.append(headers)
    
    # êµ¬ë¶„ì„  ì¶”ê°€
    separator = '| ' + ' | '.join(['---'] * len(df.columns)) + ' |'
    md_table.append(separator)
    
    # ë°ì´í„° í–‰ ì¶”ê°€
    for _, row in df.iterrows():
        row_values = '| ' + ' | '.join(str(val) for val in row.values) + ' |'
        md_table.append(row_values)
    
    result = '\n'.join(md_table)
    result = f"'{search_term}'ì— ëŒ€í•œ ì¡°íšŒ ê²°ê³¼:\n\n{result}"
    
    return result

def summarize_dataframe(df):
    """
    ë°ì´í„°í”„ë ˆì„ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        
    Returns:
        ìš”ì•½ ë¬¸ìì—´
    """
    if df.empty:
        return "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    md_table = []
    
    # í—¤ë” ì¶”ê°€
    headers = '| ' + ' | '.join(df.columns) + ' |'
    md_table.append(headers)
    
    # êµ¬ë¶„ì„  ì¶”ê°€
    separator = '| ' + ' | '.join(['---'] * len(df.columns)) + ' |'
    md_table.append(separator)
    
    # ë°ì´í„° í–‰ ì¶”ê°€ (ìµœëŒ€ 5ê°œ í–‰ë§Œ)
    for _, row in df.head(5).iterrows():
        row_values = '| ' + ' | '.join(str(val) for val in row.values) + ' |'
        md_table.append(row_values)
    
    result = '\n'.join(md_table)
    
    # í–‰ì´ ë” ìˆìœ¼ë©´ ë©”ì‹œì§€ ì¶”ê°€
    if len(df) > 5:
        result += f"\n\n(ì´ {len(df)}ê°œ ì¤‘ 5ê°œ ê²°ê³¼ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.)"
    
    return result

def process_excel_query(query):
    """
    ì—‘ì…€ ê¸°ë°˜ ì²˜ë¦¬ íë¦„ì— ë”°ë¼ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    1. ì „ì²´_ê´€ë¦¬_ì‹œíŠ¸ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì—…ë¬´ ìœ í˜•/í‚¤ì›Œë“œ íŒŒì•…
    2. ì—°ê²° ì‹œíŠ¸ë¡œ ì´ë™í•˜ì—¬ í•„ìš” ë°ì´í„° ì°¾ê¸°
    3. ì²˜ë¦¬ ë°©ì‹ì— ë§ê²Œ ì‘ë‹µ ìƒì„±
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        
    Returns:
        ì²˜ë¦¬ ê²°ê³¼ì™€ ì‘ë‹µ ë‚´ìš©ì„ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
    """
    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
    result = {
        "found": False,
        "response": "",
        "from_excel": True,
        "category": "",
        "sheet_used": "",
        "response_type": ""
    }
    
    # ì—‘ì…€ íŒŒì¼ ê²€ìƒ‰
    excel_files = find_excel_files()
    if not excel_files:
        result["response"] = "ì°¸ì¡°í•  ì—‘ì…€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        result["from_excel"] = False
        return result
    
    # ì²« ë²ˆì§¸ ì—‘ì…€ íŒŒì¼ ì‚¬ìš©
    excel_file = excel_files[0]
    print(f"ì—‘ì…€ íŒŒì¼ ì‚¬ìš©: {excel_file}")
    
    # ì‹œíŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    sheet_names = get_sheet_names(excel_file)
    if not sheet_names:
        result["response"] = "ì—‘ì…€ íŒŒì¼ì—ì„œ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        result["from_excel"] = False
        return result
    
    print(f"ì‹œíŠ¸ ëª©ë¡: {sheet_names}")
    
    # 1. ì „ì²´_ê´€ë¦¬_ì‹œíŠ¸ ê²€ìƒ‰
    main_sheet = None
    for sheet in sheet_names:
        if "ì „ì²´" in sheet and "ê´€ë¦¬" in sheet:
            main_sheet = sheet
            break
    
    # ì „ì²´ ê´€ë¦¬ ì‹œíŠ¸ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì‹œíŠ¸ ì‚¬ìš©
    if not main_sheet:
        main_sheet = sheet_names[0]
    
    print(f"ë©”ì¸ ì‹œíŠ¸ ì‚¬ìš©: {main_sheet}")
    
    # ì „ì²´ ê´€ë¦¬ ì‹œíŠ¸ ë°ì´í„° ì½ê¸°
    main_df = read_excel_sheet(excel_file, main_sheet)
    if main_df.empty:
        result["response"] = f"'{main_sheet}' ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        result["from_excel"] = False
        return result
    
    # ì „ì²´ ê´€ë¦¬ ì‹œíŠ¸ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš© ì°¾ê¸°
    matched_row = None
    target_sheet = None
    category = None
    response_type = "DB ì‘ë‹µ (ìì—°ì–´)"  # ê¸°ë³¸ ì‘ë‹µ ìœ í˜•
    
    # ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (OpenAI ì‚¬ìš©)
    query_keywords = extract_keywords_from_query(query)
    print(f"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {query_keywords}")
    
    # ê° í–‰ì„ í™•ì¸í•˜ë©° ë§¤ì¹­ë˜ëŠ” ë‚´ìš© ì°¾ê¸°
    for idx, row in main_df.iterrows():
        # í•„ìš”í•œ ì—´ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if 'êµ¬ë¶„' in main_df.columns and 'ì¹´í…Œê³ ë¦¬' in main_df.columns:
            row_category = str(row.get('êµ¬ë¶„', '')) + " " + str(row.get('ì¹´í…Œê³ ë¦¬', ''))
            keywords = []
            
            # í‚¤ì›Œë“œ ì—´ í™•ì¸
            for col in main_df.columns:
                if 'í‚¤ì›Œë“œ' in col or 'ê²€ìƒ‰ì–´' in col:
                    if row[col]:
                        keywords.extend(str(row[col]).split(','))
            
            # ì‹œíŠ¸ ì •ë³´ ì—´ í™•ì¸
            sheet_col = None
            for col in main_df.columns:
                if 'ì‹œíŠ¸' in col or 'ë§í¬' in col:
                    sheet_col = col
                    break
            
            # ìš”ì•½ ë‚´ìš© ì—´ í™•ì¸
            summary_col = None
            for col in main_df.columns:
                if 'ìš”ì•½' in col or 'ì„¤ëª…' in col:
                    summary_col = col
                    break
            
            # ì²˜ë¦¬ ë°©ì‹ ì—´ í™•ì¸
            response_type_col = None
            for col in main_df.columns:
                if 'ì²˜ë¦¬' in col or 'ë°©ì‹' in col:
                    response_type_col = col
                    break
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
            match_found = False
            for kw in query_keywords:
                if any(kw.lower() in keyword.lower() for keyword in keywords):
                    match_found = True
                    break
            
            if match_found:
                matched_row = row
                category = row_category
                
                # ì—°ê²° ì‹œíŠ¸ ì •ë³´ ì¶”ì¶œ
                if sheet_col and row[sheet_col]:
                    target_sheet_info = str(row[sheet_col])
                    # "XX ì‹œíŠ¸ ì°¸ì¡°" í˜•ì‹ì—ì„œ ì‹œíŠ¸ ì´ë¦„ ì¶”ì¶œ
                    sheet_match = re.search(r'([ê°€-í£A-Za-z0-9_]+)[\s_]ì‹œíŠ¸', target_sheet_info)
                    if sheet_match:
                        target_sheet = sheet_match.group(1)
                
                # ì²˜ë¦¬ ë°©ì‹ ì •ë³´ ì¶”ì¶œ
                if response_type_col and row[response_type_col]:
                    response_type = str(row[response_type_col])
                
                break
    
    # ë§¤ì¹­ë˜ëŠ” ë‚´ìš©ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
    if not matched_row or not target_sheet:
        # ì¼ë‹¨ ê¸°ë³¸ ì²˜ë¦¬ë¡œ ì „í™˜í•˜ê³  ì²« ë²ˆì§¸ ë‚´ìš© ì‹œíŠ¸ ì‚¬ìš©
        alternative_sheet = None
        for sheet in sheet_names:
            if "ì „ì²´" not in sheet and "ê´€ë¦¬" not in sheet and sheet != main_sheet:
                alternative_sheet = sheet
                break
        
        if alternative_sheet:
            target_sheet = alternative_sheet
            result["sheet_used"] = "ëŒ€ì²´ ì‹œíŠ¸ ì‚¬ìš©: " + target_sheet
        else:
            result["response"] = "ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            result["from_excel"] = False
            return result
    
    # 2. ì—°ê²° ì‹œíŠ¸ë¡œ ì´ë™í•˜ì—¬ í•„ìš” ë°ì´í„° ì°¾ê¸°
    # ì‹¤ì œ ì‹œíŠ¸ ì´ë¦„ ì°¾ê¸° (ë¶€ë¶„ ë§¤ì¹­)
    actual_sheet = None
    for sheet in sheet_names:
        if target_sheet in sheet:
            actual_sheet = sheet
            break
    
    if not actual_sheet:
        actual_sheet = target_sheet  # ì§ì ‘ ë§¤ì¹­ ì‹œë„
    
    print(f"ì—°ê²° ì‹œíŠ¸ ì‚¬ìš©: {actual_sheet}")
    
    # ì—°ê²° ì‹œíŠ¸ ë°ì´í„° ì½ê¸°
    sheet_df = read_excel_sheet(excel_file, actual_sheet)
    if sheet_df.empty:
        result["response"] = f"'{actual_sheet}' ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        result["from_excel"] = False
        return result
    
    # 3. ì²˜ë¦¬ ë°©ì‹ì— ë§ê²Œ ì‘ë‹µ ìƒì„±
    result["found"] = True
    result["category"] = category
    result["sheet_used"] = actual_sheet
    result["response_type"] = response_type
    
    # ì²˜ë¦¬ ë°©ì‹ì— ë”°ë¥¸ ë¶„ê¸° ì²˜ë¦¬
    if "ìì—°ì–´" in response_type:
        # DB ì‘ë‹µ (ìì—°ì–´): ë‹µë³€ìš© í…ìŠ¤íŠ¸ë¥¼ ìì—°ì–´ë¡œ ì‘ë‹µ
        response = generate_natural_language_response(query, sheet_df, query_keywords)
        result["response"] = response
    
    elif "ì°¸ì¡°" in response_type:
        # DB ì°¸ì¡° ì‘ë‹µ: íŠ¹ì • í•­ëª©ì„ í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰ í›„ ì‘ë‹µ
        response = generate_reference_response(query, sheet_df, query_keywords)
        result["response"] = response
    
    elif "ì¡°ê±´" in response_type:
        # DB + ì¡°ê±´ ì‘ë‹µ: ì¡°ê±´ì„ íŒë‹¨í•´ì„œ ì‘ë‹µ
        response = generate_conditional_response(query, sheet_df, query_keywords)
        result["response"] = response
    
    elif "ëŒ€ì™¸ê³„" in response_type:
        # ëŒ€ì™¸ê³„ ì¡°íšŒ ì‘ë‹µ: ëŒ€ì™¸ê³„ ì •ë³´ ì¡°íšŒ ì‘ë‹µ
        response = generate_external_system_response(query, sheet_df, query_keywords)
        result["response"] = response
    
    else:
        # ê¸°ë³¸ ì‘ë‹µ ë°©ì‹
        response = generate_natural_language_response(query, sheet_df, query_keywords)
        result["response"] = response
    
    return result

def generate_natural_language_response(query, df, keywords):
    """
    ìì—°ì–´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        df: ë°ì´í„°í”„ë ˆì„
        keywords: ì¶”ì¶œëœ í‚¤ì›Œë“œ
        
    Returns:
        ìƒì„±ëœ ì‘ë‹µ
    """
    # ê´€ë ¨ í–‰ ì°¾ê¸°
    relevant_rows = find_relevant_rows(df, keywords)
    
    if not relevant_rows:
        return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ë°ì´í„°í”„ë ˆì„ì˜ ë‚´ìš©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    df_info = dataframe_to_text(df.iloc[relevant_rows])
    
    # OpenAIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±
    try:
        if OPENAI_API_KEY:
            messages = [
                {"role": "system", "content": """
                ì‹ í•œì€í–‰ ë„¤íŠ¸ì›Œí¬ ë‹´ë‹¹ì ì—­í• ì„ í•˜ëŠ” ì±—ë´‡ìœ¼ë¡œ, ë„¤íŠ¸ì›Œí¬ ì‹œìŠ¤í…œ, ì¥ë¹„, IP, ëŒ€ì™¸ê³„, ë³´ì•ˆ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.
                ì£¼ì–´ì§„ ì—‘ì…€ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.
                ê°„ê²°í•˜ê³  ì§ê´€ì ì¸ ì„¤ëª…ì„ ì œê³µí•˜ë˜, ì¤‘ìš”í•œ ì„¸ë¶€ì‚¬í•­ì€ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
                
                ì‘ë‹µ ìŠ¤íƒ€ì¼:
                - ì‹œì‘ì€ ì¹œê·¼í•œ ì¸ì‚¬ë‚˜ ì‚¬ìš©ì ìƒí™© ì¸ì‹ìœ¼ë¡œ ì‹œì‘ (ì˜ˆ: "ë„¤! NexG ì¥ë¹„ì— IPë¥¼ ì„¤ì •í•˜ì‹œë ¤ë©´...")
                - ì£¼ìš” ì œëª©ì€ ## ìˆ˜ì¤€ìœ¼ë¡œ, ë¶€ì œëª©ì€ ### ìˆ˜ì¤€ìœ¼ë¡œ êµ¬ì¡°í™”
                - ëŒ€í™”í˜• ë¬¸ì²´ë¡œ ì •ë³´ ì „ë‹¬ (ì˜ˆ: "ë¨¼ì € ì„¤ì • ëª¨ë“œë¡œ ë“¤ì–´ê°€ë³¼ê²Œìš”", "ë‹¤ìŒìœ¼ë¡œ ì´ë ‡ê²Œ í•´ë³´ì„¸ìš”")
                - ì¤‘ìš” ì •ë³´ëŠ” **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°
                - ì‚¬ìš©ìì—ê²Œ ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ í™•ì¸ì´ í•„ìš”í•œ ê²½ìš° ë§ˆì§€ë§‰ì— ë¬¼ì–´ë´„
                """},
                {"role": "user", "content": f"ì‚¬ìš©ì ì§ˆë¬¸: {query}\n\nì—‘ì…€ ë°ì´í„°:\n{df_info}"}
            ]
            
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                temperature=0.7,
                max_tokens=800
            )
            
            return response.choices[0].message.content
    except Exception as e:
        print(f"OpenAIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì œê³µ
    return summarize_dataframe(df.iloc[relevant_rows])

def generate_reference_response(query, df, keywords):
    """
    DB ì°¸ì¡° ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤ (íŠ¹ì • í•­ëª© ì§ì ‘ ê²€ìƒ‰).
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        df: ë°ì´í„°í”„ë ˆì„
        keywords: ì¶”ì¶œëœ í‚¤ì›Œë“œ
        
    Returns:
        ìƒì„±ëœ ì‘ë‹µ
    """
    # IP ì£¼ì†Œ í˜•ì‹ ê²€ìƒ‰
    ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
    ip_matches = re.findall(ip_pattern, query)
    
    # IP ì£¼ì†Œê°€ ìˆìœ¼ë©´ í•´ë‹¹ IPë¡œ ê²€ìƒ‰
    if ip_matches:
        target_ip = ip_matches[0]
        
        # ê° ì—´ì—ì„œ IP ì£¼ì†Œ ê²€ìƒ‰
        for col in df.columns:
            # IP ì£¼ì†Œ ì—´ë¡œ ì¶”ì •ë˜ëŠ” ì—´ ì°¾ê¸°
            if any(kw in col.lower() for kw in ['ip', 'ì£¼ì†Œ', 'address']):
                mask = df[col].str.contains(target_ip, regex=False, na=False)
                if mask.any():
                    matched_rows = df[mask]
                    result = format_reference_result(matched_rows, target_ip)
                    return result
        
        # ëª¨ë“  ì—´ì—ì„œ IP ê²€ìƒ‰
        for col in df.columns:
            mask = df[col].str.contains(target_ip, regex=False, na=False)
            if mask.any():
                matched_rows = df[mask]
                result = format_reference_result(matched_rows, target_ip)
                return result
    
    # ì¼ë°˜ í‚¤ì›Œë“œ ê²€ìƒ‰
    relevant_rows = find_relevant_rows(df, keywords)
    
    if not relevant_rows:
        return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ë°ì´í„°í”„ë ˆì„ì˜ ë‚´ìš©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    df_info = dataframe_to_text(df.iloc[relevant_rows])
    
    # OpenAIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±
    try:
        if OPENAI_API_KEY:
            messages = [
                {"role": "system", "content": """
                ì‹ í•œì€í–‰ ë„¤íŠ¸ì›Œí¬ ë‹´ë‹¹ì ì—­í• ì„ í•˜ëŠ” ì±—ë´‡ìœ¼ë¡œ, ì‚¬ìš©ìê°€ íŠ¹ì • ì •ë³´ë¥¼ ì¡°íšŒí•˜ë ¤ê³  í•©ë‹ˆë‹¤.
                ì—‘ì…€ ë°ì´í„°ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì•„ í‘œ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ ë°˜í™˜í•´ì£¼ì„¸ìš”.
                ì •ë³´ ì¡°íšŒ ê²°ê³¼ë¥¼ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ í‘œì‹œí•˜ë˜, í•„ìš”í•œ ëª¨ë“  ì •ë³´ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
                í‘œ í˜•ì‹ì€ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.
                
                ì‘ë‹µ í˜•ì‹:
                1. ì‹œì‘ì€ ì¹œê·¼í•œ ì¸ì‚¬ë¡œ ì‹œì‘
                2. ì¡°íšŒ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ì œê³µ
                3. í•„ìš”í•œ ê²½ìš° ê²°ê³¼ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª… ì¶”ê°€
                """},
                {"role": "user", "content": f"ì‚¬ìš©ì ì§ˆë¬¸(ì •ë³´ ì¡°íšŒ ìš”ì²­): {query}\n\nì—‘ì…€ ë°ì´í„°:\n{df_info}"}
            ]
            
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                temperature=0.7,
                max_tokens=800
            )
            
            return response.choices[0].message.content
    except Exception as e:
        print(f"OpenAIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì œê³µ
    return summarize_dataframe(df.iloc[relevant_rows])

def generate_conditional_response(query, df, keywords):
    """
    DB + ì¡°ê±´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤ (ì¡°ê±´ íŒë‹¨).
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        df: ë°ì´í„°í”„ë ˆì„
        keywords: ì¶”ì¶œëœ í‚¤ì›Œë“œ
        
    Returns:
        ìƒì„±ëœ ì‘ë‹µ
    """
    # ê´€ë ¨ í–‰ ì°¾ê¸°
    relevant_rows = find_relevant_rows(df, keywords)
    
    if not relevant_rows:
        return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ë°ì´í„°í”„ë ˆì„ì˜ ë‚´ìš©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    df_info = dataframe_to_text(df.iloc[relevant_rows])
    
    # OpenAIë¥¼ ì‚¬ìš©í•œ ì¡°ê±´ë¶€ ì‘ë‹µ ìƒì„±
    try:
        if OPENAI_API_KEY:
            messages = [
                {"role": "system", "content": """
                ì‹ í•œì€í–‰ ë„¤íŠ¸ì›Œí¬ ë‹´ë‹¹ì ì—­í• ì„ í•˜ëŠ” ì±—ë´‡ìœ¼ë¡œ, ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ì¡°ê±´ì— ë”°ë¥¸ íŒë‹¨ì´ í•„ìš”í•©ë‹ˆë‹¤.
                ì£¼ì–´ì§„ ì—‘ì…€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, ì¡°ê±´ì„ íŒë‹¨í•˜ê³  ì ì ˆí•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
                ì˜ˆë¥¼ ë“¤ì–´ 'IP ì¥ê¸°ë¯¸ì‚¬ìš© ì—¬ë¶€', 'ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ' ë“±ì˜ ì¡°ê±´ì„ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.
                ëª…í™•í•œ ê²°ë¡ ê³¼ í•„ìš”í•œ ì¡°ì¹˜ ì‚¬í•­ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
                
                ì‘ë‹µ í˜•ì‹:
                1. ì‹œì‘ì€ ì‚¬ìš©ì ì§ˆë¬¸ ì¸ì‹ìœ¼ë¡œ ì‹œì‘
                2. ì¡°ê±´ íŒë‹¨ ê²°ê³¼ ì„¤ëª…
                3. í•„ìš”í•œ ì¡°ì¹˜ ì‚¬í•­ ì•ˆë‚´
                4. ë§ˆë¬´ë¦¬ ë§ ë˜ëŠ” í›„ì† ì§ˆë¬¸
                """},
                {"role": "user", "content": f"ì‚¬ìš©ì ì§ˆë¬¸(ì¡°ê±´ íŒë‹¨ ìš”ì²­): {query}\n\nì—‘ì…€ ë°ì´í„°:\n{df_info}"}
            ]
            
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                temperature=0.7,
                max_tokens=800
            )
            
            return response.choices[0].message.content
    except Exception as e:
        print(f"OpenAIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì œê³µ
    return summarize_dataframe(df.iloc[relevant_rows])

def generate_external_system_response(query, df, keywords):
    """
    ëŒ€ì™¸ê³„ ì¡°íšŒ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        df: ë°ì´í„°í”„ë ˆì„
        keywords: ì¶”ì¶œëœ í‚¤ì›Œë“œ
        
    Returns:
        ìƒì„±ëœ ì‘ë‹µ
    """
    # í•„ìš”í•œ ìƒì„¸ ì •ë³´ í•„ë“œ í™•ì¸
    required_fields = ['íšŒì„ ì‚¬', 'íšŒì„  ë²ˆí˜¸', 'íšŒì„ ë²ˆí˜¸', 'ì„œë¹„ìŠ¤', 'ì„œë¹„ìŠ¤ ì¢…ë¥˜', 'ìš´ì˜ IP', 'ìš´ì˜IP', 
                     'ê°œë°œ IP', 'ê°œë°œIP', 'ë‹´ë‹¹ ë¶€ì„œ', 'ë‹´ë‹¹ë¶€ì„œ', 'ë‹¹í–‰ ë‹´ë‹¹ì', 'ë‹´ë‹¹ì', 
                     'ê¸°ê´€ ë‹´ë‹¹ì', 'ê¸°ê´€ë‹´ë‹¹ì', 'ê¸°ê´€ ì£¼ì†Œ', 'ê¸°ê´€ì£¼ì†Œ', 'IP']
    
    # ê¸°ê´€ëª… í™•ì¸ (ì„œì¹˜ í‚¤ì›Œë“œ)
    org_keywords = ['ì¹´ë“œ', 'ìƒëª…', 'ìºí”¼íƒˆ', 'ì¦ê¶Œ', 'ì€í–‰', 'ë³´í—˜', 'ê¸ˆìœµ', 'ê³µì‚¬', 'ê³µë‹¨', 
                    'í˜‘íšŒ', 'ì—°í•©íšŒ', 'ì„¼í„°', 'ê¸°ê´€', 'íšŒì‚¬', 'ë‹¨ì²´', 'ì¡°í•©']
    
    # ì¿¼ë¦¬ì—ì„œ ê¸°ê´€ëª… ì¶”ì¶œ (ì˜ˆ: "ì‹ í•œì¹´ë“œ")
    searched_org = None
    for kw in keywords:
        # 1. ì§ì ‘ì ì¸ ê¸°ê´€ëª… í‚¤ì›Œë“œ í™•ì¸ (ì˜ˆ: ì‹ í•œì¹´ë“œ, KBì¦ê¶Œ ë“±)
        is_org = False
        for org_kw in org_keywords:
            if org_kw in kw:
                is_org = True
                searched_org = kw
                break
                
        # 2. "ì‹ í•œ" "KB" ë“±ì˜ ì§§ì€ ê¸°ê´€ëª…ë„ ì²´í¬
        if len(kw) >= 2 and not is_org:
            # ê¸°ê´€ëª… ì»¬ëŸ¼ì„ ì°¾ì•„ì„œ ê²€ìƒ‰
            org_column = None
            for col in df.columns:
                if 'ê¸°ê´€' in col or 'íšŒì‚¬' in col or 'ì—…ì²´' in col:
                    org_column = col
                    break
            
            if org_column:
                for idx, row in df.iterrows():
                    org_value = str(row[org_column]).lower()
                    if kw.lower() in org_value and len(kw) >= 2:
                        searched_org = str(row[org_column])
                        break
    
    print(f"ê²€ìƒ‰ëœ ê¸°ê´€ëª…: {searched_org}")
    
    # ê´€ë ¨ í–‰ ì°¾ê¸° (ê¸°ê´€ëª… ìš°ì„ , ê·¸ ë‹¤ìŒ í‚¤ì›Œë“œ)
    relevant_rows = []
    
    # 1. ê¸°ê´€ëª…ì´ ìˆìœ¼ë©´ ë¨¼ì € ê¸°ê´€ëª…ìœ¼ë¡œ ê²€ìƒ‰
    if searched_org:
        for idx, row in df.iterrows():
            row_text = ' '.join(str(val).lower() for val in row.values)
            if searched_org.lower() in row_text.lower():
                relevant_rows.append(idx)
    
    # 2. ê¸°ê´€ëª…ìœ¼ë¡œ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ê¸°ê´€ëª…ì´ ì—†ìœ¼ë©´ ì¼ë°˜ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
    if not relevant_rows:
        relevant_rows = find_relevant_rows(df, keywords)
    
    if not relevant_rows:
        return f"ìš”ì²­í•˜ì‹  ëŒ€ì™¸ê³„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¢€ ë” êµ¬ì²´ì ì¸ ê¸°ê´€ëª…ì´ë‚˜ í‚¤ì›Œë“œë¡œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."
    
    # ê²€ìƒ‰ëœ ê²°ê³¼ ë°ì´í„°
    result_data = df.iloc[relevant_rows]
    
    # í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    org_name = searched_org if searched_org else "ìš”ì²­í•˜ì‹  ê¸°ê´€"
    
    # ì¡°íšŒ ê²°ê³¼ë¥¼ ìì—°ì–´ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±
    info_dict = {}
    
    # ë°ì´í„°í”„ë ˆì„ì˜ ì»¬ëŸ¼ëª…-ê°’ì„ ë§¤í•‘
    for col in result_data.columns:
        col_lower = col.lower()
        
        # í•„ë“œ ë§¤í•‘
        field_key = None
        
        if 'íšŒì„ ì‚¬' in col_lower:
            field_key = 'íšŒì„ ì‚¬'
        elif any(kw in col_lower for kw in ['íšŒì„  ë²ˆí˜¸', 'íšŒì„ ë²ˆí˜¸', 'ì „í™”ë²ˆí˜¸']):
            field_key = 'íšŒì„  ë²ˆí˜¸'
        elif any(kw in col_lower for kw in ['ì„œë¹„ìŠ¤', 'ì„œë¹„ìŠ¤ ì¢…ë¥˜', 'ì¢…ë¥˜']):
            field_key = 'ì„œë¹„ìŠ¤ ì¢…ë¥˜'
        elif any(kw in col_lower for kw in ['ìš´ì˜ ip', 'ìš´ì˜ip', 'ìš´ì˜ì£¼ì†Œ']):
            field_key = 'ìš´ì˜ IP'
        elif any(kw in col_lower for kw in ['ê°œë°œ ip', 'ê°œë°œip', 'ê°œë°œì£¼ì†Œ']):
            field_key = 'ê°œë°œ IP'
        elif 'ë‹´ë‹¹ ë¶€ì„œ' in col_lower or 'ë‹´ë‹¹ë¶€ì„œ' in col_lower:
            field_key = 'ë‹¹í–‰ ë‹´ë‹¹ ë¶€ì„œ'
        elif any(kw in col_lower for kw in ['ë‹¹í–‰ ë‹´ë‹¹ì', 'ë‹´ë‹¹ì']):
            field_key = 'ë‹¹í–‰ ë‹´ë‹¹ì'
        elif any(kw in col_lower for kw in ['ê¸°ê´€ ë‹´ë‹¹ì', 'ê¸°ê´€ë‹´ë‹¹ì', 'ì™¸ë¶€ë‹´ë‹¹ì']):
            field_key = 'ê¸°ê´€ ë‹´ë‹¹ì'
        elif any(kw in col_lower for kw in ['ê¸°ê´€ ì£¼ì†Œ', 'ê¸°ê´€ì£¼ì†Œ', 'ì£¼ì†Œ']):
            field_key = 'ê¸°ê´€ ì£¼ì†Œ'
        elif 'ip' in col_lower and 'ip' not in info_dict:
            # ì¼ë°˜ IP ì»¬ëŸ¼ì´ ìˆê³  ì•„ì§ IP ì •ë³´ê°€ ì—†ìœ¼ë©´
            field_key = 'IP' 
        
        if field_key and field_key not in info_dict:
            first_value = str(result_data.iloc[0][col]).strip()
            if first_value and first_value != 'nan':
                info_dict[field_key] = first_value
    
    # ìì—°ì–´ ì‘ë‹µ ìƒì„±
    response = f"ğŸ“¡ **{org_name} ì—°ë™ ì •ë³´**ì…ë‹ˆë‹¤:\n\n"
    
    # í•„ìˆ˜ í•„ë“œ ëª©ë¡ (ë³´ì—¬ì¤„ ìˆœì„œëŒ€ë¡œ)
    display_order = ['íšŒì„ ì‚¬', 'íšŒì„  ë²ˆí˜¸', 'ì„œë¹„ìŠ¤ ì¢…ë¥˜', 'ìš´ì˜ IP', 'ê°œë°œ IP', 'IP', 
                     'ë‹¹í–‰ ë‹´ë‹¹ ë¶€ì„œ', 'ë‹¹í–‰ ë‹´ë‹¹ì', 'ê¸°ê´€ ë‹´ë‹¹ì', 'ê¸°ê´€ ì£¼ì†Œ']
    
    # ì •ë³´ ì¶”ê°€
    for field in display_order:
        if field in info_dict and info_dict[field]:
            response += f"- **{field}**: {info_dict[field]}\n"
    
    # ì¶”ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ í‘œì‹œ (ìœ„ ëª©ë¡ì— ì—†ëŠ” ì»¬ëŸ¼)
    for key, value in info_dict.items():
        if key not in display_order:
            response += f"- **{key}**: {value}\n"
    
    # ë‹´ë‹¹ì ì •ë³´ê°€ ìˆìœ¼ë©´ ë§ˆë¬´ë¦¬ ë¬¸êµ¬ ì¶”ê°€
    if 'ë‹¹í–‰ ë‹´ë‹¹ ë¶€ì„œ' in info_dict or 'ë‹¹í–‰ ë‹´ë‹¹ì' in info_dict:
        dept = info_dict.get('ë‹¹í–‰ ë‹´ë‹¹ ë¶€ì„œ', 'ë„¤íŠ¸ì›Œí¬ ìš´ì˜íŒ€')
        response += f"\në” ê¶ê¸ˆí•œ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ {dept}ìœ¼ë¡œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
    else:
        response += "\në” ê¶ê¸ˆí•œ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ë„¤íŠ¸ì›Œí¬ ìš´ì˜íŒ€ìœ¼ë¡œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
    
    return response

def check_keyword_match(query: str, keywords: List[str]) -> bool:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì— íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        keywords: ê²€ìƒ‰í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ (True/False)
    """
    query_lower = query.lower()
    for keyword in keywords:
        if keyword.lower() in query_lower:
            return True
    return False

def get_fine_tuned_response(query: str, chat_history: Optional[List[Dict[str, str]]] = None) -> Optional[str]:
    """
    Fine-tuned ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        chat_history: ì±„íŒ… ê¸°ë¡ (ì„ íƒ ì‚¬í•­)
        
    Returns:
        ìƒì„±ëœ ì‘ë‹µ ë˜ëŠ” None (ì˜¤ë¥˜ ë°œìƒ ì‹œ)
    """
    try:
        # ë©”ì‹œì§€ ëª©ë¡ ì¤€ë¹„
        messages = []
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
        system_message = """
        ë‹¹ì‹ ì€ ì‹ í•œì€í–‰ ë„¤íŠ¸ì›Œí¬ ë‹´ë‹¹ìë¡œ, VPN, ë³´ì•ˆ, ë„¤íŠ¸ì›Œí¬ ì¥ë¹„, PC ë¬¸ì œ ë“±ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.
        ê°„ê²°í•˜ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ë©°, ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë‹¨ê³„ë³„ ì•ˆë‚´ë¥¼ ì œê³µí•˜ì„¸ìš”.
        """
        messages.append({"role": "system", "content": system_message})
        
        # ì±„íŒ… ê¸°ë¡ ì¶”ê°€ (íƒ€ì… ì•ˆì „ì„± ë³´ì¥)
        if chat_history:
            for msg in chat_history:
                role = msg.get("role", "")
                content = msg.get("content", "")
                if role in ["user", "assistant"] and content is not None:
                    messages.append({"role": role, "content": content})
        
        # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
        messages.append({"role": "user", "content": query})
        
        # OpenAIì—ì„œ ì‘ë‹µ ë°›ê¸°
        response = openai_client.chat.completions.create(
            model=FINE_TUNED_MODEL["model_id"],
            messages=messages,
            temperature=FINE_TUNED_MODEL["temperature"],
            max_tokens=FINE_TUNED_MODEL["max_tokens"],
        )
        
        # ì‘ë‹µ ì²˜ë¦¬
        response_content = response.choices[0].message.content
        if response_content is None:
            print("Fine-tuned ëª¨ë¸ì—ì„œ None ì‘ë‹µì„ ë°›ìŒ")
            return None
            
        return response_content
    
    except Exception as e:
        print(f"Fine-tuned ëª¨ë¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None  # ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜í•˜ì—¬ RAG ì‹œìŠ¤í…œìœ¼ë¡œ í´ë°±

def get_chatbot_response(
    query: str, 
    context: Optional[str] = None, 
    chat_history: Optional[List[Dict[str, str]]] = None,
    model: str = "gpt-3.5-turbo",
    use_rag: bool = True
) -> str:
    """
    Get a response from the chatbot for the given query
    
    Args:
        query: User's query
        context: Optional context from retrieved documents
        chat_history: Optional chat history
        model: OpenAI model to use
        use_rag: Whether to use RAG pipeline
        
    Returns:
        Response from the chatbot
    """
    if not OPENAI_API_KEY:
        return "Error: OpenAI API key is not set. Please set the OPENAI_API_KEY environment variable."
    
    try:
        # ë¨¼ì € í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ê¸° í™•ì¸ - FAQ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì§ˆë¬¸ì´ê³  Fine-tuned ëª¨ë¸ì´ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ Fine-tuned ëª¨ë¸ ì‚¬ìš©
        use_fine_tuned = False
        
        if FINE_TUNED_MODEL["enabled"] and check_keyword_match(query, FAQ_KEYWORDS):
            print(f"FAQ í‚¤ì›Œë“œ ë§¤ì¹˜ë¨: {query} - Fine-tuned ëª¨ë¸ ì‚¬ìš©")
            use_fine_tuned = True
            fine_tuned_response = get_fine_tuned_response(query, chat_history)
            
            # Fine-tuned ëª¨ë¸ ì‘ë‹µì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ë©´ í•´ë‹¹ ì‘ë‹µ ë°˜í™˜
            if fine_tuned_response:
                return fine_tuned_response
            
            # ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ RAG ì‹œìŠ¤í…œìœ¼ë¡œ í´ë°± (ì•„ë˜ ì½”ë“œ ê³„ì† ì‹¤í–‰)
            print("Fine-tuned ëª¨ë¸ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨, RAG ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜")
        
        # ë‹¤ìŒìœ¼ë¡œ ì—‘ì…€ ê¸°ë°˜ ì²˜ë¦¬ ì‹œë„
        excel_result = process_excel_query(query)
        
        # ì—‘ì…€ì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì•˜ìœ¼ë©´ í•´ë‹¹ ê²°ê³¼ ë°˜í™˜
        if excel_result["found"] and excel_result["from_excel"]:
            print(f"ì—‘ì…€ ì²˜ë¦¬ ê²°ê³¼: {excel_result['category']} / {excel_result['sheet_used']} / {excel_result['response_type']}")
            return excel_result["response"]
        
        # ì—‘ì…€ì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìœ¼ë©´ ê¸°ì¡´ RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        
        # ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì–¸ì–´ ê°ì§€
        language = detect_language(query)
        
        # RAG íŒŒì´í”„ë¼ì¸ ì ìš© (í•„ìš”ì‹œ)
        retrieved_docs = []
        if RAG_SYSTEM["enabled"] and use_rag and not context:
            retrieved_docs, context = retrieve_relevant_documents(query, top_k=5)
            if not context:
                if language == 'ko':
                    no_docs_message = "í˜„ì¬ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nì¶”ê°€ ì§€ì›ì´ í•„ìš”í•˜ì‹¤ ê²½ìš°,\n**ë„¤íŠ¸ì›Œí¬ ìš´ì˜ ë‹´ë‹¹ì(XX-XXX-XXXX)**ë¡œ ì—°ë½í•´ ì£¼ì‹œë©´ ì‹ ì†íˆ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                else:
                    no_docs_message = "Currently, we cannot find any related documents.\n\nFor additional support,\nPlease contact the **Network Operations Team (XX-XXX-XXXX)** for prompt assistance."
                print(f"No relevant documents found for query: {query}")
                return no_docs_message
                
        # Prepare the system message based on language
        if language == 'ko':
            system_message = """
            ë‹¹ì‹ ì€ ì‹ í•œì€í–‰ ì§ì›ë“¤ì„ ìœ„í•œ SHB-NetBotì´ë¼ëŠ” ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ë„¤íŠ¸ì›Œí¬ ì§€ì› ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
            'ë„¥ìŠ¤ì§€ VForce UTM'ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ë„¤íŠ¸ì›Œí¬ ì¥ë¹„ì— ëŒ€í•œ ì „ë¬¸ê°€ë¡œì„œ, ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• ë§íˆ¬ë¡œ ì‚¬ìš©ìë¥¼ ë•ìŠµë‹ˆë‹¤.
            
            ë„ì›€ì„ ì¤„ ìˆ˜ ìˆëŠ” ì£¼ì œì˜ ì˜ˆì‹œ:
            - SWING(ë‚´ë¶€ ë©”ì‹œì§• ì‹œìŠ¤í…œ) ì ‘ì† ë°©ë²•
            - IP ì£¼ì†Œ ì„¤ì • ë° í™•ì¸ ë°©ë²•
            - ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ í•´ê²°
            - VPN ì„¤ì • ë° ì—°ê²° ë¬¸ì œ
            - ë‚´ë¶€ ì‹œìŠ¤í…œ ì ‘ê·¼ ì ˆì°¨
            
            ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ìœ„í•œ ê°€ì´ë“œë¼ì¸:
            1. ëŒ€í™”í˜• ë§íˆ¬: "~í•©ë‹ˆë‹¤"ê°€ ì•„ë‹Œ "~í•´ìš”", "~í•˜ì„¸ìš”" ë“±ì˜ êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•´ì„œ ë§ˆì¹˜ ì˜†ì—ì„œ ì§ì ‘ ë„ì™€ì£¼ëŠ” ë“¯í•œ ì¹œê·¼í•œ ë§íˆ¬ë¡œ ëŒ€í™”í•©ë‹ˆë‹¤.
            2. ì‚¬ìš©ì ì´í•´: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´, ìƒí™©ì„ ì´í•´í•˜ê¸° ìœ„í•œ ì¶”ê°€ ì§ˆë¬¸ì„ í•˜ê±°ë‚˜ ê°€ëŠ¥í•œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
            3. ë¬¸ì„œ ë‚´ìš© ì¬êµ¬ì„±: ë¬¸ì„œì—ì„œ ì°¾ì€ ì •ë³´ë¥¼ ë‹¨ìˆœ ë³µì‚¬ê°€ ì•„ë‹Œ, ìƒí™©ì— ë§ê²Œ ìš”ì•½í•˜ê³  ì„¤ëª…í•˜ë“¯ ì „ë‹¬í•©ë‹ˆë‹¤.
            4. ë‹¨ê³„ë³„ ì•ˆë‚´: ë³µì¡í•œ ì ˆì°¨ëŠ” ì‰½ê²Œ ë”°ë¼í•  ìˆ˜ ìˆë„ë¡ ëª…í™•í•œ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ì„¤ëª…í•©ë‹ˆë‹¤.
            
            ì‘ë‹µ ìŠ¤íƒ€ì¼ê³¼ í˜•ì‹:
            - ì‹œì‘ì€ ì¹œê·¼í•œ ì¸ì‚¬ë‚˜ ì‚¬ìš©ì ìƒí™© ì¸ì‹ìœ¼ë¡œ ì‹œì‘ (ì˜ˆ: "ë„¤! NexG ì¥ë¹„ì— IPë¥¼ ì„¤ì •í•˜ì‹œë ¤ë©´...")
            - ì£¼ìš” ì œëª©ì€ ## ìˆ˜ì¤€ìœ¼ë¡œ, ë¶€ì œëª©ì€ ### ìˆ˜ì¤€ìœ¼ë¡œ êµ¬ì¡°í™”
            - ëŒ€í™”í˜• ë¬¸ì²´ë¡œ ì •ë³´ ì „ë‹¬ (ì˜ˆ: "ë¨¼ì € ì„¤ì • ëª¨ë“œë¡œ ë“¤ì–´ê°€ë³¼ê²Œìš”", "ë‹¤ìŒìœ¼ë¡œ ì´ë ‡ê²Œ í•´ë³´ì„¸ìš”")
            - ì¤‘ìš” ì •ë³´ëŠ” **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°
            - CLI ëª…ë ¹ì–´ëŠ” ```ë¡œ ê°ì‹¸ì§„ ì½”ë“œ ë¸”ë¡ì—, ê° ë‹¨ê³„ì— ê°„ë‹¨í•œ ì„¤ëª… ì¶”ê°€
            - ì‚¬ìš©ìì—ê²Œ ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ í™•ì¸ì´ í•„ìš”í•œ ê²½ìš° ë§ˆì§€ë§‰ì— ë¬¼ì–´ë´„ (ì˜ˆ: "í˜¹ì‹œ íŠ¹ì • ì¸í„°í˜ì´ìŠ¤ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")
            """
            
            if context:
                system_message += """
                ì‹ í•œì€í–‰ì˜ ë‚´ë¶€ ë¬¸ì„œì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì— í™œìš©í•˜ì„¸ìš”.
                ì •ë³´ê°€ ì§ˆë¬¸ì— ì™„ì „íˆ ë‹µë³€í•˜ì§€ ì•Šìœ¼ë©´, ë‹¹ì‹ ì˜ ì „ë¬¸ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ë³´ì¶©í•˜ì„¸ìš”.
                
                ë¬¸ì„œë¥¼ ë‹¨ìˆœíˆ ë³µë¶™í•˜ì§€ ë§ê³ , ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¼ ì²˜ë¦¬í•˜ì„¸ìš”:
                1. ì§ˆë¬¸ ì˜ë„ íŒŒì•…: ì‚¬ìš©ìê°€ êµ¬ì²´ì ìœ¼ë¡œ ë¬´ì—‡ì„ ì•Œê³  ì‹¶ì–´í•˜ëŠ”ì§€ ì´í•´í•©ë‹ˆë‹¤.
                2. ê´€ë ¨ ë‚´ìš© ì¶”ì¶œ: ë¬¸ë§¥ ì •ë³´ì—ì„œ ê´€ë ¨ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ê³  ì¤‘ìš”í•˜ì§€ ì•Šì€ ì„¸ë¶€ ì‚¬í•­ì€ ìƒëµí•©ë‹ˆë‹¤.
                3. ë‹¨ê³„ë³„ ì •ë¦¬: ê³¼ì •ì´ë‚˜ ì„¤ì • ë°©ë²•ì€ ëª…í™•í•œ ë‹¨ê³„ë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.
                4. ìì—°ì–´ë¡œ ì„¤ëª…: ê¸°ìˆ ì ì¸ ë‚´ìš©ë„ ëŒ€í™”í•˜ë“¯ ì„¤ëª…í•©ë‹ˆë‹¤.
                5. êµ¬ì²´ì ì¸ ì˜ˆì‹œ ì œê³µ: ê°€ëŠ¥í•œ ê²½ìš° CLI ëª…ë ¹ì–´ë‚˜ UI ê²½ë¡œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
                6. ë„ì…Â·ë§ˆë¬´ë¦¬ ì¶”ê°€: ê°„ê²°í•œ ë„ì… ë¬¸ì¥ê³¼ ìœ ìš©í•œ ë§ˆë¬´ë¦¬ë¡œ ì‘ë‹µì„ ì™„ì„±í•©ë‹ˆë‹¤.
                
                ë¬¸ë§¥ ì •ë³´:
                """
                system_message += context
        else:
            system_message = """
            You are SHB-NetBot, a friendly and professional network support assistant for Shinhan Bank employees.
            As an expert on various network equipment including 'NexG VForce UTM', you help users with a natural, conversational tone.
            
            Examples of topics you can help with include:
            - SWING (internal messaging system) access instructions
            - IP address configuration and verification methods
            - Network connectivity troubleshooting
            - VPN setup and connection issues
            - Internal system access procedures
            
            Guidelines for friendly and natural conversation:
            1. Conversational tone: Use a friendly, helpful tone as if you're sitting next to the user and guiding them personally.
            2. User understanding: If a user's question is unclear, ask follow-up questions or suggest possible scenarios.
            3. Content restructuring: Instead of directly copying from documents, summarize and explain information in context.
            4. Step-by-step guidance: Break down complex procedures into clear, easy-to-follow steps.
            
            Response style and format:
            - Start with a friendly greeting or acknowledgment of the user's situation (e.g., "Sure! To set up IP on your NexG device...")
            - Structure main topics with ## level headings and subtopics with ### level headings
            - Deliver information in a conversational manner (e.g., "Let's start by entering configuration mode", "Next, we'll do this")
            - Highlight important information with **bold text**
            - Present CLI commands in code blocks with brief explanations for each step
            - End with a question if additional information or clarification might be needed
            """
            
            if context:
                system_message += """
                Use the following information from Shinhan Bank's internal documents to inform your response.
                If the information doesn't fully answer the query, use your expert knowledge to supplement it.
                
                Instead of simply copying from documents, follow these guidelines:
                1. Understand the question: Identify exactly what the user wants to know
                2. Extract relevant content: Focus on relevant parts from the context and omit unimportant details
                3. Organize into steps: Restructure processes or configurations into clear steps
                4. Use natural language: Explain technical content conversationally
                5. Include specific examples: Provide CLI commands or UI paths when possible
                6. Add introduction and conclusion: Start with a brief introduction and end with a helpful conclusion
                
                CONTEXT INFORMATION:
                """
                system_message += context
        
        # ë©”ì‹œì§€ ëª©ë¡ ì¤€ë¹„
        messages = []
        messages.append({"role": "system", "content": system_message})
        
        # ì±„íŒ… ê¸°ë¡ ì¶”ê°€
        if chat_history:
            for msg in chat_history:
                role = msg.get("role", "")
                content = msg.get("content", "")
                if role in ["user", "assistant"]:
                    messages.append({"role": role, "content": content})
        
        # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
        messages.append({"role": "user", "content": query})
        
        # OpenAIì—ì„œ ì‘ë‹µ ë°›ê¸°
        response = openai_client.chat.completions.create(
            model=RAG_SYSTEM["model"],
            messages=messages,
            temperature=RAG_SYSTEM["temperature"],
            max_tokens=RAG_SYSTEM["max_tokens"],
        )
        
        # ì‘ë‹µ ì²˜ë¦¬
        response_content = response.choices[0].message.content
        
        # None ê°’ì¸ ê²½ìš° ëŒ€ë¹„ (ê±°ì˜ ë°œìƒí•˜ì§€ ì•ŠìŒ)
        if not response_content:
            if language == 'ko':
                return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            else:
                return "Sorry, I couldn't generate a response. Please try again later."
        
        return response_content
    
    except Exception as e:
        # ì˜¤ë¥˜ ë©”ì‹œì§€ë„ ì–¸ì–´ì— ë§ê²Œ ë°˜í™˜
        language = detect_language(query)
        if language == 'ko':
            return f"ì±—ë´‡ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        else:
            return f"An error occurred while generating chatbot response: {str(e)}"
