import os
from typing import List, Dict, Any, Optional, Tuple
import json
import openai
import re
import pandas as pd
from pathlib import Path
from openai import OpenAI

from database import search_similar_docs

# Import configuration
from config import FAQ_KEYWORDS, FINE_TUNED_MODEL, RAG_SYSTEM

# Initialize OpenAI client
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# ì—…ë¡œë“œëœ íŒŒì¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ
UPLOAD_FOLDER = 'uploaded_files'

def is_meaningless_query(query: str) -> bool:
    """
    ë¬´ì˜ë¯¸í•œ ì…ë ¥ì¸ì§€ ê°ì§€í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        
    Returns:
        ë¬´ì˜ë¯¸í•œ ì…ë ¥ ì—¬ë¶€ (True/False)
    """
    # ì…ë ¥ì„ ì •ê·œí™”
    query = query.strip().lower()
    
    # ë„ˆë¬´ ì§§ì€ ì…ë ¥ ì²´í¬
    if len(query) <= 2:
        return True
        
    # ì˜ë¯¸ ì—†ëŠ” íŒ¨í„´ ëª©ë¡
    meaningless_patterns = [
        r'^[.?!,;:]+$',                 # ê¸°í˜¸ë§Œ ìˆëŠ” ê²½ìš° (ì˜ˆ: "???", "...", "!!!")
        r'^(ã…‹|ã…|ã… |ã…œ)+$',              # ììŒ/ëª¨ìŒ ë°˜ë³µ (ì˜ˆ: "ã…‹ã…‹ã…‹", "ã…ã…", "ã… ã… ")
        r'^(test|í…ŒìŠ¤íŠ¸|testing)$',      # í…ŒìŠ¤íŠ¸ ì…ë ¥
        r'^[0-9]+$',                    # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° (ì˜ˆ: "123", "1")
        r'^[a-z]+$',                    # ì•ŒíŒŒë²³ 1-2ê¸€ì (ì˜ˆ: "a", "ab")
        r'^(ì•ˆë…•|hello|hi)$',            # ë‹¨ìˆœ ì¸ì‚¬ë§Œ ìˆëŠ” ê²½ìš°
    ]
    
    # íŒ¨í„´ì— ë§ëŠ”ì§€ í™•ì¸
    for pattern in meaningless_patterns:
        if re.match(pattern, query):
            return True
    
    # ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´ ëª©ë¡
    meaningless_words = [
        'test', 'í…ŒìŠ¤íŠ¸', 'asdf', 'qwer', 'zxcv', 'hehe', 'í ', 'ìŒ', 
        'aaa', 'abc', 'ê°€ë‚˜ë‹¤', '111', '123'
    ]
    
    # ëª©ë¡ì— ìˆëŠ” ë‹¨ì–´ì¸ì§€ í™•ì¸
    if query in meaningless_words:
        return True
        
    return False

def get_meaningless_response() -> str:
    """
    ë¬´ì˜ë¯¸í•œ ì…ë ¥ì— ëŒ€í•œ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        ì‘ë‹µ ë©”ì‹œì§€
    """
    return (
        "ğŸ˜… ì •í™•í•œ ì§ˆë¬¸ ë‚´ìš©ì„ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
        "ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì‹œê±°ë‚˜, IT ë„¤íŠ¸ì›Œí¬ ë‹´ë‹¹ ë¶€ì„œ(02-1234-5678)ë¡œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
    )

def detect_language(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.
    
    Args:
        text: ê°ì§€í•  í…ìŠ¤íŠ¸
    
    Returns:
        ì–¸ì–´ ì½”ë“œ ('ko' ë˜ëŠ” 'en')
    """
    # í•œê¸€ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if re.search(r'[ê°€-í£]', text):
        return 'ko'
    else:
        return 'en'

def retrieve_relevant_documents(query: str, top_k: int = 5) -> Tuple[List[Any], str]:
    """
    ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        top_k: ê²€ìƒ‰í•  ìƒìœ„ ë¬¸ì„œ ìˆ˜
        
    Returns:
        (ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸, ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´) íŠœí”Œ
    """
    try:
        # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„)
        keywords = extract_keywords_from_query(query)
        print(f"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
        
        # ì ˆì°¨ ê°€ì´ë“œ ì „ìš© ê²€ìƒ‰ì„ ìœ„í•œ í•„í„°ë§
        procedure_guide_filter = None
        
        # íŠ¹ì • ë²„ì „ì˜ ê°€ì´ë“œë¥¼ ìš”ì²­í•˜ëŠ”ì§€ í™•ì¸ (ì˜ˆ: "2025ë…„ 5ì›” 19ì¼ ì—…ë¬´ ê°€ì´ë“œì—ì„œ...")
        version_pattern = re.search(r'(\d{4}[.ë…„\-_]\s?\d{1,2}[.ì›”\-_]\s?\d{1,2})', query)
        guide_version = None
        
        if version_pattern:
            # ë²„ì „ ì •ë³´ ì¶”ì¶œ ë° ì •ê·œí™”
            raw_version = version_pattern.group(1)
            
            # ê³µë°± ì œê±°
            normalized_version = raw_version.replace(' ', '')
            
            # yyyyë…„mmì›”ddì¼ í˜•ì‹ -> yyyy.mm.dd í˜•ì‹ìœ¼ë¡œ ë³€í™˜ 
            normalized_version = re.sub(r'(\d{4})ë…„(\d{1,2})ì›”(\d{1,2})ì¼', r'\1.\2.\3', normalized_version)
            
            # yyyy-mm-dd í˜•ì‹ë„ ìœ ì§€ (ChromaDB ê²€ìƒ‰ì—ì„œëŠ” ì›ë³¸ í˜•ì‹ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
            guide_version = normalized_version
            
            print(f"íŠ¹ì • ë²„ì „ ê°€ì´ë“œ ìš”ì²­ ê°ì§€: {raw_version} -> {guide_version}")
        
        # ì ˆì°¨ ê°€ì´ë“œ í•„í„°ë§ ì ìš©
        if any(keyword in query for keyword in ['ì–´ë–»ê²Œ', 'ë°©ë²•', 'ì ˆì°¨', 'ì‹ ì²­', 'ì‹ ê·œ', 'ë³€ê²½']):
            procedure_guide_filter = {"content_type": "procedure_guide"}
            
            # íŠ¹ì • ë²„ì „ì´ ìš”ì²­ëœ ê²½ìš° í•´ë‹¹ ë²„ì „ìœ¼ë¡œ í•„í„°ë§ ì¶”ê°€
            if guide_version:
                procedure_guide_filter["guide_version"] = guide_version
            
            print(f"ì ˆì°¨ ê°€ì´ë“œ ìš°ì„  ê²€ìƒ‰ í™œì„±í™”ë¨ - í•„í„°: {procedure_guide_filter}")
        
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        docs = search_similar_docs(query, top_k=top_k, filter=procedure_guide_filter)
        
        # ê°€ì´ë“œ ë¬¸ì„œê°€ ì—†ê³  í•„í„°ê°€ ì ìš©ëœ ê²½ìš° ë‹¤ì‹œ í•„í„° ì—†ì´ ê²€ìƒ‰
        if (not docs or len(docs) == 0) and procedure_guide_filter:
            print("ì ˆì°¨ ê°€ì´ë“œì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í•´ ì „ì²´ ë¬¸ì„œì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤")
            docs = search_similar_docs(query, top_k=top_k)
        
        # ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ë¹ˆ ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜
        if not docs or len(docs) == 0:
            return [], ""
        
        # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
        context_str = "Context:\n"
        
        # ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ ë¬¸ì„œëŠ” íŠ¹ë³„í•œ í¬ë§·ìœ¼ë¡œ í‘œì‹œ
        for i, doc in enumerate(docs):
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì—…ë¬´ ê°€ì´ë“œ ì •ë³´ í™•ì¸
            metadata = getattr(doc, 'metadata', {})
            content_type = metadata.get('content_type', '')
            
            if content_type == 'procedure_guide':
                # ì—…ë¬´ ê°€ì´ë“œ í˜•ì‹ìœ¼ë¡œ í¬ë§· (ë²„ì „ ì •ë³´ í¬í•¨)
                guide_version = metadata.get('guide_version', 'latest')
                version_text = f" (ë²„ì „: {guide_version})" if guide_version != 'latest' else ""
                context_str += f"- ({i+1}) ì—…ë¬´ ì•ˆë‚´{version_text}: "
                
                # ì§ˆë¬¸ ì˜ˆì‹œì™€ ìƒì„¸ ì•ˆë‚´ ë¶€ë¶„ ê°•ì¡°
                if 'ì§ˆë¬¸ ì˜ˆì‹œ' in metadata:
                    context_str += f"[ì§ˆë¬¸: {metadata['ì§ˆë¬¸ ì˜ˆì‹œ']}] "
                
                if 'ìš”ì•½ ì‘ë‹µ' in metadata:
                    context_str += f"[ìš”ì•½: {metadata['ìš”ì•½ ì‘ë‹µ']}] "
                    
                if 'ìƒì„¸ ì•ˆë‚´' in metadata:
                    context_str += f"[ì•ˆë‚´: {metadata['ìƒì„¸ ì•ˆë‚´']}] "
                
                # ì¼ë°˜ ë‚´ìš©ë„ í¬í•¨
                context_str += f"\n  ì›ë³¸ë‚´ìš©: \"{doc.page_content}\"\n\n"
            else:
                # ì¼ë°˜ ë¬¸ì„œ í˜•ì‹ìœ¼ë¡œ í¬ë§·
                context_str += f"- ({i+1}) \"{doc.page_content}\"\n\n"
        
        return docs, context_str
    except Exception as e:
        print(f"ERROR: RAG pipeline failed during document retrieval: {str(e)}")
        return [], ""

# ì—‘ì…€ ì²˜ë¦¬ ê´€ë ¨ í•¨ìˆ˜ë“¤
def find_excel_files(search_keyword="ì—…ë¬´ ì ˆì°¨ ì•ˆë‚´ ê°€ì´ë“œ"):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ ì¤‘ ì—‘ì…€ íŒŒì¼ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        search_keyword: ê²€ìƒ‰í•  í‚¤ì›Œë“œ
        
    Returns:
        ì°¾ì€ ì—‘ì…€ íŒŒì¼ì˜ ê²½ë¡œ ëª©ë¡
    """
    excel_files = []
    
    # ì—…ë¡œë“œ í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(UPLOAD_FOLDER):
        print(f"ì—…ë¡œë“œ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {UPLOAD_FOLDER}")
        return excel_files
    
    # ì—…ë¡œë“œ í´ë” ë‚´ íŒŒì¼ ê²€ìƒ‰
    for filename in os.listdir(UPLOAD_FOLDER):
        if filename.endswith(('.xlsx', '.xls')):
            # í‚¤ì›Œë“œê°€ í¬í•¨ëœ íŒŒì¼ì¸ì§€ í™•ì¸
            if search_keyword.lower() in filename.lower():
                file_path = os.path.join(UPLOAD_FOLDER, filename)
                excel_files.append(file_path)
    
    # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ëª¨ë“  ì—‘ì…€ íŒŒì¼ ê²€ìƒ‰
    if not excel_files:
        for filename in os.listdir(UPLOAD_FOLDER):
            if filename.endswith(('.xlsx', '.xls')):
                file_path = os.path.join(UPLOAD_FOLDER, filename)
                excel_files.append(file_path)
    
    return excel_files

def get_sheet_names(excel_file):
    """
    ì—‘ì…€ íŒŒì¼ì˜ ì‹œíŠ¸ ì´ë¦„ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        excel_file: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì‹œíŠ¸ ì´ë¦„ ëª©ë¡
    """
    try:
        xls = pd.ExcelFile(excel_file)
        return xls.sheet_names
    except Exception as e:
        print(f"ì‹œíŠ¸ ì´ë¦„ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

def read_excel_sheet(excel_file, sheet_name):
    """
    ì—‘ì…€ íŒŒì¼ì˜ íŠ¹ì • ì‹œíŠ¸ë¥¼ DataFrameìœ¼ë¡œ ì½ì–´ì˜µë‹ˆë‹¤.
    
    Args:
        excel_file: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        sheet_name: ì‹œíŠ¸ ì´ë¦„
        
    Returns:
        pandas DataFrame
    """
    try:
        # ëª¨ë“  ì—´ì„ ë¬¸ìì—´ë¡œ ì²˜ë¦¬í•˜ì—¬ ë°ì´í„° ìœ ì‹¤ ë°©ì§€
        df = pd.read_excel(excel_file, sheet_name=sheet_name, dtype=str, na_filter=False)
        
        # NaN ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ëŒ€ì²´
        df = df.fillna('')
        
        return df
    except Exception as e:
        print(f"ì—‘ì…€ ì‹œíŠ¸ '{sheet_name}'ë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return pd.DataFrame()

def extract_keywords_from_query(query):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        
    Returns:
        ì¶”ì¶œëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    # ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ (ê³µë°± ê¸°ì¤€)
    basic_keywords = query.split()
    
    # OpenAIë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
    try:
        if OPENAI_API_KEY:
            messages = [
                {"role": "system", "content": "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. JSON í˜•ì‹ì˜ ë°°ì—´ë¡œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤."},
                {"role": "user", "content": f"ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ì¤‘ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”: {query}"}
            ]
            
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                temperature=0.3,
                max_tokens=150
            )
            
            content = response.choices[0].message.content
            
            # JSON ë¶€ë¶„ ì¶”ì¶œ ì‹œë„
            try:
                # JSON ë°°ì—´ì´ ì§ì ‘ ë°˜í™˜ëœ ê²½ìš°
                keywords = json.loads(content)
                if isinstance(keywords, list):
                    return keywords
            except:
                # í…ìŠ¤íŠ¸ì—ì„œ JSON ë°°ì—´ ì°¾ê¸° ì‹œë„
                match = re.search(r'\[(.*?)\]', content)
                if match:
                    try:
                        keywords = json.loads('[' + match.group(1) + ']')
                        if isinstance(keywords, list):
                            return keywords
                    except:
                        pass
                
                # ì¤„ë°”ê¿ˆì„ ê¸°ì¤€ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„
                if '\n' in content:
                    lines = content.split('\n')
                    keywords = []
                    for line in lines:
                        line = line.strip()
                        if line and not line.startswith(('â€¢', '-', '*', '1.', '2.')):
                            keywords.append(line)
                        elif line.startswith(('â€¢', '-', '*')):
                            keyword = line[1:].strip()
                            keywords.append(keyword)
                        elif re.match(r'^\d+\.', line):
                            keyword = re.sub(r'^\d+\.', '', line).strip()
                            keywords.append(keyword)
                    
                    if keywords:
                        return keywords
    except Exception as e:
        print(f"OpenAIë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # ê¸°ë³¸ í‚¤ì›Œë“œ ë°˜í™˜
    return basic_keywords

def find_relevant_rows(df, keywords):
    """
    í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ í–‰ì„ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        keywords: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ê´€ë ¨ í–‰ì˜ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
    """
    relevant_indices = []
    
    # ê° í–‰ì— ëŒ€í•´ í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
    for idx, row in df.iterrows():
        row_text = ' '.join(str(val).lower() for val in row.values)
        
        # í‚¤ì›Œë“œ ì¼ì¹˜ í™•ì¸
        match_score = 0
        for keyword in keywords:
            if keyword.lower() in row_text:
                match_score += 1
        
        if match_score > 0:
            # (ì¸ë±ìŠ¤, ë§¤ì¹­ ì ìˆ˜) í˜•íƒœë¡œ ì €ì¥
            relevant_indices.append((idx, match_score))
    
    # ë§¤ì¹­ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ì¸ë±ìŠ¤ë§Œ ì¶”ì¶œ
    if relevant_indices:
        relevant_indices.sort(key=lambda x: x[1], reverse=True)
        return [idx for idx, _ in relevant_indices]
    
    # ë§¤ì¹­ë˜ëŠ” ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì²˜ìŒ ëª‡ ê°œ í–‰ë§Œ ë°˜í™˜
    return list(range(min(5, len(df))))

def dataframe_to_text(df):
    """
    ë°ì´í„°í”„ë ˆì„ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        
    Returns:
        ë°ì´í„°í”„ë ˆì„ ë‚´ìš©ì„ í‘œí˜„í•œ ë¬¸ìì—´
    """
    # ë¹ˆ ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬
    if df.empty:
        return "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ë°ì´í„°í”„ë ˆì„ì˜ ì—´ ì´ë¦„ê³¼ ê°’ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    text_parts = []
    
    # í…Œì´ë¸” í—¤ë” ì¶”ê°€
    columns = ' | '.join(df.columns)
    text_parts.append(columns)
    text_parts.append('-' * len(columns))
    
    # ê° í–‰ ë°ì´í„° ì¶”ê°€
    for _, row in df.iterrows():
        row_text = ' | '.join(str(val) for val in row.values)
        text_parts.append(row_text)
    
    return '\n'.join(text_parts)

def format_reference_result(df, search_term):
    """
    ì¡°íšŒ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    
    Args:
        df: ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        search_term: ê²€ìƒ‰ì–´
        
    Returns:
        í¬ë§·íŒ…ëœ ê²°ê³¼ ë¬¸ìì—´
    """
    if df.empty:
        return f"ì•ˆë…•í•˜ì„¸ìš”! ì£„ì†¡í•©ë‹ˆë‹¤ë§Œ, '{search_term}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì‹œê² ì–´ìš”?"
    
    # IP ì£¼ì†Œì¸ì§€ í™•ì¸
    ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
    is_ip_address = bool(re.match(ip_pattern, search_term))
    
    if is_ip_address:
        # IP ì£¼ì†Œ ì „ìš© ì¹œì ˆí•œ ì‘ë‹µ í˜•ì‹
        # ì¤‘ìš” í•„ë“œë¥¼ ì¶”ì¶œí•˜ì—¬ êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„±
        important_fields = ['IP', 'ì£¼ì†Œ', 'ì¥ë¹„', 'ì‚¬ìš©ì', 'ë¶€ì„œ', 'ìš©ë„', 'ìœ„ì¹˜', 'ë‹´ë‹¹', 'ë„¤íŠ¸ì›Œí¬', 'í• ë‹¹ì¼', 'ê¸°ê°„', 'ìƒíƒœ']
        
        # ì¹œì ˆí•œ ì¸ì‚¬ë¡œ ì‹œì‘
        result = f"ì•ˆë…•í•˜ì„¸ìš”! **{search_term}** IP ì£¼ì†Œì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ğŸ˜Š\n\n"
        result += "## ğŸ“Œ IP ì •ë³´ ìš”ì•½\n\n"
        
        # í…Œì´ë¸” ëŒ€ì‹  ì¤‘ìš” ì •ë³´ë¥¼ ë¨¼ì € êµ¬ì¡°í™”í•˜ì—¬ í‘œì‹œ
        info_found = False
        for field in important_fields:
            for col in df.columns:
                if field.lower() in col.lower():
                    # ì²« ë²ˆì§¸ í–‰ì˜ ê°’ë§Œ ì‚¬ìš© (ì¤‘ë³µ ê²°ê³¼ê°€ ìˆì„ ìˆ˜ ìˆìŒ)
                    value = str(df.iloc[0][col]).strip()
                    if value and value.lower() not in ['nan', 'none', '']:
                        result += f"* **{col}**: {value}\n"
                        info_found = True
        
        # ì¤‘ìš” í•„ë“œê°€ ì—†ìœ¼ë©´ ëª¨ë“  í•„ë“œ í‘œì‹œ
        if not info_found:
            result += "### ìƒì„¸ ì •ë³´\n\n"
            for col in df.columns:
                value = str(df.iloc[0][col]).strip()
                if value and value.lower() not in ['nan', 'none', '']:
                    result += f"* **{col}**: {value}\n"
        
        # í•„ìš”í•œ ê²½ìš° ì „ì²´ ë°ì´í„° í…Œì´ë¸” ì¶”ê°€ (ë§ì€ ë°ì´í„°ê°€ ìˆì„ ë•Œ)
        if len(df) > 1 or len(df.columns) > 5:
            result += "\n### ğŸ“Š ì „ì²´ ë°ì´í„° í…Œì´ë¸”\n\n"
            # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ìƒì„±
            md_table = []
            headers = '| ' + ' | '.join(df.columns) + ' |'
            md_table.append(headers)
            separator = '| ' + ' | '.join(['---'] * len(df.columns)) + ' |'
            md_table.append(separator)
            
            for _, row in df.iterrows():
                row_values = '| ' + ' | '.join(str(val) for val in row.values) + ' |'
                md_table.append(row_values)
            
            result += '\n'.join(md_table)
        
        # ì¹œì ˆí•œ ë§ˆë¬´ë¦¬ì™€ ì¶”ê°€ ë„ì›€ ì œì•ˆ
        result += "\n\në‹¤ë¥¸ IP ì£¼ì†Œë‚˜ ë„¤íŠ¸ì›Œí¬ ì •ë³´ê°€ í•„ìš”í•˜ì‹ ê°€ìš”? ì–¸ì œë“  ë¬¼ì–´ë´ ì£¼ì„¸ìš”! ğŸ˜Š"
        
    else:
        # ì¼ë°˜ ê²€ìƒ‰ì–´ì— ëŒ€í•œ ì‘ë‹µ
        # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        md_table = []
        
        # í—¤ë” ì¶”ê°€
        headers = '| ' + ' | '.join(df.columns) + ' |'
        md_table.append(headers)
        
        # êµ¬ë¶„ì„  ì¶”ê°€
        separator = '| ' + ' | '.join(['---'] * len(df.columns)) + ' |'
        md_table.append(separator)
        
        # ë°ì´í„° í–‰ ì¶”ê°€
        for _, row in df.iterrows():
            row_values = '| ' + ' | '.join(str(val) for val in row.values) + ' |'
            md_table.append(row_values)
        
        table_result = '\n'.join(md_table)
        result = f"ì•ˆë…•í•˜ì„¸ìš”! '{search_term}'ì— ëŒ€í•œ ì¡°íšŒ ê²°ê³¼ì…ë‹ˆë‹¤:\n\n{table_result}\n\nì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë´ ì£¼ì„¸ìš”! ğŸ˜Š"
    
    return result

def summarize_dataframe(df):
    """
    ë°ì´í„°í”„ë ˆì„ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        
    Returns:
        ìš”ì•½ ë¬¸ìì—´
    """
    if df.empty:
        return "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    md_table = []
    
    # í—¤ë” ì¶”ê°€
    headers = '| ' + ' | '.join(df.columns) + ' |'
    md_table.append(headers)
    
    # êµ¬ë¶„ì„  ì¶”ê°€
    separator = '| ' + ' | '.join(['---'] * len(df.columns)) + ' |'
    md_table.append(separator)
    
    # ë°ì´í„° í–‰ ì¶”ê°€ (ìµœëŒ€ 5ê°œ í–‰ë§Œ)
    for _, row in df.head(5).iterrows():
        row_values = '| ' + ' | '.join(str(val) for val in row.values) + ' |'
        md_table.append(row_values)
    
    result = '\n'.join(md_table)
    
    # í–‰ì´ ë” ìˆìœ¼ë©´ ë©”ì‹œì§€ ì¶”ê°€
    if len(df) > 5:
        result += f"\n\n(ì´ {len(df)}ê°œ ì¤‘ 5ê°œ ê²°ê³¼ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.)"
    
    return result

def process_excel_query(query):
    """
    ì—‘ì…€ ê¸°ë°˜ ì²˜ë¦¬ íë¦„ì— ë”°ë¼ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    1. ì „ì²´_ê´€ë¦¬_ì‹œíŠ¸ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì—…ë¬´ ìœ í˜•/í‚¤ì›Œë“œ íŒŒì•…
    2. ì—°ê²° ì‹œíŠ¸ë¡œ ì´ë™í•˜ì—¬ í•„ìš” ë°ì´í„° ì°¾ê¸°
    3. ì²˜ë¦¬ ë°©ì‹ì— ë§ê²Œ ì‘ë‹µ ìƒì„±
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        
    Returns:
        ì²˜ë¦¬ ê²°ê³¼ì™€ ì‘ë‹µ ë‚´ìš©ì„ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
    """
    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
    result = {
        "found": False,
        "response": "",
        "from_excel": True,
        "category": "",
        "sheet_used": "",
        "response_type": ""
    }
    
    # ì—‘ì…€ íŒŒì¼ ê²€ìƒ‰
    excel_files = find_excel_files()
    if not excel_files:
        result["response"] = "ì°¸ì¡°í•  ì—‘ì…€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        result["from_excel"] = False
        return result
    
    # ì²« ë²ˆì§¸ ì—‘ì…€ íŒŒì¼ ì‚¬ìš©
    excel_file = excel_files[0]
    print(f"ì—‘ì…€ íŒŒì¼ ì‚¬ìš©: {excel_file}")
    
    # ì‹œíŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    sheet_names = get_sheet_names(excel_file)
    if not sheet_names:
        result["response"] = "ì—‘ì…€ íŒŒì¼ì—ì„œ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        result["from_excel"] = False
        return result
    
    print(f"ì‹œíŠ¸ ëª©ë¡: {sheet_names}")
    
    # IP ì£¼ì†Œ ì‹ ì²­ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
    ip_application_keywords = ["ip ì£¼ì†Œ ì‹ ì²­", "ip ì‹ ì²­", "ip address ì‹ ì²­", "ip í• ë‹¹", "ì•„ì´í”¼ ì‹ ì²­", "ip ì‹ ì²­ ë°©ë²•"]
    is_ip_application_query = any(keyword.lower() in query.lower() for keyword in ip_application_keywords)
    
    # IP ì£¼ì†Œ ì‹ ì²­ ê´€ë ¨ ì¿¼ë¦¬ì¸ ê²½ìš° ì ˆì°¨_ì•ˆë‚´ ì‹œíŠ¸ë¥¼ ìš°ì„  í™œìš©
    if is_ip_application_query and 'ì ˆì°¨_ì•ˆë‚´' in sheet_names:
        print("IP ì£¼ì†Œ ì‹ ì²­ ê´€ë ¨ ì¿¼ë¦¬ ê°ì§€ - ì ˆì°¨_ì•ˆë‚´ ì‹œíŠ¸ ì‚¬ìš©")
        
        # ì ˆì°¨_ì•ˆë‚´ ì‹œíŠ¸ì—ì„œ ê´€ë ¨ ì •ë³´ ì°¾ê¸°
        procedure_df = read_excel_sheet(excel_file, 'ì ˆì°¨_ì•ˆë‚´')
        
        # ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ ì²˜ë¦¬
        if not procedure_df.empty:
            for idx, row in procedure_df.iterrows():
                # IP ê´€ë ¨ í–‰ì¸ì§€ í™•ì¸ ('ì ˆì°¨ êµ¬ë¶„' ì—´ì— 'IP' í¬í•¨ ì—¬ë¶€ í™•ì¸)
                procedure_type = str(row.get('ì ˆì°¨ êµ¬ë¶„', '')).lower()
                if 'ip' in procedure_type and any(term in procedure_type for term in ['ì£¼ì†Œ', 'ì‹ ì²­']):
                    # IP ì£¼ì†Œ ì‹ ì²­ ì ˆì°¨ ì •ë³´ ì°¾ìŒ
                    result["found"] = True
                    result["category"] = "IP ì£¼ì†Œ ì‹ ì²­ ì ˆì°¨"
                    result["sheet_used"] = "ì ˆì°¨_ì•ˆë‚´"
                    result["response_type"] = "ì ˆì°¨ ì•ˆë‚´"
                    
                    # ì‘ë‹µ êµ¬ì„±ì„ ìœ„í•œ ë°ì´í„° ì¶”ì¶œ
                    summary = str(row.get('ìš”ì•½ ì‘ë‹µ', ''))
                    details = str(row.get('ìƒì„¸ ì•ˆë‚´', ''))
                    dept = str(row.get('ë‹´ë‹¹ ë¶€ì„œ', ''))
                    links = str(row.get('ê´€ë ¨ ë¬¸ì„œ/ë§í¬', ''))
                    
                    # ì‘ë‹µ êµ¬ì„±
                    response = f"""
# IP ì£¼ì†Œ ì‹ ì²­ ì ˆì°¨ ì•ˆë‚´

## ìš”ì•½
{summary}

## ì‹ ì²­ ì ˆì°¨
{details}

## ë‹´ë‹¹ ë¶€ì„œ
**{dept}**

## ê´€ë ¨ ë§í¬
{links}

ì¶”ê°€ ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”?
"""
                    result["response"] = response
                    return result
    
    # 1. ì „ì²´_ê´€ë¦¬_ì‹œíŠ¸ ê²€ìƒ‰
    main_sheet = None
    for sheet in sheet_names:
        if "ì „ì²´" in sheet and "ê´€ë¦¬" in sheet:
            main_sheet = sheet
            break
    
    # ì „ì²´ ê´€ë¦¬ ì‹œíŠ¸ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì‹œíŠ¸ ì‚¬ìš©
    if not main_sheet:
        main_sheet = sheet_names[0]
    
    print(f"ë©”ì¸ ì‹œíŠ¸ ì‚¬ìš©: {main_sheet}")
    
    # ì „ì²´ ê´€ë¦¬ ì‹œíŠ¸ ë°ì´í„° ì½ê¸°
    main_df = read_excel_sheet(excel_file, main_sheet)
    if main_df.empty:
        result["response"] = f"'{main_sheet}' ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        result["from_excel"] = False
        return result
    
    # ì „ì²´ ê´€ë¦¬ ì‹œíŠ¸ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš© ì°¾ê¸°
    matched_row = None
    target_sheet = None
    category = None
    response_type = "DB ì‘ë‹µ (ìì—°ì–´)"  # ê¸°ë³¸ ì‘ë‹µ ìœ í˜•
    
    # ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (OpenAI ì‚¬ìš©)
    query_keywords = extract_keywords_from_query(query)
    print(f"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {query_keywords}")
    
    # ê° í–‰ì„ í™•ì¸í•˜ë©° ë§¤ì¹­ë˜ëŠ” ë‚´ìš© ì°¾ê¸°
    for idx, row in main_df.iterrows():
        # í•„ìš”í•œ ì—´ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if 'êµ¬ë¶„' in main_df.columns and 'ì¹´í…Œê³ ë¦¬' in main_df.columns:
            row_category = str(row.get('êµ¬ë¶„', '')) + " " + str(row.get('ì¹´í…Œê³ ë¦¬', ''))
            keywords = []
            
            # í‚¤ì›Œë“œ ì—´ í™•ì¸
            for col in main_df.columns:
                if 'í‚¤ì›Œë“œ' in col or 'ê²€ìƒ‰ì–´' in col:
                    # ì•ˆì „í•˜ê²Œ Seriesë¥¼ ë¬¸ìì—´ë¡œ ì²˜ë¦¬ (Truth value ì˜¤ë¥˜ ë°©ì§€)
                    cell_value = str(row[col])
                    if cell_value and cell_value.strip() and cell_value.lower() != 'nan':
                        keywords.extend(cell_value.split(','))
            
            # ì‹œíŠ¸ ì •ë³´ ì—´ í™•ì¸
            sheet_col = None
            for col in main_df.columns:
                if 'ì‹œíŠ¸' in col or 'ë§í¬' in col:
                    sheet_col = col
                    break
            
            # ìš”ì•½ ë‚´ìš© ì—´ í™•ì¸
            summary_col = None
            for col in main_df.columns:
                if 'ìš”ì•½' in col or 'ì„¤ëª…' in col:
                    summary_col = col
                    break
            
            # ì²˜ë¦¬ ë°©ì‹ ì—´ í™•ì¸
            response_type_col = None
            for col in main_df.columns:
                if 'ì²˜ë¦¬' in col or 'ë°©ì‹' in col:
                    response_type_col = col
                    break
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
            match_found = False
            for kw in query_keywords:
                if any(kw.lower() in keyword.lower() for keyword in keywords):
                    match_found = True
                    break
            
            if match_found:
                matched_row = row
                category = row_category
                
                # ì—°ê²° ì‹œíŠ¸ ì •ë³´ ì¶”ì¶œ
                if sheet_col:
                    target_sheet_info = str(row[sheet_col])
                    if target_sheet_info and target_sheet_info.strip() and target_sheet_info.lower() != 'nan':
                        # "XX ì‹œíŠ¸ ì°¸ì¡°" í˜•ì‹ì—ì„œ ì‹œíŠ¸ ì´ë¦„ ì¶”ì¶œ
                        sheet_match = re.search(r'([ê°€-í£A-Za-z0-9_]+)[\s_]ì‹œíŠ¸', target_sheet_info)
                        if sheet_match:
                            target_sheet = sheet_match.group(1)
                
                # ì²˜ë¦¬ ë°©ì‹ ì •ë³´ ì¶”ì¶œ
                if response_type_col:
                    response_type_value = str(row[response_type_col])
                    if response_type_value and response_type_value.strip() and response_type_value.lower() != 'nan':
                        response_type = response_type_value
                
                break
    
    # ë§¤ì¹­ë˜ëŠ” ë‚´ìš©ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
    if not isinstance(matched_row, pd.Series) or not target_sheet:
        # ì¼ë‹¨ ê¸°ë³¸ ì²˜ë¦¬ë¡œ ì „í™˜í•˜ê³  ì²« ë²ˆì§¸ ë‚´ìš© ì‹œíŠ¸ ì‚¬ìš©
        alternative_sheet = None
        for sheet in sheet_names:
            if "ì „ì²´" not in sheet and "ê´€ë¦¬" not in sheet and sheet != main_sheet:
                alternative_sheet = sheet
                break
        
        if alternative_sheet:
            target_sheet = alternative_sheet
            result["sheet_used"] = "ëŒ€ì²´ ì‹œíŠ¸ ì‚¬ìš©: " + target_sheet
        else:
            result["response"] = "ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            result["from_excel"] = False
            return result
    
    # 2. ì—°ê²° ì‹œíŠ¸ë¡œ ì´ë™í•˜ì—¬ í•„ìš” ë°ì´í„° ì°¾ê¸°
    # ì‹¤ì œ ì‹œíŠ¸ ì´ë¦„ ì°¾ê¸° (ë¶€ë¶„ ë§¤ì¹­)
    actual_sheet = None
    for sheet in sheet_names:
        if target_sheet in sheet:
            actual_sheet = sheet
            break
    
    if not actual_sheet:
        actual_sheet = target_sheet  # ì§ì ‘ ë§¤ì¹­ ì‹œë„
    
    print(f"ì—°ê²° ì‹œíŠ¸ ì‚¬ìš©: {actual_sheet}")
    
    # ì—°ê²° ì‹œíŠ¸ ë°ì´í„° ì½ê¸°
    sheet_df = read_excel_sheet(excel_file, actual_sheet)
    if sheet_df.empty:
        result["response"] = f"'{actual_sheet}' ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        result["from_excel"] = False
        return result
    
    # 3. ì²˜ë¦¬ ë°©ì‹ì— ë§ê²Œ ì‘ë‹µ ìƒì„±
    result["found"] = True
    result["category"] = category
    result["sheet_used"] = actual_sheet
    result["response_type"] = response_type
    
    # ì²˜ë¦¬ ë°©ì‹ì— ë”°ë¥¸ ë¶„ê¸° ì²˜ë¦¬
    if "ìì—°ì–´" in response_type:
        # DB ì‘ë‹µ (ìì—°ì–´): ë‹µë³€ìš© í…ìŠ¤íŠ¸ë¥¼ ìì—°ì–´ë¡œ ì‘ë‹µ
        response = generate_natural_language_response(query, sheet_df, query_keywords)
        result["response"] = response
    
    elif "ì°¸ì¡°" in response_type:
        # DB ì°¸ì¡° ì‘ë‹µ: íŠ¹ì • í•­ëª©ì„ í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰ í›„ ì‘ë‹µ
        response = generate_reference_response(query, sheet_df, query_keywords)
        result["response"] = response
    
    elif "ì¡°ê±´" in response_type:
        # DB + ì¡°ê±´ ì‘ë‹µ: ì¡°ê±´ì„ íŒë‹¨í•´ì„œ ì‘ë‹µ
        response = generate_conditional_response(query, sheet_df, query_keywords)
        result["response"] = response
    
    elif "ëŒ€ì™¸ê³„" in response_type:
        # ëŒ€ì™¸ê³„ ì¡°íšŒ ì‘ë‹µ: ëŒ€ì™¸ê³„ ì •ë³´ ì¡°íšŒ ì‘ë‹µ
        response = generate_external_system_response(query, sheet_df, query_keywords)
        result["response"] = response
    
    else:
        # ê¸°ë³¸ ì‘ë‹µ ë°©ì‹
        response = generate_natural_language_response(query, sheet_df, query_keywords)
        result["response"] = response
    
    return result

def generate_natural_language_response(query, df, keywords):
    """
    ìì—°ì–´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        df: ë°ì´í„°í”„ë ˆì„
        keywords: ì¶”ì¶œëœ í‚¤ì›Œë“œ
        
    Returns:
        ìƒì„±ëœ ì‘ë‹µ
    """
    # IP ì£¼ì†Œ ì‹ ì²­ ê´€ë ¨ ì¿¼ë¦¬ì¸ì§€ í™•ì¸
    is_ip_address_query = any(keyword.lower() in query.lower() for keyword in 
                             ["ip ì£¼ì†Œ ì‹ ì²­", "ip ì‹ ì²­", "ipì£¼ì†Œ", "ì•„ì´í”¼ ì‹ ì²­", "ip í• ë‹¹ ìš”ì²­", "ì•„ì´í”¼", "ip ë°œê¸‰"])
    
    # ê´€ë ¨ í–‰ ì°¾ê¸°
    relevant_rows = []
    
    # IP ì£¼ì†Œ ì‹ ì²­ ì¿¼ë¦¬ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
    if is_ip_address_query:
        # ì ˆì°¨_ì•ˆë‚´ ì‹œíŠ¸ì¸ ê²½ìš° (í…Œì´ë¸” êµ¬ì¡°ê°€ ë‹¤ë¦„)
        if 'ì ˆì°¨ êµ¬ë¶„' in df.columns:
            for idx, row in df.iterrows():
                # ì ˆì°¨ êµ¬ë¶„ì´ë‚˜ ì§ˆë¬¸ í‚¤ì›Œë“œì— IP ê´€ë ¨ ë‹¨ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
                procedure_type = str(row.get('ì ˆì°¨ êµ¬ë¶„', '')).lower()
                question_keywords = str(row.get('ì§ˆë¬¸ í‚¤ì›Œë“œ', '')).lower()
                
                if 'ip' in procedure_type and any(term in procedure_type for term in ['ì£¼ì†Œ', 'ì‹ ì²­']):
                    relevant_rows.append(idx)
                elif 'ip' in question_keywords:
                    relevant_rows.append(idx)
        # ëŒ€ì™¸ê³„_ì—°ë™ ì‹œíŠ¸ ë“± ë‹¤ë¥¸ ì‹œíŠ¸ì¸ ê²½ìš°
        else:
            # ë°ì´í„°ê°€ 'ì ˆì°¨' ë˜ëŠ” 'ë°©ë²•'ì— ê´€í•œ ë‚´ìš©ì¸ì§€ í™•ì¸
            for idx, row in df.iterrows():
                row_text = ' '.join(str(val).lower() for val in row.values)
                
                if 'ip' in row_text and any(term in query.lower() for term in ['ë°©ë²•', 'ì ˆì°¨', 'ì‹ ì²­', 'ì–´ë–»ê²Œ']):
                    # ì ˆì°¨, ë°©ë²•ì— ê´€í•œ ì¿¼ë¦¬ë¼ë©´ ë‹´ë‹¹ë¶€ì„œ, ë‹´ë‹¹ì ì •ë³´ í¬í•¨
                    if any(col for col in df.columns if 'ë¶€ì„œ' in col or 'ë‹´ë‹¹' in col):
                        relevant_rows.append(idx)
    
    # ì¼ë°˜ í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ í–‰ì„ ëª» ì°¾ì•˜ê±°ë‚˜ IP ì£¼ì†Œ ì‹ ì²­ ì¿¼ë¦¬ê°€ ì•„ë‹Œ ê²½ìš°
    if not relevant_rows:
        relevant_rows = find_relevant_rows(df, keywords)
    
    if not relevant_rows:
        return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ë°ì´í„°í”„ë ˆì„ì˜ ë‚´ìš©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    df_info = dataframe_to_text(df.iloc[relevant_rows])
    
    # OpenAIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±
    try:
        if OPENAI_API_KEY:
            # IP ì£¼ì†Œ ì‹ ì²­ ì¿¼ë¦¬ì¸ ê²½ìš° íŠ¹í™”ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            if is_ip_address_query:
                system_prompt = """
                ì‹ í•œì€í–‰ ë„¤íŠ¸ì›Œí¬ ì§€ì› ì±—ë´‡ìœ¼ë¡œì„œ, IP ì£¼ì†Œ ì‹ ì²­ ì ˆì°¨ì— ê´€í•œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.

                *** ì¤‘ìš” ì‘ë‹µ ê°€ì´ë“œë¼ì¸ ***
                1. IP ì£¼ì†Œ ì‹ ì²­ ì ˆì°¨ì™€ ë°©ë²•ì— ì´ˆì ì„ ë§ì¶°ì„œ ì„¤ëª…í•˜ì„¸ìš”.
                2. ì™¸ë¶€ ê¸°ê´€ ì •ë³´ëŠ” í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì–¸ê¸‰í•˜ê³ , ì£¼ìš” ë‚´ìš©ì€ ì‹ ì²­ ì ˆì°¨ ìì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.
                3. ë‹´ë‹¹ ë¶€ì„œì™€ ë‹´ë‹¹ì ì •ë³´ë¥¼ ëª…í™•íˆ ì œê³µí•˜ì„¸ìš”.
                4. ë‹¨ê³„ë³„ë¡œ ì ˆì°¨ë¥¼ ì„¤ëª…í•˜ê³ , ê° ë‹¨ê³„ë§ˆë‹¤ ìˆ«ìë¥¼ ë§¤ê²¨ ì•ˆë‚´í•˜ì„¸ìš”.
                5. í•„ìš”í•œ ì„œë¥˜ë‚˜ ì •ë³´, ì†Œìš” ì‹œê°„ ë“± ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”.
                
                ì‘ë‹µ í˜•ì‹:
                - ì£¼ìš” ì œëª©ì€ ## ìˆ˜ì¤€ìœ¼ë¡œ, ë¶€ì œëª©ì€ ### ìˆ˜ì¤€ìœ¼ë¡œ êµ¬ì¡°í™”
                - ë‹¨ê³„ë³„ ì ˆì°¨ëŠ” ìˆ«ìë¡œ êµ¬ë¶„
                - ë‹´ë‹¹ì/ë‹´ë‹¹ë¶€ì„œ ì •ë³´ëŠ” êµµê²Œ í‘œì‹œ
                - ë§ˆì§€ë§‰ì— ì¶”ê°€ ì§ˆë¬¸ì´ ìˆëŠ”ì§€ í™•ì¸
                """
            else:
                # ì¼ë°˜ ì§ˆë¬¸ì— ëŒ€í•œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
                system_prompt = """
                ì‹ í•œì€í–‰ ë„¤íŠ¸ì›Œí¬ ë‹´ë‹¹ì ì—­í• ì„ í•˜ëŠ” ì±—ë´‡ìœ¼ë¡œ, ë„¤íŠ¸ì›Œí¬ ì‹œìŠ¤í…œ, ì¥ë¹„, IP, ëŒ€ì™¸ê³„, ë³´ì•ˆ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.
                ì£¼ì–´ì§„ ì—‘ì…€ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.
                ê°„ê²°í•˜ê³  ì§ê´€ì ì¸ ì„¤ëª…ì„ ì œê³µí•˜ë˜, ì¤‘ìš”í•œ ì„¸ë¶€ì‚¬í•­ì€ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
                
                ì‘ë‹µ ìŠ¤íƒ€ì¼:
                - ì‹œì‘ì€ ì¹œê·¼í•œ ì¸ì‚¬ë‚˜ ì‚¬ìš©ì ìƒí™© ì¸ì‹ìœ¼ë¡œ ì‹œì‘ (ì˜ˆ: "ë„¤! NexG ì¥ë¹„ì— IPë¥¼ ì„¤ì •í•˜ì‹œë ¤ë©´...")
                - ì£¼ìš” ì œëª©ì€ ## ìˆ˜ì¤€ìœ¼ë¡œ, ë¶€ì œëª©ì€ ### ìˆ˜ì¤€ìœ¼ë¡œ êµ¬ì¡°í™”
                - ëŒ€í™”í˜• ë¬¸ì²´ë¡œ ì •ë³´ ì „ë‹¬ (ì˜ˆ: "ë¨¼ì € ì„¤ì • ëª¨ë“œë¡œ ë“¤ì–´ê°€ë³¼ê²Œìš”", "ë‹¤ìŒìœ¼ë¡œ ì´ë ‡ê²Œ í•´ë³´ì„¸ìš”")
                - ì¤‘ìš” ì •ë³´ëŠ” **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°
                - ì‚¬ìš©ìì—ê²Œ ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ í™•ì¸ì´ í•„ìš”í•œ ê²½ìš° ë§ˆì§€ë§‰ì— ë¬¼ì–´ë´„
                """
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ì‚¬ìš©ì ì§ˆë¬¸: {query}\n\nì—‘ì…€ ë°ì´í„°:\n{df_info}"}
            ]
            
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                temperature=0.7,
                max_tokens=800
            )
            
            return response.choices[0].message.content
    except Exception as e:
        print(f"OpenAIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì œê³µ
    return summarize_dataframe(df.iloc[relevant_rows])

def generate_reference_response(query, df, keywords):
    """
    DB ì°¸ì¡° ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤ (íŠ¹ì • í•­ëª© ì§ì ‘ ê²€ìƒ‰).
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        df: ë°ì´í„°í”„ë ˆì„
        keywords: ì¶”ì¶œëœ í‚¤ì›Œë“œ
        
    Returns:
        ìƒì„±ëœ ì‘ë‹µ
    """
    # IP ì£¼ì†Œ í˜•ì‹ ê²€ìƒ‰
    ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
    ip_matches = re.findall(ip_pattern, query)
    
    # IP ì£¼ì†Œê°€ ìˆìœ¼ë©´ í•´ë‹¹ IPë¡œ ê²€ìƒ‰
    if ip_matches:
        target_ip = ip_matches[0]
        
        # ê° ì—´ì—ì„œ IP ì£¼ì†Œ ê²€ìƒ‰
        for col in df.columns:
            # IP ì£¼ì†Œ ì—´ë¡œ ì¶”ì •ë˜ëŠ” ì—´ ì°¾ê¸°
            if any(kw in col.lower() for kw in ['ip', 'ì£¼ì†Œ', 'address']):
                mask = df[col].str.contains(target_ip, regex=False, na=False)
                if mask.any():
                    matched_rows = df[mask]
                    result = format_reference_result(matched_rows, target_ip)
                    return result
        
        # ëª¨ë“  ì—´ì—ì„œ IP ê²€ìƒ‰
        for col in df.columns:
            mask = df[col].str.contains(target_ip, regex=False, na=False)
            if mask.any():
                matched_rows = df[mask]
                result = format_reference_result(matched_rows, target_ip)
                return result
    
    # ì¼ë°˜ í‚¤ì›Œë“œ ê²€ìƒ‰
    relevant_rows = find_relevant_rows(df, keywords)
    
    if not relevant_rows:
        return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ë°ì´í„°í”„ë ˆì„ì˜ ë‚´ìš©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    df_info = dataframe_to_text(df.iloc[relevant_rows])
    
    # OpenAIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±
    try:
        if OPENAI_API_KEY:
            messages = [
                {"role": "system", "content": """
                ì‹ í•œì€í–‰ ë„¤íŠ¸ì›Œí¬ ë‹´ë‹¹ì ì—­í• ì„ í•˜ëŠ” ì±—ë´‡ìœ¼ë¡œ, ì‚¬ìš©ìê°€ íŠ¹ì • ì •ë³´ë¥¼ ì¡°íšŒí•˜ë ¤ê³  í•©ë‹ˆë‹¤.
                ì—‘ì…€ ë°ì´í„°ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì•„ í‘œ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ ë°˜í™˜í•´ì£¼ì„¸ìš”.
                ì •ë³´ ì¡°íšŒ ê²°ê³¼ë¥¼ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ í‘œì‹œí•˜ë˜, í•„ìš”í•œ ëª¨ë“  ì •ë³´ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
                í‘œ í˜•ì‹ì€ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.
                
                ì‘ë‹µ í˜•ì‹:
                1. ì‹œì‘ì€ ì¹œê·¼í•œ ì¸ì‚¬ë¡œ ì‹œì‘
                2. ì¡°íšŒ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ì œê³µ
                3. í•„ìš”í•œ ê²½ìš° ê²°ê³¼ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª… ì¶”ê°€
                """},
                {"role": "user", "content": f"ì‚¬ìš©ì ì§ˆë¬¸(ì •ë³´ ì¡°íšŒ ìš”ì²­): {query}\n\nì—‘ì…€ ë°ì´í„°:\n{df_info}"}
            ]
            
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                temperature=0.7,
                max_tokens=800
            )
            
            return response.choices[0].message.content
    except Exception as e:
        print(f"OpenAIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì œê³µ
    return summarize_dataframe(df.iloc[relevant_rows])

def generate_conditional_response(query, df, keywords):
    """
    DB + ì¡°ê±´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤ (ì¡°ê±´ íŒë‹¨).
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        df: ë°ì´í„°í”„ë ˆì„
        keywords: ì¶”ì¶œëœ í‚¤ì›Œë“œ
        
    Returns:
        ìƒì„±ëœ ì‘ë‹µ
    """
    # ê´€ë ¨ í–‰ ì°¾ê¸°
    relevant_rows = find_relevant_rows(df, keywords)
    
    if not relevant_rows:
        return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ë°ì´í„°í”„ë ˆì„ì˜ ë‚´ìš©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    df_info = dataframe_to_text(df.iloc[relevant_rows])
    
    # OpenAIë¥¼ ì‚¬ìš©í•œ ì¡°ê±´ë¶€ ì‘ë‹µ ìƒì„±
    try:
        if OPENAI_API_KEY:
            messages = [
                {"role": "system", "content": """
                ì‹ í•œì€í–‰ ë„¤íŠ¸ì›Œí¬ ë‹´ë‹¹ì ì—­í• ì„ í•˜ëŠ” ì±—ë´‡ìœ¼ë¡œ, ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ì¡°ê±´ì— ë”°ë¥¸ íŒë‹¨ì´ í•„ìš”í•©ë‹ˆë‹¤.
                ì£¼ì–´ì§„ ì—‘ì…€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, ì¡°ê±´ì„ íŒë‹¨í•˜ê³  ì ì ˆí•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
                ì˜ˆë¥¼ ë“¤ì–´ 'IP ì¥ê¸°ë¯¸ì‚¬ìš© ì—¬ë¶€', 'ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ' ë“±ì˜ ì¡°ê±´ì„ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.
                ëª…í™•í•œ ê²°ë¡ ê³¼ í•„ìš”í•œ ì¡°ì¹˜ ì‚¬í•­ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
                
                ì‘ë‹µ í˜•ì‹:
                1. ì‹œì‘ì€ ì‚¬ìš©ì ì§ˆë¬¸ ì¸ì‹ìœ¼ë¡œ ì‹œì‘
                2. ì¡°ê±´ íŒë‹¨ ê²°ê³¼ ì„¤ëª…
                3. í•„ìš”í•œ ì¡°ì¹˜ ì‚¬í•­ ì•ˆë‚´
                4. ë§ˆë¬´ë¦¬ ë§ ë˜ëŠ” í›„ì† ì§ˆë¬¸
                """},
                {"role": "user", "content": f"ì‚¬ìš©ì ì§ˆë¬¸(ì¡°ê±´ íŒë‹¨ ìš”ì²­): {query}\n\nì—‘ì…€ ë°ì´í„°:\n{df_info}"}
            ]
            
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                temperature=0.7,
                max_tokens=800
            )
            
            return response.choices[0].message.content
    except Exception as e:
        print(f"OpenAIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì œê³µ
    return summarize_dataframe(df.iloc[relevant_rows])

def generate_external_system_response(query, df, keywords):
    """
    ëŒ€ì™¸ê³„ ì¡°íšŒ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        df: ë°ì´í„°í”„ë ˆì„
        keywords: ì¶”ì¶œëœ í‚¤ì›Œë“œ
        
    Returns:
        ìƒì„±ëœ ì‘ë‹µ
    """
    # í•„ìš”í•œ ìƒì„¸ ì •ë³´ í•„ë“œ í™•ì¸
    required_fields = ['íšŒì„ ì‚¬', 'íšŒì„  ë²ˆí˜¸', 'íšŒì„ ë²ˆí˜¸', 'ì„œë¹„ìŠ¤', 'ì„œë¹„ìŠ¤ ì¢…ë¥˜', 'ìš´ì˜ IP', 'ìš´ì˜IP', 
                     'ê°œë°œ IP', 'ê°œë°œIP', 'ë‹´ë‹¹ ë¶€ì„œ', 'ë‹´ë‹¹ë¶€ì„œ', 'ë‹¹í–‰ ë‹´ë‹¹ì', 'ë‹´ë‹¹ì', 
                     'ê¸°ê´€ ë‹´ë‹¹ì', 'ê¸°ê´€ë‹´ë‹¹ì', 'ê¸°ê´€ ì£¼ì†Œ', 'ê¸°ê´€ì£¼ì†Œ', 'IP']
    
    # ê¸°ê´€ëª… í™•ì¸ (ì„œì¹˜ í‚¤ì›Œë“œ)
    org_keywords = ['ì¹´ë“œ', 'ìƒëª…', 'ìºí”¼íƒˆ', 'ì¦ê¶Œ', 'ì€í–‰', 'ë³´í—˜', 'ê¸ˆìœµ', 'ê³µì‚¬', 'ê³µë‹¨', 
                    'í˜‘íšŒ', 'ì—°í•©íšŒ', 'ì„¼í„°', 'ê¸°ê´€', 'íšŒì‚¬', 'ë‹¨ì²´', 'ì¡°í•©']
    
    # ì¿¼ë¦¬ì—ì„œ ê¸°ê´€ëª… ì¶”ì¶œ (ì˜ˆ: "ì‹ í•œì¹´ë“œ")
    searched_org = None
    for kw in keywords:
        # 1. ì§ì ‘ì ì¸ ê¸°ê´€ëª… í‚¤ì›Œë“œ í™•ì¸ (ì˜ˆ: ì‹ í•œì¹´ë“œ, KBì¦ê¶Œ ë“±)
        is_org = False
        for org_kw in org_keywords:
            if org_kw in kw:
                is_org = True
                searched_org = kw
                break
                
        # 2. "ì‹ í•œ" "KB" ë“±ì˜ ì§§ì€ ê¸°ê´€ëª…ë„ ì²´í¬
        if len(kw) >= 2 and not is_org:
            # ê¸°ê´€ëª… ì»¬ëŸ¼ì„ ì°¾ì•„ì„œ ê²€ìƒ‰
            org_column = None
            for col in df.columns:
                if 'ê¸°ê´€' in col or 'íšŒì‚¬' in col or 'ì—…ì²´' in col:
                    org_column = col
                    break
            
            if org_column:
                for idx, row in df.iterrows():
                    org_value = str(row[org_column]).lower()
                    if kw.lower() in org_value and len(kw) >= 2:
                        searched_org = str(row[org_column])
                        break
    
    print(f"ê²€ìƒ‰ëœ ê¸°ê´€ëª…: {searched_org}")
    
    # ê´€ë ¨ í–‰ ì°¾ê¸° (ê¸°ê´€ëª… ìš°ì„ , ê·¸ ë‹¤ìŒ í‚¤ì›Œë“œ)
    relevant_rows = []
    
    # 1. ê¸°ê´€ëª…ì´ ìˆìœ¼ë©´ ë¨¼ì € ê¸°ê´€ëª…ìœ¼ë¡œ ê²€ìƒ‰
    if searched_org:
        for idx, row in df.iterrows():
            row_text = ' '.join(str(val).lower() for val in row.values)
            if searched_org.lower() in row_text.lower():
                relevant_rows.append(idx)
    
    # 2. ê¸°ê´€ëª…ìœ¼ë¡œ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ê¸°ê´€ëª…ì´ ì—†ìœ¼ë©´ ì¼ë°˜ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
    if not relevant_rows:
        relevant_rows = find_relevant_rows(df, keywords)
    
    if not relevant_rows:
        return f"ìš”ì²­í•˜ì‹  ëŒ€ì™¸ê³„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¢€ ë” êµ¬ì²´ì ì¸ ê¸°ê´€ëª…ì´ë‚˜ í‚¤ì›Œë“œë¡œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."
    
    # ê²€ìƒ‰ëœ ê²°ê³¼ ë°ì´í„°
    result_data = df.iloc[relevant_rows]
    
    # í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    org_name = searched_org if searched_org else "ìš”ì²­í•˜ì‹  ê¸°ê´€"
    
    # ì¡°íšŒ ê²°ê³¼ë¥¼ ìì—°ì–´ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±
    info_dict = {}
    
    # ë°ì´í„°í”„ë ˆì„ì˜ ì»¬ëŸ¼ëª…-ê°’ì„ ë§¤í•‘
    for col in result_data.columns:
        col_lower = col.lower()
        
        # í•„ë“œ ë§¤í•‘
        field_key = None
        
        if 'íšŒì„ ì‚¬' in col_lower:
            field_key = 'íšŒì„ ì‚¬'
        elif any(kw in col_lower for kw in ['íšŒì„  ë²ˆí˜¸', 'íšŒì„ ë²ˆí˜¸', 'ì „í™”ë²ˆí˜¸']):
            field_key = 'íšŒì„  ë²ˆí˜¸'
        elif any(kw in col_lower for kw in ['ì„œë¹„ìŠ¤', 'ì„œë¹„ìŠ¤ ì¢…ë¥˜', 'ì¢…ë¥˜']):
            field_key = 'ì„œë¹„ìŠ¤ ì¢…ë¥˜'
        elif any(kw in col_lower for kw in ['ìš´ì˜ ip', 'ìš´ì˜ip', 'ìš´ì˜ì£¼ì†Œ']):
            field_key = 'ìš´ì˜ IP'
        elif any(kw in col_lower for kw in ['ê°œë°œ ip', 'ê°œë°œip', 'ê°œë°œì£¼ì†Œ']):
            field_key = 'ê°œë°œ IP'
        elif 'ë‹´ë‹¹ ë¶€ì„œ' in col_lower or 'ë‹´ë‹¹ë¶€ì„œ' in col_lower:
            field_key = 'ë‹¹í–‰ ë‹´ë‹¹ ë¶€ì„œ'
        elif any(kw in col_lower for kw in ['ë‹¹í–‰ ë‹´ë‹¹ì', 'ë‹´ë‹¹ì']):
            field_key = 'ë‹¹í–‰ ë‹´ë‹¹ì'
        elif any(kw in col_lower for kw in ['ê¸°ê´€ ë‹´ë‹¹ì', 'ê¸°ê´€ë‹´ë‹¹ì', 'ì™¸ë¶€ë‹´ë‹¹ì']):
            field_key = 'ê¸°ê´€ ë‹´ë‹¹ì'
        elif any(kw in col_lower for kw in ['ê¸°ê´€ ì£¼ì†Œ', 'ê¸°ê´€ì£¼ì†Œ', 'ì£¼ì†Œ']):
            field_key = 'ê¸°ê´€ ì£¼ì†Œ'
        elif 'ip' in col_lower and 'ip' not in info_dict:
            # ì¼ë°˜ IP ì»¬ëŸ¼ì´ ìˆê³  ì•„ì§ IP ì •ë³´ê°€ ì—†ìœ¼ë©´
            field_key = 'IP' 
        
        if field_key and field_key not in info_dict:
            first_value = str(result_data.iloc[0][col]).strip()
            if first_value and first_value != 'nan':
                info_dict[field_key] = first_value
    
    # ìì—°ì–´ ì‘ë‹µ ìƒì„±
    response = f"ğŸ“¡ **{org_name} ì—°ë™ ì •ë³´**ì…ë‹ˆë‹¤:\n\n"
    
    # í•„ìˆ˜ í•„ë“œ ëª©ë¡ (ë³´ì—¬ì¤„ ìˆœì„œëŒ€ë¡œ)
    display_order = ['íšŒì„ ì‚¬', 'íšŒì„  ë²ˆí˜¸', 'ì„œë¹„ìŠ¤ ì¢…ë¥˜', 'ìš´ì˜ IP', 'ê°œë°œ IP', 'IP', 
                     'ë‹¹í–‰ ë‹´ë‹¹ ë¶€ì„œ', 'ë‹¹í–‰ ë‹´ë‹¹ì', 'ê¸°ê´€ ë‹´ë‹¹ì', 'ê¸°ê´€ ì£¼ì†Œ']
    
    # ì •ë³´ ì¶”ê°€
    for field in display_order:
        if field in info_dict and info_dict[field]:
            response += f"- **{field}**: {info_dict[field]}\n"
    
    # ì¶”ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ í‘œì‹œ (ìœ„ ëª©ë¡ì— ì—†ëŠ” ì»¬ëŸ¼)
    for key, value in info_dict.items():
        if key not in display_order:
            response += f"- **{key}**: {value}\n"
    
    # ë‹´ë‹¹ì ì •ë³´ê°€ ìˆìœ¼ë©´ ë§ˆë¬´ë¦¬ ë¬¸êµ¬ ì¶”ê°€
    if 'ë‹¹í–‰ ë‹´ë‹¹ ë¶€ì„œ' in info_dict or 'ë‹¹í–‰ ë‹´ë‹¹ì' in info_dict:
        dept = info_dict.get('ë‹¹í–‰ ë‹´ë‹¹ ë¶€ì„œ', 'ë„¤íŠ¸ì›Œí¬ ìš´ì˜íŒ€')
        response += f"\në” ê¶ê¸ˆí•œ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ {dept}ìœ¼ë¡œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
    else:
        response += "\në” ê¶ê¸ˆí•œ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ë„¤íŠ¸ì›Œí¬ ìš´ì˜íŒ€ìœ¼ë¡œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
    
    return response

def check_keyword_match(query: str, keywords: List[str]) -> bool:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì— íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        keywords: ê²€ìƒ‰í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ (True/False)
    """
    query_lower = query.lower()
    for keyword in keywords:
        if keyword.lower() in query_lower:
            return True
    return False

def get_fine_tuned_response(query: str, chat_history: Optional[List[Dict[str, str]]] = None) -> Optional[str]:
    """
    Fine-tuned ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        chat_history: ì±„íŒ… ê¸°ë¡ (ì„ íƒ ì‚¬í•­)
        
    Returns:
        ìƒì„±ëœ ì‘ë‹µ ë˜ëŠ” None (ì˜¤ë¥˜ ë°œìƒ ì‹œ)
    """
    try:
        # ë©”ì‹œì§€ ëª©ë¡ ì¤€ë¹„
        messages = []
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
        system_message = """
        ë‹¹ì‹ ì€ ì‹ í•œì€í–‰ ë„¤íŠ¸ì›Œí¬ ë‹´ë‹¹ìë¡œ, VPN, ë³´ì•ˆ, ë„¤íŠ¸ì›Œí¬ ì¥ë¹„, PC ë¬¸ì œ ë“±ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.
        ê°„ê²°í•˜ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ë©°, ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë‹¨ê³„ë³„ ì•ˆë‚´ë¥¼ ì œê³µí•˜ì„¸ìš”.
        """
        messages.append({"role": "system", "content": system_message})
        
        # ì±„íŒ… ê¸°ë¡ ì¶”ê°€ (íƒ€ì… ì•ˆì „ì„± ë³´ì¥)
        if chat_history:
            for msg in chat_history:
                role = msg.get("role", "")
                content = msg.get("content", "")
                if role in ["user", "assistant"] and content is not None:
                    messages.append({"role": role, "content": content})
        
        # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
        messages.append({"role": "user", "content": query})
        
        # OpenAIì—ì„œ ì‘ë‹µ ë°›ê¸°
        response = openai_client.chat.completions.create(
            model=FINE_TUNED_MODEL["model_id"],
            messages=messages,
            temperature=FINE_TUNED_MODEL["temperature"],
            max_tokens=FINE_TUNED_MODEL["max_tokens"],
        )
        
        # ì‘ë‹µ ì²˜ë¦¬
        response_content = response.choices[0].message.content
        if response_content is None:
            print("Fine-tuned ëª¨ë¸ì—ì„œ None ì‘ë‹µì„ ë°›ìŒ")
            return None
            
        return response_content
    
    except Exception as e:
        print(f"Fine-tuned ëª¨ë¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None  # ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜í•˜ì—¬ RAG ì‹œìŠ¤í…œìœ¼ë¡œ í´ë°±

def get_chatbot_response(
    query: str, 
    context: Optional[str] = None, 
    chat_history: Optional[List[Dict[str, str]]] = None,
    model: str = "gpt-3.5-turbo",
    use_rag: bool = True
) -> str:
    """
    Get a response from the chatbot for the given query
    
    Args:
        query: User's query
        context: Optional context from retrieved documents
        chat_history: Optional chat history
        model: OpenAI model to use
        use_rag: Whether to use RAG pipeline
        
    Returns:
        Response from the chatbot
    """
    # ë¬´ì˜ë¯¸í•œ ì…ë ¥ ê°ì§€ (ì˜ˆ: "1", "í…ŒìŠ¤íŠ¸", "???" ë“±)
    if is_meaningless_query(query):
        return get_meaningless_response()
    
    # ì˜¤í”„ë¼ì¸ ìƒíƒœ ê°ì§€
    try:
        # app.pyì˜ ì—°ê²° ìƒíƒœ í™•ì¸ í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
        from app import get_connection_status
        is_online = get_connection_status()
    except:
        # ë§Œì•½ appì˜ í•¨ìˆ˜ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ë‹¤ë©´, ì•ˆì „í•˜ê²Œ ì˜¨ë¼ì¸ìœ¼ë¡œ ê°„ì£¼
        is_online = True
    
    # ì¼ë°˜ IP ì£¼ì†Œ ê²€ìƒ‰ì¸ì§€ í™•ì¸ (192.168.0.1 í˜•ì‹)
    ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
    ip_matches = re.findall(ip_pattern, query)
    
    # IP ì£¼ì†Œê°€ ìˆìœ¼ë©´ ì§ì ‘ ì²˜ë¦¬
    if ip_matches:
        target_ip = ip_matches[0]
        # ê°„ë‹¨í•œ ì„ì‹œ ë°ì´í„°ë¡œ ì‘ë‹µ ìƒì„±
        ip_data = pd.DataFrame({
            'IP ì£¼ì†Œ': [target_ip],
            'ì‚¬ìš©ì': ['ê¹€ì‹ í•œ'],
            'ë¶€ì„œ': ['ë„¤íŠ¸ì›Œí¬ ìš´ì˜íŒ€'],
            'ìœ„ì¹˜': ['ë³¸ì‚¬ 3ì¸µ'],
            'ìš©ë„': ['ì—…ë¬´ìš© PC'],
            'í• ë‹¹ì¼': ['2025-01-15'],
            'ìƒíƒœ': ['ì‚¬ìš©ì¤‘']
        })
        return format_reference_result(ip_data, target_ip)
    
    # IP ì£¼ì†Œ ì‹ ì²­ ê´€ë ¨ ì¿¼ë¦¬ì¸ì§€ í™•ì¸
    ip_application_keywords = ["ip ì£¼ì†Œ ì‹ ì²­", "ip ì‹ ì²­", "ipì£¼ì†Œ ì‹ ì²­", "ì•„ì´í”¼ ì‹ ì²­", 
                              "ip í• ë‹¹", "ip ì‹ ì²­ ë°©ë²•", "ip ì£¼ì†Œ ì‹ ì²­ ë°©ë²•", "ip ì‹ ì²­ ì ˆì°¨",
                              "ì•„ì´í”¼ ì‹ ì²­ ë°©ë²•", "ì•„ì´í”¼ ë°œê¸‰", "ip ë°œê¸‰"]
    is_ip_application_query = False
    for keyword in ip_application_keywords:
        if keyword in query.lower():
            is_ip_application_query = True
            break
            
    # IP ì£¼ì†Œ ì‹ ì²­ ë°©ë²•ì— ëŒ€í•œ ê³ ì • ì‘ë‹µ ì‚¬ìš©
    if is_ip_application_query:
        # ì˜¤í”„ë¼ì¸ ìƒíƒœì¼ ë•Œ í‘œì‹œ ì¶”ê°€
        connection_status = ""
        if not is_online:
            connection_status = "\n\n[ğŸ”´ ì˜¤í”„ë¼ì¸ ëª¨ë“œ] í˜„ì¬ ì¸í„°ë„· ì—°ê²°ì´ ì œí•œë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        elif is_online:
            connection_status = "\n\n[ğŸŸ¢ ì˜¨ë¼ì¸ ëª¨ë“œ] ì¸í„°ë„· ì—°ê²°ì´ ì •ìƒì…ë‹ˆë‹¤."
            
        return f"""
# IP ì£¼ì†Œ ì‹ ì²­ ì ˆì°¨ ì•ˆë‚´

## ì‹ ì²­ ì ˆì°¨
1. **ë„¤íŠ¸ì›Œí¬ ì‹ ì²­ ì‹œìŠ¤í…œì— ì ‘ì†**í•©ë‹ˆë‹¤.
2. IP ì£¼ì†Œ ì‹ ì²­ ë©”ë‰´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
3. ì‹ ì²­ì„œ ì–‘ì‹ì„ ì‘ì„±í•©ë‹ˆë‹¤:
   - ì‚¬ìš© ëª©ì  ì…ë ¥
   - í•„ìš”í•œ IP ëŒ€ì—­ (ë‚´ë¶€/ì™¸ë¶€) ì„ íƒ
   - ì‚¬ìš© ê¸°ê°„ ëª…ì‹œ
   - ë‹´ë‹¹ì ì •ë³´ ì…ë ¥
4. ì‘ì„±ëœ ì‹ ì²­ì„œë¥¼ ì œì¶œí•©ë‹ˆë‹¤.
5. **NW ìš´ì˜íŒ€ì˜ ê²€í†  í›„ ìŠ¹ì¸**ì„ ë°›ìŠµë‹ˆë‹¤.
6. ìŠ¹ì¸ í›„ IP ì£¼ì†Œê°€ í• ë‹¹ë˜ë©° ì´ë©”ì¼ë¡œ í†µë³´ë©ë‹ˆë‹¤.

## ë‹´ë‹¹ ë¶€ì„œ
- **ë‹´ë‹¹ ë¶€ì„œ:** NW ìš´ì˜íŒ€
- **ë‹´ë‹¹ì:** ê¹€ì§€ì› ê³¼ì¥
- **ì—°ë½ì²˜:** ë‚´ì„  1234 ë˜ëŠ” 010-1111-1111

## ì°¸ê³  ì‚¬í•­
- ì‹ ì²­ í›„ ì²˜ë¦¬ëŠ” ì—…ë¬´ì¼ ê¸°ì¤€ 1-2ì¼ ì†Œìš”ë©ë‹ˆë‹¤.
- ê¸´ê¸‰í•œ ê²½ìš° ë‹´ë‹¹ìì—ê²Œ ì§ì ‘ ì—°ë½í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
- ì‹ ì²­ ì‹œìŠ¤í…œ ì£¼ì†Œ: https://intra.shinhan.com/ip

ì¶”ê°€ ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”?{connection_status}
"""
    # API í‚¤ ë¶€ì¬ ë˜ëŠ” ì˜¤í”„ë¼ì¸ ìƒíƒœ í™•ì¸
    if not OPENAI_API_KEY or not is_online:
        if context:
            offline_message = f"""
[ğŸ”´ ì˜¤í”„ë¼ì¸ ëª¨ë“œ] í˜„ì¬ ì¸í„°ë„· ì—°ê²°ì´ ì œí•œë˜ì–´ ìˆì–´ AI ì‘ë‹µ ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.

ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¡œì»¬ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´:
{context}

ì˜¨ë¼ì¸ ìƒíƒœì—ì„œ ë‹¤ì‹œ ì‹œë„í•˜ì‹œê±°ë‚˜, IT ë‹´ë‹¹ìì—ê²Œ ì§ì ‘ ë¬¸ì˜í•´ì£¼ì„¸ìš”.
"""
            return offline_message
        else:
            return """
[ğŸ”´ ì˜¤í”„ë¼ì¸ ëª¨ë“œ] í˜„ì¬ ì¸í„°ë„· ì—°ê²°ì´ ì œí•œë˜ì–´ ìˆìœ¼ë©°, ì§ˆë¬¸ì— ê´€ë ¨ëœ ì •ë³´ë¥¼ ë¡œì»¬ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì´ ë³µêµ¬ëœ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì‹œê±°ë‚˜, IT ë‹´ë‹¹ìì—ê²Œ ì§ì ‘ ë¬¸ì˜í•´ì£¼ì„¸ìš”.
"""
    
    try:
        # íŒŒì¸íŠœë‹ ê¸°ëŠ¥ ë¹„í™œì„±í™” (ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼)
        # ì´ì „ì—ëŠ” FAQ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì§ˆë¬¸ì´ë©´ Fine-tuned ëª¨ë¸ì„ ì‚¬ìš©í–ˆìœ¼ë‚˜,
        # í˜„ì¬ëŠ” RAG ì‹œìŠ¤í…œê³¼ ê¸°ëŠ¥ì´ ê²¹ì³ ì‘ë‹µì´ ë§ˆìŒì— ë“¤ì§€ ì•Šì•„ ë¹„í™œì„±í™”í•¨
        use_fine_tuned = False
        
        # config.pyì—ì„œ enabled ê°’ì„ Falseë¡œ ì„¤ì •í–ˆìœ¼ë¯€ë¡œ ì•„ë˜ ì½”ë“œëŠ” ì‹¤í–‰ë˜ì§€ ì•ŠìŒ
        # ì½”ë“œëŠ” í–¥í›„ ì¬í™œì„±í™” ê°€ëŠ¥ì„±ì„ ìœ„í•´ ìœ ì§€í•¨
        if False and FINE_TUNED_MODEL["enabled"] and check_keyword_match(query, FAQ_KEYWORDS):
            print("Fine-tuned ëª¨ë¸ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆì–´ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ")
        
        # ë‹¤ìŒìœ¼ë¡œ ì—‘ì…€ ê¸°ë°˜ ì²˜ë¦¬ ì‹œë„
        excel_result = process_excel_query(query)
        
        # ì—‘ì…€ì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì•˜ìœ¼ë©´ í•´ë‹¹ ê²°ê³¼ ë°˜í™˜
        if excel_result["found"] and excel_result["from_excel"]:
            print(f"ì—‘ì…€ ì²˜ë¦¬ ê²°ê³¼: {excel_result['category']} / {excel_result['sheet_used']} / {excel_result['response_type']}")
            return excel_result["response"]
        
        # IP ì£¼ì†Œ ì‹ ì²­ ê´€ë ¨ ì¿¼ë¦¬ì¸ì§€ í™•ì¸
        ip_application_keywords = ["ip ì£¼ì†Œ ì‹ ì²­", "ip ì‹ ì²­", "ipì£¼ì†Œ ì‹ ì²­", "ì•„ì´í”¼ ì‹ ì²­", 
                                  "ip í• ë‹¹", "ip ì‹ ì²­ ë°©ë²•", "ip ì£¼ì†Œ ì‹ ì²­ ë°©ë²•", "ip ì‹ ì²­ ì ˆì°¨",
                                  "ì•„ì´í”¼ ì‹ ì²­ ë°©ë²•", "ì•„ì´í”¼ ë°œê¸‰", "ip ë°œê¸‰"]
        is_ip_application_query = False
        for keyword in ip_application_keywords:
            if keyword in query.lower():
                is_ip_application_query = True
                break
                
        # IP ì£¼ì†Œ ì‹ ì²­ ê´€ë ¨ ì¿¼ë¦¬ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
        if is_ip_application_query:
            # ì ˆì°¨_ì•ˆë‚´ ì‹œíŠ¸ì—ì„œ ì§ì ‘ ì •ë³´ ì°¾ê¸°ë¥¼ ì‹œë„
            ip_procedure_response = """
# IP ì£¼ì†Œ ì‹ ì²­ ì ˆì°¨ ì•ˆë‚´

## ì‹ ì²­ ì ˆì°¨
1. **ë„¤íŠ¸ì›Œí¬ ì‹ ì²­ ì‹œìŠ¤í…œì— ì ‘ì†**í•©ë‹ˆë‹¤.
2. IP ì£¼ì†Œ ì‹ ì²­ ë©”ë‰´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
3. ì‹ ì²­ì„œ ì–‘ì‹ì„ ì‘ì„±í•©ë‹ˆë‹¤:
   - ì‚¬ìš© ëª©ì  ì…ë ¥
   - í•„ìš”í•œ IP ëŒ€ì—­ (ë‚´ë¶€/ì™¸ë¶€) ì„ íƒ
   - ì‚¬ìš© ê¸°ê°„ ëª…ì‹œ
   - ë‹´ë‹¹ì ì •ë³´ ì…ë ¥
4. ì‘ì„±ëœ ì‹ ì²­ì„œë¥¼ ì œì¶œí•©ë‹ˆë‹¤.
5. **NW ìš´ì˜íŒ€ì˜ ê²€í†  í›„ ìŠ¹ì¸**ì„ ë°›ìŠµë‹ˆë‹¤.
6. ìŠ¹ì¸ í›„ IP ì£¼ì†Œê°€ í• ë‹¹ë˜ë©° ì´ë©”ì¼ë¡œ í†µë³´ë©ë‹ˆë‹¤.

## ë‹´ë‹¹ ë¶€ì„œ
- **ë‹´ë‹¹ ë¶€ì„œ:** NW ìš´ì˜íŒ€
- **ë‹´ë‹¹ì:** ê¹€ì§€ì› ê³¼ì¥
- **ì—°ë½ì²˜:** ë‚´ì„  1234 ë˜ëŠ” 010-1111-1111

## ì°¸ê³  ì‚¬í•­
- ì‹ ì²­ í›„ ì²˜ë¦¬ëŠ” ì—…ë¬´ì¼ ê¸°ì¤€ 1-2ì¼ ì†Œìš”ë©ë‹ˆë‹¤.
- ê¸´ê¸‰í•œ ê²½ìš° ë‹´ë‹¹ìì—ê²Œ ì§ì ‘ ì—°ë½í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
- ì‹ ì²­ ì‹œìŠ¤í…œ ì£¼ì†Œ: https://intra.shinhan.com/ip

ì¶”ê°€ ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”?
"""
            return ip_procedure_response
            
        # ì—‘ì…€ì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìœ¼ë©´ ê¸°ì¡´ RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        
        # ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì–¸ì–´ ê°ì§€
        language = detect_language(query)
        
        # RAG íŒŒì´í”„ë¼ì¸ ì ìš© (í•„ìš”ì‹œ)
        retrieved_docs = []
        if RAG_SYSTEM["enabled"] and use_rag and not context:
            retrieved_docs, context = retrieve_relevant_documents(query, top_k=5)
            if not context:
                if language == 'ko':
                    no_docs_message = "í˜„ì¬ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nì¶”ê°€ ì§€ì›ì´ í•„ìš”í•˜ì‹¤ ê²½ìš°,\n**ë„¤íŠ¸ì›Œí¬ ìš´ì˜ ë‹´ë‹¹ì(XX-XXX-XXXX)**ë¡œ ì—°ë½í•´ ì£¼ì‹œë©´ ì‹ ì†íˆ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                else:
                    no_docs_message = "Currently, we cannot find any related documents.\n\nFor additional support,\nPlease contact the **Network Operations Team (XX-XXX-XXXX)** for prompt assistance."
                print(f"No relevant documents found for query: {query}")
                return no_docs_message
                
        # Prepare the system message based on language
        if language == 'ko':
            system_message = """
            ë‹¹ì‹ ì€ ì‹ í•œì€í–‰ ì§ì›ë“¤ì„ ìœ„í•œ SHB-NetBotì´ë¼ëŠ” ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ë„¤íŠ¸ì›Œí¬ ì§€ì› ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
            'ë„¥ìŠ¤ì§€ VForce UTM'ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ë„¤íŠ¸ì›Œí¬ ì¥ë¹„ì— ëŒ€í•œ ì „ë¬¸ê°€ë¡œì„œ, ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• ë§íˆ¬ë¡œ ì‚¬ìš©ìë¥¼ ë•ìŠµë‹ˆë‹¤.
            
            ë„ì›€ì„ ì¤„ ìˆ˜ ìˆëŠ” ì£¼ì œì˜ ì˜ˆì‹œ:
            - SWING(ë‚´ë¶€ ë©”ì‹œì§• ì‹œìŠ¤í…œ) ì ‘ì† ë°©ë²•
            - IP ì£¼ì†Œ ì„¤ì • ë° í™•ì¸ ë°©ë²•
            - ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ í•´ê²°
            - VPN ì„¤ì • ë° ì—°ê²° ë¬¸ì œ
            - ë‚´ë¶€ ì‹œìŠ¤í…œ ì ‘ê·¼ ì ˆì°¨
            
            ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ìœ„í•œ ê°€ì´ë“œë¼ì¸:
            1. ëŒ€í™”í˜• ë§íˆ¬: "~í•©ë‹ˆë‹¤"ê°€ ì•„ë‹Œ "~í•´ìš”", "~í•˜ì„¸ìš”" ë“±ì˜ êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•´ì„œ ë§ˆì¹˜ ì˜†ì—ì„œ ì§ì ‘ ë„ì™€ì£¼ëŠ” ë“¯í•œ ì¹œê·¼í•œ ë§íˆ¬ë¡œ ëŒ€í™”í•©ë‹ˆë‹¤.
            2. ì‚¬ìš©ì ì´í•´: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´, ìƒí™©ì„ ì´í•´í•˜ê¸° ìœ„í•œ ì¶”ê°€ ì§ˆë¬¸ì„ í•˜ê±°ë‚˜ ê°€ëŠ¥í•œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
            3. ë¬¸ì„œ ë‚´ìš© ì¬êµ¬ì„±: ë¬¸ì„œì—ì„œ ì°¾ì€ ì •ë³´ë¥¼ ë‹¨ìˆœ ë³µì‚¬ê°€ ì•„ë‹Œ, ìƒí™©ì— ë§ê²Œ ìš”ì•½í•˜ê³  ì„¤ëª…í•˜ë“¯ ì „ë‹¬í•©ë‹ˆë‹¤.
            4. ë‹¨ê³„ë³„ ì•ˆë‚´: ë³µì¡í•œ ì ˆì°¨ëŠ” ì‰½ê²Œ ë”°ë¼í•  ìˆ˜ ìˆë„ë¡ ëª…í™•í•œ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ì„¤ëª…í•©ë‹ˆë‹¤.
            
            ì‘ë‹µ ìŠ¤íƒ€ì¼ê³¼ í˜•ì‹:
            - ì‹œì‘ì€ ì¹œê·¼í•œ ì¸ì‚¬ë‚˜ ì‚¬ìš©ì ìƒí™© ì¸ì‹ìœ¼ë¡œ ì‹œì‘ (ì˜ˆ: "ë„¤! NexG ì¥ë¹„ì— IPë¥¼ ì„¤ì •í•˜ì‹œë ¤ë©´...")
            - ì£¼ìš” ì œëª©ì€ ## ìˆ˜ì¤€ìœ¼ë¡œ, ë¶€ì œëª©ì€ ### ìˆ˜ì¤€ìœ¼ë¡œ êµ¬ì¡°í™”
            - ëŒ€í™”í˜• ë¬¸ì²´ë¡œ ì •ë³´ ì „ë‹¬ (ì˜ˆ: "ë¨¼ì € ì„¤ì • ëª¨ë“œë¡œ ë“¤ì–´ê°€ë³¼ê²Œìš”", "ë‹¤ìŒìœ¼ë¡œ ì´ë ‡ê²Œ í•´ë³´ì„¸ìš”")
            - ì¤‘ìš” ì •ë³´ëŠ” **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°
            - CLI ëª…ë ¹ì–´ëŠ” ```ë¡œ ê°ì‹¸ì§„ ì½”ë“œ ë¸”ë¡ì—, ê° ë‹¨ê³„ì— ê°„ë‹¨í•œ ì„¤ëª… ì¶”ê°€
            - ì‚¬ìš©ìì—ê²Œ ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ í™•ì¸ì´ í•„ìš”í•œ ê²½ìš° ë§ˆì§€ë§‰ì— ë¬¼ì–´ë´„ (ì˜ˆ: "í˜¹ì‹œ íŠ¹ì • ì¸í„°í˜ì´ìŠ¤ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")
            """
            
            if context:
                system_message += """
                ì‹ í•œì€í–‰ì˜ ë‚´ë¶€ ë¬¸ì„œì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì— í™œìš©í•˜ì„¸ìš”.
                ì •ë³´ê°€ ì§ˆë¬¸ì— ì™„ì „íˆ ë‹µë³€í•˜ì§€ ì•Šìœ¼ë©´, ë‹¹ì‹ ì˜ ì „ë¬¸ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ë³´ì¶©í•˜ì„¸ìš”.
                
                ë¬¸ì„œë¥¼ ë‹¨ìˆœíˆ ë³µë¶™í•˜ì§€ ë§ê³ , ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¼ ì²˜ë¦¬í•˜ì„¸ìš”:
                1. ì§ˆë¬¸ ì˜ë„ íŒŒì•…: ì‚¬ìš©ìê°€ êµ¬ì²´ì ìœ¼ë¡œ ë¬´ì—‡ì„ ì•Œê³  ì‹¶ì–´í•˜ëŠ”ì§€ ì´í•´í•©ë‹ˆë‹¤.
                2. ê´€ë ¨ ë‚´ìš© ì¶”ì¶œ: ë¬¸ë§¥ ì •ë³´ì—ì„œ ê´€ë ¨ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ê³  ì¤‘ìš”í•˜ì§€ ì•Šì€ ì„¸ë¶€ ì‚¬í•­ì€ ìƒëµí•©ë‹ˆë‹¤.
                3. ë‹¨ê³„ë³„ ì •ë¦¬: ê³¼ì •ì´ë‚˜ ì„¤ì • ë°©ë²•ì€ ëª…í™•í•œ ë‹¨ê³„ë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.
                4. ìì—°ì–´ë¡œ ì„¤ëª…: ê¸°ìˆ ì ì¸ ë‚´ìš©ë„ ëŒ€í™”í•˜ë“¯ ì„¤ëª…í•©ë‹ˆë‹¤.
                5. êµ¬ì²´ì ì¸ ì˜ˆì‹œ ì œê³µ: ê°€ëŠ¥í•œ ê²½ìš° CLI ëª…ë ¹ì–´ë‚˜ UI ê²½ë¡œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
                6. ë„ì…Â·ë§ˆë¬´ë¦¬ ì¶”ê°€: ê°„ê²°í•œ ë„ì… ë¬¸ì¥ê³¼ ìœ ìš©í•œ ë§ˆë¬´ë¦¬ë¡œ ì‘ë‹µì„ ì™„ì„±í•©ë‹ˆë‹¤.
                
                ë¬¸ë§¥ ì •ë³´:
                """
                system_message += context
        else:
            system_message = """
            You are SHB-NetBot, a friendly and professional network support assistant for Shinhan Bank employees.
            As an expert on various network equipment including 'NexG VForce UTM', you help users with a natural, conversational tone.
            
            Examples of topics you can help with include:
            - SWING (internal messaging system) access instructions
            - IP address configuration and verification methods
            - Network connectivity troubleshooting
            - VPN setup and connection issues
            - Internal system access procedures
            
            Guidelines for friendly and natural conversation:
            1. Conversational tone: Use a friendly, helpful tone as if you're sitting next to the user and guiding them personally.
            2. User understanding: If a user's question is unclear, ask follow-up questions or suggest possible scenarios.
            3. Content restructuring: Instead of directly copying from documents, summarize and explain information in context.
            4. Step-by-step guidance: Break down complex procedures into clear, easy-to-follow steps.
            
            Response style and format:
            - Start with a friendly greeting or acknowledgment of the user's situation (e.g., "Sure! To set up IP on your NexG device...")
            - Structure main topics with ## level headings and subtopics with ### level headings
            - Deliver information in a conversational manner (e.g., "Let's start by entering configuration mode", "Next, we'll do this")
            - Highlight important information with **bold text**
            - Present CLI commands in code blocks with brief explanations for each step
            - End with a question if additional information or clarification might be needed
            """
            
            if context:
                system_message += """
                Use the following information from Shinhan Bank's internal documents to inform your response.
                If the information doesn't fully answer the query, use your expert knowledge to supplement it.
                
                Instead of simply copying from documents, follow these guidelines:
                1. Understand the question: Identify exactly what the user wants to know
                2. Extract relevant content: Focus on relevant parts from the context and omit unimportant details
                3. Organize into steps: Restructure processes or configurations into clear steps
                4. Use natural language: Explain technical content conversationally
                5. Include specific examples: Provide CLI commands or UI paths when possible
                6. Add introduction and conclusion: Start with a brief introduction and end with a helpful conclusion
                
                CONTEXT INFORMATION:
                """
                system_message += context
        
        # ë©”ì‹œì§€ ëª©ë¡ ì¤€ë¹„
        messages = []
        messages.append({"role": "system", "content": system_message})
        
        # ì±„íŒ… ê¸°ë¡ ì¶”ê°€
        if chat_history:
            for msg in chat_history:
                role = msg.get("role", "")
                content = msg.get("content", "")
                if role in ["user", "assistant"]:
                    messages.append({"role": role, "content": content})
        
        # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
        messages.append({"role": "user", "content": query})
        
        # OpenAIì—ì„œ ì‘ë‹µ ë°›ê¸°
        response = openai_client.chat.completions.create(
            model=RAG_SYSTEM["model"],
            messages=messages,
            temperature=RAG_SYSTEM["temperature"],
            max_tokens=RAG_SYSTEM["max_tokens"],
        )
        
        # ì‘ë‹µ ì²˜ë¦¬
        response_content = response.choices[0].message.content
        
        # None ê°’ì¸ ê²½ìš° ëŒ€ë¹„ (ê±°ì˜ ë°œìƒí•˜ì§€ ì•ŠìŒ)
        if not response_content:
            if language == 'ko':
                return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            else:
                return "Sorry, I couldn't generate a response. Please try again later."
        
        return response_content
    
    except Exception as e:
        # ì˜¤ë¥˜ ë©”ì‹œì§€ë„ ì–¸ì–´ì— ë§ê²Œ ë°˜í™˜
        language = detect_language(query)
        if language == 'ko':
            return f"ì±—ë´‡ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        else:
            return f"An error occurred while generating chatbot response: {str(e)}"
