"""
SHB-NetBot Flow CSV â†’ JSON ìë™ ë³€í™˜ ëª¨ë“ˆ
- SHB-NetBot_Flow.csv íŒŒì¼ì„ ê°ì§€í•˜ì—¬ ìë™ìœ¼ë¡œ JSON êµ¬ì¡°ë¡œ ë³€í™˜
- ì˜¤í”„ë¼ì¸ ëª¨ë“œì—ì„œ ì‚¬ìš©í•  Flow í˜•íƒœë¡œ ì €ì¥
"""

import os
import pandas as pd
import json
import logging
from typing import Dict, List, Any, Optional

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FlowConverter:
    """CSV Flow íŒŒì¼ì„ JSONìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.flow_file_pattern = "SHB-NetBot_Flow"
        self.output_path = "static/data/offline_flow.json"
        
    def detect_flow_file(self, uploaded_files_dir: str = "uploaded_files") -> Optional[str]:
        """
        ì—…ë¡œë“œëœ íŒŒì¼ ì¤‘ SHB-NetBot_Flow.csv íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            uploaded_files_dir: ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
            
        Returns:
            ì°¾ì€ íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œ ë˜ëŠ” None
        """
        try:
            for filename in os.listdir(uploaded_files_dir):
                if self.flow_file_pattern in filename and filename.endswith('.csv'):
                    full_path = os.path.join(uploaded_files_dir, filename)
                    logger.info(f"Flow íŒŒì¼ ë°œê²¬: {filename}")
                    return full_path
        except Exception as e:
            logger.error(f"Flow íŒŒì¼ íƒìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return None
    
    def parse_options(self, options_str: str) -> List[Dict[str, str]]:
        """
        ì„ íƒì§€ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ì˜µì…˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            options_str: "ì˜ˆ:check_phone_light, ì•„ë‹ˆìš”:check_pc_lan_light" í˜•íƒœì˜ ë¬¸ìì—´
            
        Returns:
            [{"label": "ì˜ˆ", "next": "check_phone_light"}, ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
        """
        if not options_str or options_str.strip() == "(ì¢…ë£Œ)":
            return []
            
        options = []
        try:
            # ì‰¼í‘œë¡œ ë¶„ë¦¬
            option_pairs = [opt.strip() for opt in options_str.split(',')]
            
            for pair in option_pairs:
                if ':' in pair:
                    label, next_id = pair.split(':', 1)
                    options.append({
                        "label": label.strip(),
                        "next": next_id.strip()
                    })
        except Exception as e:
            logger.error(f"ì˜µì…˜ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}, ì…ë ¥: {options_str}")
            
        return options
    
    def convert_csv_to_json(self, csv_file_path: str) -> Dict[str, Any]:
        """
        CSV íŒŒì¼ì„ JSON Flow êµ¬ì¡°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            csv_file_path: CSV íŒŒì¼ ê²½ë¡œ
            
        Returns:
            JSON Flow êµ¬ì¡° ë”•ì…”ë„ˆë¦¬
        """
        try:
            # CSV íŒŒì¼ ì½ê¸° (UTF-8 ì‹œë„ í›„ CP949ë¡œ fallback)
            try:
                df = pd.read_csv(csv_file_path, encoding='utf-8')
            except UnicodeDecodeError:
                df = pd.read_csv(csv_file_path, encoding='cp949')
            
            logger.info(f"CSV íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰")
            
            # JSON Flow êµ¬ì¡° ìƒì„±
            flow_data = {}
            
            for _, row in df.iterrows():
                node_id = str(row['ID']).strip()
                text = str(row['ì§ˆë¬¸/ì•ˆë‚´']).strip()
                options_str = str(row['ì„ íƒì§€']).strip() if pd.notna(row['ì„ íƒì§€']) else ""
                
                # ì˜µì…˜ íŒŒì‹±
                options = self.parse_options(options_str)
                
                flow_data[node_id] = {
                    "id": node_id,
                    "text": text,
                    "options": options
                }
                
            logger.info(f"JSON Flow ë³€í™˜ ì™„ë£Œ: {len(flow_data)}ê°œ ë…¸ë“œ")
            return flow_data
            
        except Exception as e:
            logger.error(f"CSV â†’ JSON ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return {}
    
    def save_flow_json(self, flow_data: Dict[str, Any]) -> bool:
        """
        ë³€í™˜ëœ Flow ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            flow_data: Flow ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(os.path.dirname(self.output_path), exist_ok=True)
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            with open(self.output_path, 'w', encoding='utf-8') as f:
                json.dump(flow_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Flow JSON ì €ì¥ ì™„ë£Œ: {self.output_path}")
            return True
            
        except Exception as e:
            logger.error(f"Flow JSON ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def load_flow_json(self) -> Dict[str, Any]:
        """
        ì €ì¥ëœ Flow JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Returns:
            Flow ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        try:
            if os.path.exists(self.output_path):
                with open(self.output_path, 'r', encoding='utf-8') as f:
                    flow_data = json.load(f)
                logger.info(f"Flow JSON ë¡œë“œ ì™„ë£Œ: {len(flow_data)}ê°œ ë…¸ë“œ")
                return flow_data
        except Exception as e:
            logger.error(f"Flow JSON ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return {}
    
    def auto_convert_if_needed(self) -> bool:
        """
        Flow íŒŒì¼ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ë³€í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            ë³€í™˜ ì„±ê³µ ì—¬ë¶€
        """
        # Flow íŒŒì¼ íƒìƒ‰
        flow_file = self.detect_flow_file()
        
        if not flow_file:
            logger.info("Flow íŒŒì¼ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        # ê¸°ì¡´ JSON íŒŒì¼ í™•ì¸
        if os.path.exists(self.output_path):
            # íŒŒì¼ ìˆ˜ì • ì‹œê°„ ë¹„êµ
            csv_mtime = os.path.getmtime(flow_file)
            json_mtime = os.path.getmtime(self.output_path)
            
            if csv_mtime <= json_mtime:
                logger.info("ê¸°ì¡´ Flow JSONì´ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.")
                return True
        
        # CSV â†’ JSON ë³€í™˜
        logger.info("Flow íŒŒì¼ ë³€í™˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        flow_data = self.convert_csv_to_json(flow_file)
        
        if not flow_data:
            logger.error("Flow ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return False
        
        # JSON ì €ì¥
        return self.save_flow_json(flow_data)

def convert_flow_file() -> bool:
    """
    Flow íŒŒì¼ì„ ìë™ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í¸ì˜ í•¨ìˆ˜
    
    Returns:
        ë³€í™˜ ì„±ê³µ ì—¬ë¶€
    """
    converter = FlowConverter()
    return converter.auto_convert_if_needed()

def get_offline_flow() -> Dict[str, Any]:
    """
    ì˜¤í”„ë¼ì¸ ëª¨ë“œìš© Flow ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    
    Returns:
        Flow ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    converter = FlowConverter()
    return converter.load_flow_json()

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    success = convert_flow_file()
    if success:
        print("âœ… Flow ë³€í™˜ ì„±ê³µ!")
        flow_data = get_offline_flow()
        print(f"ğŸ“Š ë¡œë“œëœ ë…¸ë“œ ìˆ˜: {len(flow_data)}")
    else:
        print("âŒ Flow ë³€í™˜ ì‹¤íŒ¨")