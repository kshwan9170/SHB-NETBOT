"""
ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ ì „ìš© ì²˜ë¦¬ ëª¨ë“ˆ
- ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ(~).csv íŒŒì¼ë“¤ì—ì„œ í‚¤ì›Œë“œ ìš°ì„  ë§¤ì¹­
- ì •í˜•í™”ëœ í…œí”Œë¦¿ ì‘ë‹µ ìƒì„±
- GPT ì‘ë‹µì€ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œì—ë§Œ ì‚¬ìš©
"""

import os
import pandas as pd
import re
from typing import List, Dict, Any, Optional, Tuple
import logging
from pathlib import Path

logger = logging.getLogger(__name__)

class BusinessGuideProcessor:
    """ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ CSV íŒŒì¼ ì „ìš© ì²˜ë¦¬ê¸°"""
    
    def __init__(self, upload_folder: str = "uploaded_files"):
        self.upload_folder = upload_folder
        self.guide_files = {}  # ê°€ì´ë“œ íŒŒì¼ë³„ ë°ì´í„° ìºì‹œ
        self.load_guide_files()
    
    def load_guide_files(self):
        """ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ CSV íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ê³  ìºì‹œ"""
        if not os.path.exists(self.upload_folder):
            logger.warning(f"ì—…ë¡œë“œ í´ë” '{self.upload_folder}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return
        
        # ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ íŒŒì¼ íŒ¨í„´
        guide_patterns = [
            r".*ì—…ë¬´\s*ì•ˆë‚´\s*ê°€ì´ë“œ.*\.csv$",
            r".*ì—…ë¬´.*ê°€ì´ë“œ.*\.csv$",
            r".*ì•ˆë‚´.*ê°€ì´ë“œ.*\.csv$"
        ]
        
        for filename in os.listdir(self.upload_folder):
            filepath = os.path.join(self.upload_folder, filename)
            
            # ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ íŒŒì¼ì¸ì§€ í™•ì¸
            is_guide_file = any(re.search(pattern, filename, re.IGNORECASE) for pattern in guide_patterns)
            
            if is_guide_file and os.path.isfile(filepath):
                try:
                    # íŒŒì¼ ìœ í˜•ë³„ êµ¬ë¶„
                    guide_type = self._determine_guide_type(filename)
                    df = self._load_csv_file(filepath)
                    
                    if df is not None and not df.empty:
                        self.guide_files[filename] = {
                            'type': guide_type,
                            'data': df,
                            'filepath': filepath,
                            'columns': list(df.columns)
                        }
                        logger.info(f"ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ ë¡œë“œ ì™„ë£Œ: {filename} ({guide_type})")
                
                except Exception as e:
                    logger.error(f"ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ ë¡œë“œ ì‹¤íŒ¨ {filename}: {str(e)}")
        
        logger.info(f"ì´ {len(self.guide_files)}ê°œ ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
    
    def _determine_guide_type(self, filename: str) -> str:
        """íŒŒì¼ëª…ìœ¼ë¡œ ê°€ì´ë“œ ìœ í˜• ê²°ì •"""
        filename_lower = filename.lower()
        
        if 'ip' in filename_lower and ('ì‚¬ìš©ì' in filename_lower or 'ì¡°íšŒ' in filename_lower):
            return 'ip_user_guide'
        elif 'ëŒ€ì™¸ê³„' in filename_lower or 'ì—°ë™' in filename_lower:
            return 'external_system_guide'
        elif 'ì¥ì• ' in filename_lower or 'ë¬¸ì˜' in filename_lower:
            return 'trouble_inquiry_guide'
        elif 'ì ˆì°¨' in filename_lower or 'ì•ˆë‚´' in filename_lower:
            return 'procedure_guide'
        else:
            return 'general_guide'
    
    def _load_csv_file(self, filepath: str) -> Optional[pd.DataFrame]:
        """CSV íŒŒì¼ ë¡œë“œ (ì¸ì½”ë”© ìë™ ê°ì§€)"""
        encodings = ['utf-8', 'cp949', 'euc-kr', 'latin-1']
        
        for encoding in encodings:
            try:
                df = pd.read_csv(filepath, encoding=encoding)
                logger.info(f"CSV íŒŒì¼ '{filepath}' {encoding} ì¸ì½”ë”©ìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ì½ìŒ")
                return df
            except UnicodeDecodeError:
                continue
            except Exception as e:
                logger.error(f"CSV íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ {filepath}: {str(e)}")
                break
        
        logger.error(f"CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {filepath}")
        return None
    
    def search_keywords(self, query: str) -> Optional[Dict[str, Any]]:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œì—ì„œ ë§¤ì¹­ ê²€ìƒ‰
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            ë§¤ì¹­ëœ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        if not self.guide_files:
            return None
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(query)
        logger.info(f"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
        
        # ëª¨ë“  ê°€ì´ë“œ íŒŒì¼ì—ì„œ ê²€ìƒ‰
        best_match = None
        best_score = 0
        
        for filename, guide_info in self.guide_files.items():
            matches = self._search_in_guide(guide_info, keywords, query)
            
            for match in matches:
                if match['score'] > best_score:
                    best_score = match['score']
                    best_match = match
                    best_match['source_file'] = filename
                    best_match['guide_type'] = guide_info['type']
        
        return best_match if best_score > 0 else None
    
    def _extract_keywords(self, query: str) -> List[str]:
        """ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = ['ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ì˜', 'ì—', 'ì—ì„œ', 'ë¡œ', 'ìœ¼ë¡œ', 
                    'ì™€', 'ê³¼', 'í•˜ê³ ', 'ê·¸ë¦¬ê³ ', 'ë˜ëŠ”', 'í•˜ëŠ”', 'ë˜ëŠ”', 'ìˆëŠ”', 'ì—†ëŠ”',
                    'ì–´ë–»ê²Œ', 'ë¬´ì—‡', 'ì–¸ì œ', 'ì–´ë””ì„œ', 'ì™œ', 'ëˆ„ê°€', 'ë­', 'ì–´ë–¤',
                    'ì…ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤', 'í•´ìš”', 'ì˜ˆìš”', 'ì´ì—ìš”', 'ë„¤ìš”', 'ìš”']
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê³µë°±ìœ¼ë¡œ ë¶„í• 
        cleaned_query = re.sub(r'[^\w\s]', ' ', query)
        words = [word.strip() for word in cleaned_query.split() if len(word.strip()) > 1]
        
        # ë¶ˆìš©ì–´ ì œê±°
        keywords = [word for word in words if word not in stopwords]
        
        return keywords
    
    def _search_in_guide(self, guide_info: Dict[str, Any], keywords: List[str], original_query: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ê°€ì´ë“œ íŒŒì¼ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰"""
        df = guide_info['data']
        guide_type = guide_info['type']
        results = []
        
        # ê²€ìƒ‰ ëŒ€ìƒ ì»¬ëŸ¼ ê²°ì •
        search_columns = self._get_search_columns(guide_type, list(df.columns))
        
        for idx, row in df.iterrows():
            score = 0
            matched_fields = []
            
            # ê° ê²€ìƒ‰ ì»¬ëŸ¼ì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­
            for col in search_columns:
                if col in df.columns and pd.notna(row[col]):
                    cell_value = str(row[col]).lower()
                    
                    for keyword in keywords:
                        if keyword.lower() in cell_value:
                            score += 2  # í‚¤ì›Œë“œ ì •í™• ë§¤ì¹­
                            matched_fields.append(f"{col}: {keyword}")
                    
                    # ë¶€ë¶„ ë§¤ì¹­ ì ìˆ˜
                    for keyword in keywords:
                        if len(keyword) > 2:
                            for word in cell_value.split():
                                if keyword.lower() in word and len(word) > 2:
                                    score += 1  # ë¶€ë¶„ ë§¤ì¹­
            
            if score > 0:
                result = {
                    'score': score,
                    'row_data': row.to_dict(),
                    'matched_fields': matched_fields,
                    'guide_type': guide_type,
                    'row_index': idx
                }
                results.append(result)
        
        # ì ìˆ˜ë³„ ì •ë ¬
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:3]  # ìƒìœ„ 3ê°œë§Œ ë°˜í™˜
    
    def _get_search_columns(self, guide_type: str, available_columns: List[str]) -> List[str]:
        """ê°€ì´ë“œ ìœ í˜•ë³„ ê²€ìƒ‰ ëŒ€ìƒ ì»¬ëŸ¼ ê²°ì •"""
        search_priority = {
            'ip_user_guide': ['ì§ˆë¬¸ í‚¤ì›Œë“œ', 'ì§ˆë¬¸ ì˜ˆì‹œ', 'IP ì£¼ì†Œ', 'ì‚¬ìš©ìëª…', 'ë¶€ì„œ'],
            'external_system_guide': ['ëŒ€ì™¸ê¸°ê´€ëª…', 'ì„œë¹„ìŠ¤ëª…', 'ì§ˆë¬¸ í‚¤ì›Œë“œ', 'ë¹„ê³ '],
            'trouble_inquiry_guide': ['ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬', 'ì§ˆë¬¸ í‚¤ì›Œë“œ', 'ì§ˆë¬¸ ì˜ˆì‹œ'],
            'procedure_guide': ['ì ˆì°¨ êµ¬ë¶„', 'ì§ˆë¬¸ í‚¤ì›Œë“œ', 'ì§ˆë¬¸ ì˜ˆì‹œ'],
            'general_guide': ['ì§ˆë¬¸ í‚¤ì›Œë“œ', 'ì§ˆë¬¸ ì˜ˆì‹œ', 'ì¹´í…Œê³ ë¦¬', 'êµ¬ë¶„']
        }
        
        priority_columns = search_priority.get(guide_type, ['ì§ˆë¬¸ í‚¤ì›Œë“œ', 'ì§ˆë¬¸ ì˜ˆì‹œ'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë°˜í™˜
        result_columns = []
        for col in priority_columns:
            if col in available_columns:
                result_columns.append(col)
        
        # ì¶”ê°€ë¡œ í‚¤ì›Œë“œë‚˜ ì˜ˆì‹œê°€ í¬í•¨ëœ ì»¬ëŸ¼ ì°¾ê¸°
        for col in available_columns:
            col_lower = col.lower()
            if ('í‚¤ì›Œë“œ' in col_lower or 'ì˜ˆì‹œ' in col_lower or 'ì¹´í…Œê³ ë¦¬' in col_lower or 
                'êµ¬ë¶„' in col_lower or 'ë¬¸ì˜' in col_lower) and col not in result_columns:
                result_columns.append(col)
        
        return result_columns
    
    def generate_template_response(self, match_result: Dict[str, Any]) -> Optional[str]:
        """ë§¤ì¹­ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í˜•í™”ëœ í…œí”Œë¦¿ ì‘ë‹µ ìƒì„±"""
        if not match_result:
            return None
        
        row_data = match_result['row_data']
        guide_type = match_result['guide_type']
        source_file = match_result.get('source_file', 'ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ')
        
        # ê°€ì´ë“œ ìœ í˜•ë³„ í…œí”Œë¦¿ ì‘ë‹µ ìƒì„±
        if guide_type == 'ip_user_guide':
            return self._generate_ip_user_response(row_data, source_file)
        elif guide_type == 'external_system_guide':
            return self._generate_external_system_response(row_data, source_file)
        elif guide_type == 'trouble_inquiry_guide':
            return self._generate_trouble_inquiry_response(row_data, source_file)
        elif guide_type == 'procedure_guide':
            return self._generate_procedure_response(row_data, source_file)
        else:
            return self._generate_general_response(row_data, source_file)
    
    def _generate_ip_user_response(self, row_data: Dict[str, Any], source_file: str) -> str:
        """IP ì‚¬ìš©ì ì¡°íšŒ ê°€ì´ë“œ ì‘ë‹µ ìƒì„±"""
        response_parts = []
        
        if 'IP ì£¼ì†Œ' in row_data and pd.notna(row_data['IP ì£¼ì†Œ']):
            response_parts.append(f"ğŸŒ **IP ì£¼ì†Œ**: {row_data['IP ì£¼ì†Œ']}")
        
        if 'ì‚¬ìš©ìëª…' in row_data and pd.notna(row_data['ì‚¬ìš©ìëª…']):
            response_parts.append(f"ğŸ‘¤ **ì‚¬ìš©ì**: {row_data['ì‚¬ìš©ìëª…']}")
        
        if 'ë¶€ì„œ' in row_data and pd.notna(row_data['ë¶€ì„œ']):
            response_parts.append(f"ğŸ¢ **ë¶€ì„œ**: {row_data['ë¶€ì„œ']}")
        
        if 'ì—°ë½ì²˜' in row_data and pd.notna(row_data['ì—°ë½ì²˜']):
            response_parts.append(f"ğŸ“ **ì—°ë½ì²˜**: {row_data['ì—°ë½ì²˜']}")
        
        if 'ìƒíƒœ' in row_data and pd.notna(row_data['ìƒíƒœ']):
            response_parts.append(f"ğŸ“Š **ìƒíƒœ**: {row_data['ìƒíƒœ']}")
        
        if 'ë¹„ê³ ' in row_data and pd.notna(row_data['ë¹„ê³ ']):
            response_parts.append(f"ğŸ“ **ë¹„ê³ **: {row_data['ë¹„ê³ ']}")
        
        response = "\n".join(response_parts)
        response += f"\n\nğŸ“‹ **ì¶œì²˜**: {source_file}"
        
        return response
    
    def _generate_external_system_response(self, row_data: Dict[str, Any], source_file: str) -> str:
        """ëŒ€ì™¸ê³„ ì—°ë™ ê°€ì´ë“œ ì‘ë‹µ ìƒì„±"""
        # í‘œ í—¤ë” ìƒì„±
        response = "## ğŸ“‹ ëŒ€ì™¸ê¸°ê´€ ì—°ê²° ì •ë³´\n\n"
        
        # í‘œ í˜•íƒœë¡œ ì •ë³´ êµ¬ì„±
        table_rows = []
        
        if 'ëŒ€ì™¸ê¸°ê´€ëª…' in row_data and pd.notna(row_data['ëŒ€ì™¸ê¸°ê´€ëª…']):
            table_rows.append(f"| ğŸ›ï¸ **ê¸°ê´€ëª…** | {row_data['ëŒ€ì™¸ê¸°ê´€ëª…']} |")
        
        if 'ì„œë¹„ìŠ¤ëª…' in row_data and pd.notna(row_data['ì„œë¹„ìŠ¤ëª…']):
            table_rows.append(f"| âš™ï¸ **ì„œë¹„ìŠ¤** | {row_data['ì„œë¹„ìŠ¤ëª…']} |")
        
        if 'íšŒì„ ì‚¬' in row_data and pd.notna(row_data['íšŒì„ ì‚¬']):
            table_rows.append(f"| ğŸ“¡ **íšŒì„ ì‚¬** | {row_data['íšŒì„ ì‚¬']} |")
        
        if 'íšŒì„ ë²ˆí˜¸' in row_data and pd.notna(row_data['íšŒì„ ë²ˆí˜¸']):
            table_rows.append(f"| ğŸ“ **íšŒì„ ë²ˆí˜¸** | {row_data['íšŒì„ ë²ˆí˜¸']} |")
        
        if 'IP(ìš´ì˜)' in row_data and pd.notna(row_data['IP(ìš´ì˜)']):
            table_rows.append(f"| ğŸŒ **ìš´ì˜ IP** | `{row_data['IP(ìš´ì˜)']}` |")
        
        if 'IP(ê°œë°œ)' in row_data and pd.notna(row_data['IP(ê°œë°œ)']):
            table_rows.append(f"| ğŸ”§ **ê°œë°œ IP** | `{row_data['IP(ê°œë°œ)']}` |")
        
        # ë‹´ë‹¹ì ì •ë³´ ì„¹ì…˜
        contact_info = []
        if 'ë‹¹í–‰ ë‹´ë‹¹ì' in row_data and pd.notna(row_data['ë‹¹í–‰ ë‹´ë‹¹ì']):
            contact_info.append(f"| ğŸ‘¤ **ë‹´ë‹¹ì** | {row_data['ë‹¹í–‰ ë‹´ë‹¹ì']} |")
        
        if 'ë‹¹í–‰ ì—°ë½ì²˜' in row_data and pd.notna(row_data['ë‹¹í–‰ ì—°ë½ì²˜']):
            contact_info.append(f"| ğŸ“ **ì—°ë½ì²˜** | {row_data['ë‹¹í–‰ ì—°ë½ì²˜']} |")
        
        if 'ë‹¹í–‰ ë¶€ì„œ' in row_data and pd.notna(row_data['ë‹¹í–‰ ë¶€ì„œ']):
            contact_info.append(f"| ğŸ¢ **ë¶€ì„œ** | {row_data['ë‹¹í–‰ ë¶€ì„œ']} |")
        
        # ê¸°ê´€ ë‹´ë‹¹ì ì •ë³´
        if 'ê¸°ê´€ ë‹´ë‹¹ì' in row_data and pd.notna(row_data['ê¸°ê´€ ë‹´ë‹¹ì']):
            contact_info.append(f"| ğŸ‘¥ **ê¸°ê´€ ë‹´ë‹¹ì** | {row_data['ê¸°ê´€ ë‹´ë‹¹ì']} |")
        
        if 'ê¸°ê´€ ì—°ë½ì²˜' in row_data and pd.notna(row_data['ê¸°ê´€ ì—°ë½ì²˜']):
            contact_info.append(f"| ğŸ“± **ê¸°ê´€ ì—°ë½ì²˜** | {row_data['ê¸°ê´€ ì—°ë½ì²˜']} |")
        
        # í‘œ êµ¬ì„±
        if table_rows:
            response += "| êµ¬ë¶„ | ë‚´ìš© |\n"
            response += "|------|------|\n"
            response += "\n".join(table_rows)
            response += "\n\n"
        
        # ë‹´ë‹¹ì ì •ë³´ê°€ ìˆìœ¼ë©´ ë³„ë„ ì„¹ì…˜ìœ¼ë¡œ ì¶”ê°€
        if contact_info:
            response += "### ğŸ‘¥ ë‹´ë‹¹ì ì •ë³´\n\n"
            response += "| êµ¬ë¶„ | ë‚´ìš© |\n"
            response += "|------|------|\n"
            response += "\n".join(contact_info)
            response += "\n\n"
        
        # ë¹„ê³  ì •ë³´
        if 'ë¹„ê³ ' in row_data and pd.notna(row_data['ë¹„ê³ ']):
            response += f"### ğŸ“ ë¹„ê³ \n{row_data['ë¹„ê³ ']}\n\n"
        
        # ê¸°ê´€ ì£¼ì†Œ ì •ë³´
        if 'ê¸°ê´€ ì£¼ì†Œ' in row_data and pd.notna(row_data['ê¸°ê´€ ì£¼ì†Œ']):
            response += f"### ğŸ“ ê¸°ê´€ ì£¼ì†Œ\n{row_data['ê¸°ê´€ ì£¼ì†Œ']}\n\n"
        
        # ì¶œì²˜ ì •ë³´
        response += f"---\nğŸ“‹ **ì¶œì²˜**: {source_file}"
        
        return response
    
    def _generate_trouble_inquiry_response(self, row_data: Dict[str, Any], source_file: str) -> str:
        """ì¥ì•  ë¬¸ì˜ ê°€ì´ë“œ ì‘ë‹µ ìƒì„±"""
        response_parts = []
        
        if 'ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬' in row_data and pd.notna(row_data['ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬']):
            response_parts.append(f"ğŸ“‚ **ì¹´í…Œê³ ë¦¬**: {row_data['ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬']}")
        
        if 'ìš”ì•½ ì‘ë‹µ' in row_data and pd.notna(row_data['ìš”ì•½ ì‘ë‹µ']):
            response_parts.append(f"ğŸ’¡ **ìš”ì•½**: {row_data['ìš”ì•½ ì‘ë‹µ']}")
        
        if 'ìƒì„¸ ì•ˆë‚´' in row_data and pd.notna(row_data['ìƒì„¸ ì•ˆë‚´']):
            response_parts.append(f"ğŸ“‹ **ìƒì„¸ ì•ˆë‚´**:\n{row_data['ìƒì„¸ ì•ˆë‚´']}")
        
        if 'ë‹´ë‹¹ ë¶€ì„œ' in row_data and pd.notna(row_data['ë‹´ë‹¹ ë¶€ì„œ']):
            response_parts.append(f"ğŸ¢ **ë‹´ë‹¹ ë¶€ì„œ**: {row_data['ë‹´ë‹¹ ë¶€ì„œ']}")
        
        if 'ê´€ë ¨ ë¬¸ì„œ/ë§í¬' in row_data and pd.notna(row_data['ê´€ë ¨ ë¬¸ì„œ/ë§í¬']):
            response_parts.append(f"ğŸ”— **ê´€ë ¨ ë¬¸ì„œ**: {row_data['ê´€ë ¨ ë¬¸ì„œ/ë§í¬']}")
        
        response = "\n".join(response_parts)
        response += f"\n\nğŸ“‹ **ì¶œì²˜**: {source_file}"
        
        return response
    
    def _generate_procedure_response(self, row_data: Dict[str, Any], source_file: str) -> str:
        """ì ˆì°¨ ì•ˆë‚´ ê°€ì´ë“œ ì‘ë‹µ ìƒì„±"""
        response_parts = []
        
        if 'ì ˆì°¨ êµ¬ë¶„' in row_data and pd.notna(row_data['ì ˆì°¨ êµ¬ë¶„']):
            response_parts.append(f"ğŸ“‹ **ì ˆì°¨ êµ¬ë¶„**: {row_data['ì ˆì°¨ êµ¬ë¶„']}")
        
        if 'ìš”ì•½ ì‘ë‹µ' in row_data and pd.notna(row_data['ìš”ì•½ ì‘ë‹µ']):
            response_parts.append(f"ğŸ’¡ **ìš”ì•½**: {row_data['ìš”ì•½ ì‘ë‹µ']}")
        
        if 'ìƒì„¸ ì•ˆë‚´' in row_data and pd.notna(row_data['ìƒì„¸ ì•ˆë‚´']):
            response_parts.append(f"ğŸ“ **ìƒì„¸ ì•ˆë‚´**:\n{row_data['ìƒì„¸ ì•ˆë‚´']}")
        
        if 'ë‹´ë‹¹ ë¶€ì„œ' in row_data and pd.notna(row_data['ë‹´ë‹¹ ë¶€ì„œ']):
            response_parts.append(f"ğŸ¢ **ë‹´ë‹¹ ë¶€ì„œ**: {row_data['ë‹´ë‹¹ ë¶€ì„œ']}")
        
        if 'ê´€ë ¨ ë¬¸ì„œ/ë§í¬' in row_data and pd.notna(row_data['ê´€ë ¨ ë¬¸ì„œ/ë§í¬']):
            response_parts.append(f"ğŸ”— **ê´€ë ¨ ë¬¸ì„œ**: {row_data['ê´€ë ¨ ë¬¸ì„œ/ë§í¬']}")
        
        response = "\n".join(response_parts)
        response += f"\n\nğŸ“‹ **ì¶œì²˜**: {source_file}"
        
        return response
    
    def _generate_general_response(self, row_data: Dict[str, Any], source_file: str) -> str:
        """ì¼ë°˜ ê°€ì´ë“œ ì‘ë‹µ ìƒì„±"""
        response_parts = []
        
        # ì£¼ìš” í•„ë“œë“¤ì„ ìˆœì„œëŒ€ë¡œ í™•ì¸
        key_fields = ['ìš”ì•½ ì‘ë‹µ', 'ìƒì„¸ ì•ˆë‚´', 'ì§ˆë¬¸ ì˜ˆì‹œ', 'ë¹„ê³ ', 'ì„¤ëª…', 'ë‚´ìš©']
        
        for field in key_fields:
            if field in row_data and pd.notna(row_data[field]):
                response_parts.append(f"ğŸ“ **{field}**: {row_data[field]}")
        
        # ì¶”ê°€ ì •ë³´ í•„ë“œë“¤
        info_fields = ['ë‹´ë‹¹ ë¶€ì„œ', 'ê´€ë ¨ ë¬¸ì„œ/ë§í¬', 'ì—°ë½ì²˜']
        for field in info_fields:
            if field in row_data and pd.notna(row_data[field]):
                response_parts.append(f"â„¹ï¸ **{field}**: {row_data[field]}")
        
        response = "\n".join(response_parts)
        response += f"\n\nğŸ“‹ **ì¶œì²˜**: {source_file}"
        
        return response
    
    def reload_guide_files(self):
        """ê°€ì´ë“œ íŒŒì¼ ì¬ë¡œë“œ (ìƒˆ íŒŒì¼ ì—…ë¡œë“œ ì‹œ í˜¸ì¶œ)"""
        self.guide_files.clear()
        self.load_guide_files()
        logger.info("ì—…ë¬´ ì•ˆë‚´ ê°€ì´ë“œ íŒŒì¼ ì¬ë¡œë“œ ì™„ë£Œ")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
business_guide_processor = BusinessGuideProcessor()